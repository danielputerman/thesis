{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ce214c74-c41b-4cbc-9d0c-1e107bfa5aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "from torch.utils.data import Dataset as Dataset\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "from matplotlib import pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "from datetime import datetime\n",
    "from typing import Optional, TextIO\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e25404-f945-4714-9078-b131ccd7b5af",
   "metadata": {},
   "source": [
    "## Experimental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "6112fe5f-a040-4587-88fc-41e9a50ca6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized_euclidean_distance_between_tensors(t1, t2):\n",
    "    vec1 = image1.view(-1)\n",
    "    vec2 = image2.view(-1)\n",
    "    return torch.sum(torch.abs((vec2 - vec1)))/vec1.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "dc8fad0d-c65b-4b42-9d41-7d481e8df048",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet5AutoEncoder(nn.Module):\n",
    "\n",
    "    def __init__(self, latent_size=5):\n",
    "        \n",
    "        super(LeNet5, self).__init__()\n",
    "        \n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1),\n",
    "            nn.Tanh(),\n",
    "            nn.AvgPool2d(kernel_size=2),\n",
    "            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1),\n",
    "            nn.Tanh(),\n",
    "            nn.AvgPool2d(kernel_size=2),\n",
    "            nn.Conv2d(in_channels=16, out_channels=120, kernel_size=5, stride=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "        self.feature_compressor = nn.Sequential(\n",
    "            nn.Linear(in_features=120, out_features=84),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(in_features=84, out_features=latent_size*2)\n",
    "        )\n",
    "        \n",
    "        self.feature_expander = nn.Sequential(\n",
    "            nn.Linear(in_features=latent_size, out_features=84),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(in_features=84, out_features=120),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "        self.deconv = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=120, out_channels=16, kernel_size=5, stride=1),\n",
    "            nn.MaxUnpool2d(kernel_size=2),\n",
    "            nn.Tanh(),\n",
    "            nn.ConvTranspose2d(in_channels=16, out_channels=6, kernel_size=5, stride=1),\n",
    "            nn.MaxUnpool2d(kernel_size=2),\n",
    "            nn.Tanh(),\n",
    "            nn.ConvTranspose2d(in_channels=6, out_channels=1, kernel_size=5, stride=1)\n",
    "        )\n",
    "    \n",
    "    def encode(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        x = torch.flatten(x, 1) # this is just the technical tensor reshaping. The *actual* flattening is the last \n",
    "                                # layer of the feature_extractor, which uses convolution to take the 5x5 feature maps into a single 1x1 value.\n",
    "        logits = self.feature_compressor(x)\n",
    "        return logits, probabilities\n",
    "    \n",
    "    def reparameterise(self, mu, logvar):\n",
    "        if self.training:\n",
    "            std = logvar.mul(0.5).exp_()\n",
    "            eps = std.new_empty(std.size()).normal_()\n",
    "            return eps.mul_(std).add_(mu)\n",
    "        else:\n",
    "            return mu\n",
    "\n",
    "    def decode(self, z):\n",
    "        z = self.feature_expander(z)\n",
    "        z = z.unsqueeze(2).unsqueeze(2) # Changing structure: flat->channels. Required for ConvTranspose\n",
    "        return self.deconv(z)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mu_and_logvar = self.encode(x).view(-1, 2, d)\n",
    "        mu = mu_logvar[:, 0, :]\n",
    "        logvar = mu_logvar[:, 1, :]\n",
    "        z = self.reparameterise(mu, logvar)\n",
    "        return self.decode(z), mu, logvar\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "232a9abc-d1b8-445f-bbb6-df09683e3017",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddGaussianNoise(object):\n",
    "    def __init__(self, mean=0., std=1.):\n",
    "        self.std = std\n",
    "        self.mean = mean\n",
    "        \n",
    "    def __call__(self, tensor):\n",
    "        return tensor + torch.randn(tensor.size()) * self.std + self.mean\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)\n",
    "    \n",
    "NoiseTransform=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,)),\n",
    "    AddGaussianNoise(0., 1.)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95be1ac1-bb89-49c3-ae3f-32ec426172dd",
   "metadata": {},
   "source": [
    "## NN Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "06298ae5-d3f4-4865-8d24-7546ba410958",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses_over_epochs(train_losses: list[float], valid_losses: list[float]):\n",
    "    '''\n",
    "    Graphically show the training and validation loss for each epoch.\n",
    "    '''\n",
    "    \n",
    "    # temporarily change the style of the plots to seaborn \n",
    "    plt.style.use('seaborn')\n",
    "\n",
    "    train_losses = np.array(train_losses) \n",
    "    valid_losses = np.array(valid_losses)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize = (8, 4.5))\n",
    "\n",
    "    ax.plot(train_losses, color='blue', label='Training loss') \n",
    "    ax.plot(valid_losses, color='red', label='Validation loss')\n",
    "    ax.set(title=\"Loss over epochs\", \n",
    "            xlabel='Epoch',\n",
    "            ylabel='Loss') \n",
    "    ax.legend()\n",
    "    fig.show()\n",
    "    \n",
    "    # change the plot style to default\n",
    "    plt.style.use('default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "b68323c6-3567-4d0f-a193-aa326d43f069",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_single_epoch(loader, criterion, model, optimizer, normalize_input_fn, normalize_labels_fn, positive_class = 1, train=True):\n",
    "    '''\n",
    "    Implementation a single epoch for the training/validation loop.\n",
    "    '''        \n",
    "    \n",
    "    model.train() if train else model.eval() \n",
    "    \n",
    "    running_loss = 0\n",
    "    \n",
    "    # Each iteration gets a batch from the train loader\n",
    "    for X, Y_true in loader:\n",
    "        X = normalize_input_fn(X) # Normalizing the input if necessary\n",
    "        X = X.to(DEVICE)\n",
    "        Y_true = Y_true.to(DEVICE)\n",
    "        # Y_true = normalize_labels_fn(Y_true)\n",
    "        # Y_true[Y_true == positive_class]  = 1 # We \"normalize\" the label of the positive class to be \"1\". Makes our lives easier (see comment below)\n",
    "        \n",
    "        optimizer.zero_grad() if train else None\n",
    "        \n",
    "        # Forward pass\n",
    "        Y_logits, Y_prob = model(X)\n",
    "        _, predicted_labels = torch.max(Y_prob, 1)  # The \"1\" is acutally misleading - it's the dimension to search the max in.\n",
    "                                                        # This actually returns the indices of the highest prediction for each row, \n",
    "                                                        # but since the index is one-to-one with the predicted digit (i.e., 0 or 1), \n",
    "                                                        # we use the index of the max probability as the label that's being predicted\n",
    "        batch_loss = criterion(Y_logits, Y_true) # we use the logits as the parameter since \"CELoss already pefroms softmax internally.\n",
    "        running_loss += batch_loss.item() * X.size(0) # X.size(0) is the size of the BATCH, not the image. \n",
    "                                                # The multiplication is required later for calculating the avg loss of the epoch step.\n",
    "        \n",
    "        # Backward pass, only required in training the model\n",
    "        if train:\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    avg_batch_loss_for_epoch = running_loss / len(loader.dataset)\n",
    "    return model, optimizer, avg_batch_loss_for_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "0d4fa55c-abf7-4cc3-b8c1-ccce8cb67620",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datasets_for_discovery(add_noise=False) -> tuple[SimpleDataSet, SimpleDataSet]:\n",
    "    '''\n",
    "    Returns:\n",
    "        A Tuple of (Training dataset, Test dataset)\n",
    "            Dataset.data: 4-D tensor (batch size, channels, width, height). This is because nn.Conv2d expects input of this shape.\n",
    "            Dataset.targets: 1-D tensor (target class)\n",
    "    '''\n",
    "    \n",
    "    image_padding_to_32 = transforms.Compose([transforms.Resize((32,32)), transforms.ToTensor()])\n",
    "    \n",
    "    if add_noise:\n",
    "        raise NotImplementedError(\"adding noise was not yet implemented\")\n",
    "        \n",
    "    # Get data of 4, then set the targets as \"0\" (as this is our \"null\" class).\n",
    "    training_set_full = datasets.MNIST(root='./data', download=True, transform=image_padding_to_32, train=True)\n",
    "    training_four_index = (training_set_full.targets == 4).nonzero().reshape(-1)\n",
    "    train_four_loader = torch.utils.data.DataLoader(dataset=training_set_full, batch_size=len(training_four_index), shuffle=False, sampler=Data.SubsetRandomSampler(training_four_index))\n",
    "    train_four_data, train_four_targets = next(iter(train_four_loader)) # We only need one iteration, as the loader has the size of the entire relevant sample\n",
    "    \n",
    "    assert len(train_four_targets[(train_four_targets!=4).nonzero().reshape(-1)])==0 # Avoid bugs in data loading. You're welcome hahaha\n",
    "    train_four_targets[(train_four_targets==4).nonzero().reshape(-1)] = 0\n",
    "    \n",
    "    \n",
    "    training_set = SimpleDataSet(train_four_data, train_four_targets)\n",
    "    \n",
    "    test_set_full = datasets.MNIST(root='./data', download=True, transform=image_padding_to_32, train=False)\n",
    "    test_four_index = torch.logical_or(test_set_full.targets == 4, test_set_full.targets == 9).nonzero().reshape(-1)\n",
    "    # test_four_index = (test_set_full.targets == 9).nonzero().reshape(-1)\n",
    "    test_four_loader = torch.utils.data.DataLoader(dataset=test_set_full, batch_size=len(test_four_index), shuffle=False, sampler=Data.SubsetRandomSampler(test_four_index))\n",
    "    test_four_data, test_four_targets = next(iter(test_four_loader))\n",
    "    test_four_targets[(test_four_targets==4).nonzero().reshape(-1)] = 0\n",
    "    test_four_targets[(test_four_targets==9).nonzero().reshape(-1)] = 1\n",
    "    test_set = SimpleDataSet(test_four_data, test_four_targets)\n",
    "    \n",
    "    return training_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "7e981840-3d2d-4cf4-99bb-82347b160df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_loop(train_loader, validation_loader, criterion, model, optimizer, positive_class=1, num_epochs=10, normalize_input_fn=lambda x: x, \n",
    "             normalize_labels_fn=lambda y: y, print_every=1):\n",
    "    \n",
    "    # Objects for storing metrics\n",
    "    best_loss = 1e10\n",
    "    train_losses = []\n",
    "    validation_losses = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # print(f'Epoch: {epoch}\\t')\n",
    "        \n",
    "        # Training the model\n",
    "        _, _, train_loss = run_single_epoch(train_loader, criterion, model, optimizer, normalize_input_fn, normalize_labels_fn, positive_class)\n",
    "        train_losses.append(train_loss)\n",
    "        \n",
    "        # No need for validation when working with a score model\n",
    "        validation_losses.append(0)\n",
    "        # # Validation\n",
    "        # with torch.no_grad():\n",
    "        #     _, _, validation_loss = run_single_epoch(validation_loader, criterion, model, None, normalize_input_fn, normalize_labels_fn, positive_class, False)\n",
    "        #     validation_losses.append(validation_loss)\n",
    "        \n",
    "        # if epoch % print_every == (print_every - 1):\n",
    "        #     print(f'{datetime.now().time().replace(microsecond=0)} --- '\n",
    "        #           f'Epoch: {epoch}\\t'\n",
    "        #           f'Train loss: {train_loss:.4f}\\t'\n",
    "        #           # f'Vaildation loss: {validation_loss:.4f}\\t')\n",
    "        #           f'Vaildation loss: 0\\t')\n",
    "    \n",
    "    plot_losses_over_epochs(train_losses, validation_losses)\n",
    "        \n",
    "    return model, optimizer, num_epochs, (train_losses, validation_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d4ae6f-9b94-4f17-8a2d-0625afb7dfe4",
   "metadata": {},
   "source": [
    "### LeNet5 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "558223a6-75d2-48f9-8fd1-6165d46c57f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet5(nn.Module):\n",
    "\n",
    "    def __init__(self, n_classes):\n",
    "        \n",
    "        super(LeNet5, self).__init__()\n",
    "        \n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1),\n",
    "            nn.Tanh(),\n",
    "            nn.AvgPool2d(kernel_size=2),\n",
    "            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1),\n",
    "            nn.Tanh(),\n",
    "            nn.AvgPool2d(kernel_size=2),\n",
    "            nn.Conv2d(in_channels=16, out_channels=120, kernel_size=5, stride=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(in_features=120, out_features=84),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(in_features=84, out_features=n_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        logits = self.classifier(x)\n",
    "        probabilities = F.softmax(logits, dim=1)\n",
    "        return logits, probabilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "fc3d7d05-586c-4e42-af9c-d3e93d6f5c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleDataSet(Dataset):\n",
    "    def __init__(self, data, targets):\n",
    "        super(SimpleDataSet, self).__init__()\n",
    "        assert data.shape[0] == targets.shape[0] # assuming shape[0] = dataset size\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.targets.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index], self.targets[index].item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43c239e-e344-4637-9237-8399aa06771b",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f976b72-9af3-4b17-881c-75776abffd25",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90575d37-3c02-4773-8541-fcd1781ab6c3",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ef5767-2829-4cba-9487-1eda3e8296e8",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "9c8f9c0d-79aa-49ad-94d0-8cd3088668b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, test_loader):\n",
    "    SEED = 42\n",
    "    LEARNING_RATE = 1e-3\n",
    "    N_CLASSES = 2\n",
    "\n",
    "    torch.manual_seed(SEED)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    return run_loop(train_loader, test_loader, criterion, model, optimizer, normalize_input_fn=lambda x: x / 255.0, num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "47ae51f0-5daa-445a-bfdb-62fc6324098e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConcatDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, datasetA, datasetB):\n",
    "        super(ConcatDataset, self).__init__()\n",
    "        self.datasetA = datasetA\n",
    "        self.datasetB = datasetB\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        if i<len(self.datasetA):\n",
    "            return self.datasetA[i]\n",
    "        else:\n",
    "            return self.datasetB[i-len(self.datasetA)]\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.datasetA) + len(self.datasetB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "9c86dc35-165a-4a32-a553-f7d20d4e48a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def clone_and_new_computation_graph(t: torch.Tensor, requires_grad=True) -> torch.Tensor:\n",
    "    '''\n",
    "        Returns: \n",
    "            A Tensor with the same data (copied) as `t`, on a new computation graph\n",
    "    '''\n",
    "    t2 = torch.detach(t).clone()\n",
    "    if requires_grad:\n",
    "        t2.requires_grad_()\n",
    "    return t2\n",
    "\n",
    "\n",
    "def get_synthetic_h0_h1(training_set: SimpleDataSet, test_set: SimpleDataSet) -> tuple[SimpleDataSet, SimpleDataSet, SimpleDataSet, int]:\n",
    "    '''\n",
    "    Parameters:\n",
    "        Training and Test datasets. Each of the following form:\n",
    "            Dataset.data: 4-D tensor (batch size, channels, width, height). This is because nn.Conv2d expects input of this shape.\n",
    "            Dataset.targets: 1-D tensor (target class)\n",
    "    Returns:\n",
    "        H0, H1, H1 with true target values (used for validation), K\n",
    "    '''\n",
    "    \n",
    "    # k = math.floor(len(training_set) / 2) # TODO sample random k instead?\n",
    "    k = len(training_set)- len(test_set) # TODO sample random k instead?\n",
    "    # k = len(training_set) - 50\n",
    "    original_training_data = training_set.data\n",
    "    original_training_targets = training_set.targets\n",
    "\n",
    "    # Create H0 set by *copying* the training set, and have it use a separate computation graph.\n",
    "    h0_data = clone_and_new_computation_graph(original_training_data[:k])\n",
    "    h0_targets = clone_and_new_computation_graph(original_training_targets[:k], requires_grad=False)\n",
    "    h0_targets[:] = 0\n",
    "\n",
    "    h0_set = SimpleDataSet(h0_data, h0_targets)\n",
    "    \n",
    "    # Create H1 and H1_true_targets sets by *copying* the data and have it use a separate computation graph\n",
    "    h1_0_data = clone_and_new_computation_graph(original_training_data[k:])\n",
    "    h1_0_targets = clone_and_new_computation_graph(original_training_targets[k:], requires_grad=False)\n",
    "    h1_0_targets[:] = 1\n",
    "        \n",
    "    h1_0_data_for_true_targets = clone_and_new_computation_graph(original_training_data[k:])\n",
    "    h1_0_true_targets = clone_and_new_computation_graph(original_training_targets[k:], requires_grad=False)\n",
    "    \n",
    "    original_test_data = test_set.data\n",
    "    original_test_targets = test_set.targets\n",
    "    h1_1_data = clone_and_new_computation_graph(original_test_data)\n",
    "    h1_1_targets = clone_and_new_computation_graph(original_test_targets, requires_grad=False)\n",
    "    h1_1_targets[:] = 1\n",
    "    \n",
    "    h1_1_data_for_true_targets = clone_and_new_computation_graph(original_test_data)\n",
    "    h1_1_true_targets = clone_and_new_computation_graph(original_test_targets, requires_grad=False)\n",
    "    \n",
    "    h1_data = torch.cat((h1_0_data, h1_1_data), 0)\n",
    "    h1_targets = torch.cat((h1_0_targets, h1_1_targets), 0)\n",
    "    \n",
    "    h1_set = SimpleDataSet(h1_data, h1_targets)\n",
    "    \n",
    "    h1_data_true = torch.cat((h1_0_data_for_true_targets, h1_1_data_for_true_targets), 0)\n",
    "    h1_targets_true = torch.cat((h1_0_true_targets, h1_1_true_targets), 0)\n",
    "    \n",
    "    h1_set_with_true_targets = SimpleDataSet(h1_data_true, h1_targets_true)\n",
    "    \n",
    "\n",
    "    return h0_set, h1_set, h1_set_with_true_targets, k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "d6e556c7-9a5d-4d26-bba3-64222e4a204d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datasets_for_discovery(experiment_type: int, add_noise=False) -> tuple[SimpleDataSet, SimpleDataSet]:\n",
    "    '''\n",
    "    Parameters:\n",
    "        experiment_type:\n",
    "            1 - test data is only H1, no noise\n",
    "            2 - test data is a mix of H0 and H1, no noise\n",
    "            \n",
    "    Returns:\n",
    "        A Tuple of (Training dataset, Test dataset)\n",
    "            Dataset.data: 4-D tensor (batch size, channels, width, height). This is because nn.Conv2d expects input of this shape.\n",
    "            Dataset.targets: 1-D tensor (target class)\n",
    "    '''\n",
    "    \n",
    "    image_padding_to_32 = transforms.Compose([transforms.Resize((32,32)), transforms.ToTensor()])\n",
    "    \n",
    "    if add_noise:\n",
    "        raise NotImplementedError(\"Adding noise was not yet implemented\")\n",
    "        \n",
    "    ## Training data\n",
    "    training_set_full = datasets.MNIST(root='./data', download=True, transform=image_padding_to_32, train=True)\n",
    "    training_subset_index = (training_set_full.targets == 4).nonzero().reshape(-1)\n",
    "    training_subset_loader = torch.utils.data.DataLoader(dataset=training_set_full, batch_size=len(training_subset_index), shuffle=False, sampler=Data.SubsetRandomSampler(training_subset_index))\n",
    "    training_subset_data, training_subset_targets = next(iter(training_subset_loader)) # We only need one iteration, as the loader has the size of the entire relevant sample\n",
    "    \n",
    "    assert len(training_subset_targets[(training_subset_targets!=4).nonzero().reshape(-1)])==0 # Avoid bugs in data loading. You're welcome hahaha\n",
    "    training_subset_targets[(training_subset_targets==4).nonzero().reshape(-1)] = 0  # Set the targets' value to 0 (as this is our \"null\" class).\n",
    "    \n",
    "    training_set = SimpleDataSet(training_subset_data, training_subset_targets)\n",
    "    \n",
    "    ## Test data\n",
    "    test_set_full = datasets.MNIST(root='./data', download=True, transform=image_padding_to_32, train=False)\n",
    "    test_subset_index = []\n",
    "    if experiment_type==1:\n",
    "        test_subset_index = (test_set_full.targets == 9).nonzero().reshape(-1)\n",
    "    elif experiment_type==2:\n",
    "        test_subset_index = torch.logical_or(test_set_full.targets == 4, test_set_full.targets == 9).nonzero().reshape(-1)\n",
    "    else:\n",
    "        raise NotImplementedError(\"Only 1,2 experiment types are supported\")\n",
    "    \n",
    "    test_subset_loader = torch.utils.data.DataLoader(dataset=test_set_full, batch_size=len(test_subset_index), shuffle=False, sampler=Data.SubsetRandomSampler(test_subset_index))\n",
    "    test_subset_data, test_subset_targets = next(iter(test_subset_loader))\n",
    "    test_subset_targets[(test_subset_targets==4).nonzero().reshape(-1)] = 0\n",
    "    test_subset_targets[(test_subset_targets==9).nonzero().reshape(-1)] = 1\n",
    "    test_set = SimpleDataSet(test_subset_data, test_subset_targets)\n",
    "    \n",
    "    return training_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "bbf0a781-c9cd-4d00-a8b3-05641b8e7a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_discovery(seed, batch_size, experiment_type, alpha=0.1):\n",
    "    \n",
    "    # Reproducability :-)\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "    # Get the data (notice this loads in a different random order each time, given the seed)\n",
    "    training_set, test_set = get_datasets_for_discovery(experiment_type)\n",
    "\n",
    "    # train_autoencoder(auto_econder, training_set) if auto_econder is not None else 0 \n",
    "        \n",
    "    # Re-divide train and test data for AdaDetect\n",
    "    h0_set, h1_set, h1_set_with_true_targets, k = get_synthetic_h0_h1(training_set, test_set)\n",
    "    # print(F\"Training set size: {len(training_set)}, Test set size: {len(test_set)}\")\n",
    "    # print(F\"Selected K: {k}, h0 size: {len(h0_set)} , h1 size: {len(h1_set)}\")\n",
    "    h0h1_set = ConcatDataset(h0_set,h1_set)\n",
    "    h0h1_loader = DataLoader(h0h1_set, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    ## Training\n",
    "    N_CLASSES = 2\n",
    "    score_model = nn.DataParallel(LeNet5(N_CLASSES)) # We create the model from scratch for each experiment\n",
    "    score_model, optimizer, num_epochs, (train_losses, validation_losses) = train_model(score_model, h0h1_loader, None)\n",
    "    \n",
    "    # Got a trained model, let's get the scores\n",
    "    with torch.no_grad():\n",
    "        score_model.eval()\n",
    "        _, probability_scores = score_model(h1_set.data.to(DEVICE)) # probability scores is a tensor of pairs (p(0), p(1)).\n",
    "    probability_of_discovery = probability_scores[:,1].numpy() # We only care about the probability of a discovery (p(1))\n",
    "\n",
    "    # Use BoNuS and Knockoff counting for stating discoveries while keeping FDR\n",
    "    l = len(training_set)-k # This is the length of the \"2nd part\" of the null samples, which will be concatenated to the test sample\n",
    "    m = len(test_set)\n",
    "    \n",
    "    scores_df = pd.DataFrame({'score': probability_of_discovery, 'is_test': np.concatenate((np.repeat(0, l),np.repeat(1,m))),'truth':h1_set_with_true_targets.targets.numpy()})\n",
    "    scores_df.sort_values(by=['score'], inplace=True, ascending=True)\n",
    "    \n",
    "    fdp = 10 # a value which is definitely bigger than alpha\n",
    "    \n",
    "    for lower_bound in range(len(h1_set)):\n",
    "        scores_window_df = scores_df[lower_bound:] # get the subset of the samples we want to test with.\n",
    "        ktest = len(scores_window_df[scores_window_df['is_test']==1]) # This is the \"moving\" k, which changes as we move the lower score bound.\n",
    "        v = len(scores_window_df[scores_window_df['is_test']==0]) # The count of false discoveries that we know of (i.e., training samples)\n",
    "        try: \n",
    "            fdp = ((v+1) / (l+1)) * (m / ktest)\n",
    "        except ZeroDivisionError:\n",
    "            fdp = 99999\n",
    "            break\n",
    "        # print(F\"ktest: {ktest},\\t\"\n",
    "        #       F\"v: {v},\\t\"\n",
    "        #       F\"m: {m},\\t\"\n",
    "        #       F\"l: {l},\\t\"\n",
    "        #       F\"fdp: {fdp}\")\n",
    "\n",
    "        if fdp<=alpha:\n",
    "            # print(F\"Got FDP of {fdp} <= alpha({alpha}) , for lower bound: {lower_bound}\")\n",
    "            break\n",
    "    \n",
    "    total_elements = len(scores_window_df)\n",
    "    total_discoveries = ktest\n",
    "    false_discoveries = len(scores_window_df[(scores_window_df['is_test']==1) & (scores_window_df['truth']==0)])\n",
    "    \n",
    "    return dict(model=score_model,\n",
    "                optimizer=optimizer,\n",
    "                alpha=alpha,\n",
    "                m=m,\n",
    "                l=l,\n",
    "                num_epochs=num_epochs,\n",
    "                final_CELoss=train_losses[-1],\n",
    "                total_elements=total_elements,\n",
    "                total_discoveries=total_discoveries, \n",
    "                false_discoveries=false_discoveries,\n",
    "                v=v,\n",
    "                fdp=fdp)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "295b1d85-5d39-4fe1-8801-d2cbad527a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiment_id,\texperiment_type,\tseed,\tbatch_size,\talpha,\tm,\tl,\tnum epochs,\tfinal CELoss,\ttotal elements,\ttotal discoveries (ktest),\tv,\tfalse discoveries,\tfdp\n",
      "1-0-2023-03-08-16-14-04,\t1,\t0,\t32,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/x6/ctsmhfm56hj3xdv0z721s6lc0000gn/T/ipykernel_1845/1730830866.py:7: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.\n",
      "  plt.style.use('seaborn')\n",
      "/var/folders/x6/ctsmhfm56hj3xdv0z721s6lc0000gn/T/ipykernel_1845/1730830866.py:20: UserWarning: Matplotlib is currently using module://matplotlib_inline.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t0.1,\t1009,\t1009,\t5,\t0,\t3,\t0,\t3,\t0,\t99999\n",
      "*** All done! ***\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x450 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class NullStream:\n",
    "        @staticmethod\n",
    "        def write(*_): pass\n",
    "        @staticmethod\n",
    "        def flush(*_): pass\n",
    "\n",
    "def print_to_stdout_and_stream(text, stream:TextIO = NullStream):\n",
    "        sys.stdout.write(text)\n",
    "        sys.stdout.flush()\n",
    "        stream.write(text)\n",
    "        stream.flush()\n",
    "\n",
    "NUM_EXPERIMENT_TYPES = 1\n",
    "NUM_EXPERIMENTS_PER_TYPE = 1\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# DEVICE = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "DEVICE = torch.device(\"cpu\") # No point in using MPS for now :( See https://github.com/pytorch/pytorch/issues/77799\n",
    "\n",
    "with open('experiments-results.csv', mode='at', encoding=\"utf-8\") as results_stream:\n",
    "    print_to_stdout_and_stream(\"experiment_id,\\texperiment_type,\\tseed,\\tbatch_size,\\talpha,\\tm,\\tl,\\tnum epochs,\\tfinal CELoss,\\ttotal elements,\\ttotal discoveries (ktest),\\tv,\\tfalse discoveries,\\tfdp\\n\",\n",
    "                              results_stream) \n",
    "    \n",
    "    for exp_type in range(1,NUM_EXPERIMENT_TYPES+1):\n",
    "        \n",
    "        for i in range(NUM_EXPERIMENTS_PER_TYPE):\n",
    "            \n",
    "            # Print to know we started another discovery process\n",
    "            exp_id = F\"{exp_type}-{i}-{datetime.utcnow().strftime('%Y-%m-%d-%H-%M-%S')}\"\n",
    "            print_to_stdout_and_stream(F\"{exp_id},\"\n",
    "                                       F\"\\t{exp_type},\"\n",
    "                                       F\"\\t{i},\"\n",
    "                                       F\"\\t{BATCH_SIZE},\", results_stream)\n",
    "            \n",
    "            discovery_results = run_discovery(i, BATCH_SIZE, exp_type)\n",
    "            \n",
    "            print_to_stdout_and_stream(F\"\\t{discovery_results['alpha']},\"\n",
    "                                       F\"\\t{discovery_results['m']},\"\n",
    "                                       F\"\\t{discovery_results['l']},\"\n",
    "                                       F\"\\t{discovery_results['num_epochs']},\"\n",
    "                                       F\"\\t{discovery_results['final_CELoss']},\"\n",
    "                                       F\"\\t{discovery_results['total_elements']},\"\n",
    "                                       F\"\\t{discovery_results['total_discoveries']},\"\n",
    "                                       F\"\\t{discovery_results['v']},\"\n",
    "                                       F\"\\t{discovery_results['false_discoveries']},\"\n",
    "                                       F\"\\t{discovery_results['fdp']}\\n\", results_stream)\n",
    "            \n",
    "            # Reproduceability - save the model used for this discovery process\n",
    "            torch.save({ \n",
    "                'model_state_dict': discovery_results[\"model\"].state_dict(),\n",
    "                'optimizer_state_dict': discovery_results[\"optimizer\"].state_dict(),\n",
    "                'loss': discovery_results[\"final_CELoss\"],\n",
    "            }, F\"{exp_id}.pt\")\n",
    "\n",
    "print(\"*** All done! ***\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd8fc2a-2545-42c2-9b1c-b9abbfb423d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
