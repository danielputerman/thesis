{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "ce214c74-c41b-4cbc-9d0c-1e107bfa5aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "from torch.utils.data import Dataset as Dataset\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "from matplotlib import pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "from datetime import datetime\n",
    "from typing import Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "c6170a9a-70b2-48da-a1ad-4c8e20ae4218",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x113cb41f0>"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e25404-f945-4714-9078-b131ccd7b5af",
   "metadata": {},
   "source": [
    "## Experimental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "dc8fad0d-c65b-4b42-9d41-7d481e8df048",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet5AutoEncoder(nn.Module):\n",
    "\n",
    "    def __init__(self, latent_size=5):\n",
    "        \n",
    "        super(LeNet5, self).__init__()\n",
    "        \n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1),\n",
    "            nn.Tanh(),\n",
    "            nn.AvgPool2d(kernel_size=2),\n",
    "            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1),\n",
    "            nn.Tanh(),\n",
    "            nn.AvgPool2d(kernel_size=2),\n",
    "            nn.Conv2d(in_channels=16, out_channels=120, kernel_size=5, stride=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "        self.feature_compressor = nn.Sequential(\n",
    "            nn.Linear(in_features=120, out_features=84),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(in_features=84, out_features=latent_size*2)\n",
    "        )\n",
    "        \n",
    "        self.feature_expander = nn.Sequential(\n",
    "            nn.Linear(in_features=latent_size, out_features=84),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(in_features=84, out_features=120),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "        self.deconv = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=120, out_channels=16, kernel_size=5, stride=1),\n",
    "            nn.MaxUnpool2d(kernel_size=2),\n",
    "            nn.Tanh(),\n",
    "            nn.ConvTranspose2d(in_channels=16, out_channels=6, kernel_size=5, stride=1),\n",
    "            nn.MaxUnpool2d(kernel_size=2),\n",
    "            nn.Tanh(),\n",
    "            nn.ConvTranspose2d(in_channels=6, out_channels=1, kernel_size=5, stride=1)\n",
    "        )\n",
    "    \n",
    "    def encode(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        x = torch.flatten(x, 1) # this is just the technical tensor reshaping. The *actual* flattening is the last \n",
    "                                # layer of the feature_extractor, which uses convolution to take the 5x5 feature maps into a single 1x1 value.\n",
    "        logits = self.feature_compressor(x)\n",
    "        return logits, probabilities\n",
    "    \n",
    "    def reparameterise(self, mu, logvar):\n",
    "        if self.training:\n",
    "            std = logvar.mul(0.5).exp_()\n",
    "            eps = std.new_empty(std.size()).normal_()\n",
    "            return eps.mul_(std).add_(mu)\n",
    "        else:\n",
    "            return mu\n",
    "\n",
    "    def decode(self, z):\n",
    "        z = self.feature_expander(z)\n",
    "        z = z.unsqueeze(2).unsqueeze(2) # Changing structure: flat->channels. Required for ConvTranspose\n",
    "        return self.deconv(z)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mu_and_logvar = self.encode(x).view(-1, 2, d)\n",
    "        mu = mu_logvar[:, 0, :]\n",
    "        logvar = mu_logvar[:, 1, :]\n",
    "        z = self.reparameterise(mu, logvar)\n",
    "        return self.decode(z), mu, logvar\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "232a9abc-d1b8-445f-bbb6-df09683e3017",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddGaussianNoise(object):\n",
    "    def __init__(self, mean=0., std=1.):\n",
    "        self.std = std\n",
    "        self.mean = mean\n",
    "        \n",
    "    def __call__(self, tensor):\n",
    "        return tensor + torch.randn(tensor.size()) * self.std + self.mean\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)\n",
    "    \n",
    "NoiseTransform=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,)),\n",
    "    AddGaussianNoise(0., 1.)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95be1ac1-bb89-49c3-ae3f-32ec426172dd",
   "metadata": {},
   "source": [
    "## NN Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "06298ae5-d3f4-4865-8d24-7546ba410958",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses_over_epochs(train_losses: list[float], valid_losses: list[float]):\n",
    "    '''\n",
    "    Graphically show the training and validation loss for each epoch.\n",
    "    '''\n",
    "    \n",
    "    # temporarily change the style of the plots to seaborn \n",
    "    plt.style.use('seaborn')\n",
    "\n",
    "    train_losses = np.array(train_losses) \n",
    "    valid_losses = np.array(valid_losses)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize = (8, 4.5))\n",
    "\n",
    "    ax.plot(train_losses, color='blue', label='Training loss') \n",
    "    ax.plot(valid_losses, color='red', label='Validation loss')\n",
    "    ax.set(title=\"Loss over epochs\", \n",
    "            xlabel='Epoch',\n",
    "            ylabel='Loss') \n",
    "    ax.legend()\n",
    "    fig.show()\n",
    "    \n",
    "    # change the plot style to default\n",
    "    plt.style.use('default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "b68323c6-3567-4d0f-a193-aa326d43f069",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_single_epoch(loader, criterion, model, optimizer, normalize_input_fn, normalize_labels_fn, positive_class = 1, train=True):\n",
    "    '''\n",
    "    Implementation a single epoch for the training/validation loop.\n",
    "    '''        \n",
    "    \n",
    "    model.train() if train else model.eval() \n",
    "    \n",
    "    running_loss = 0\n",
    "    \n",
    "    # Each iteration gets a batch from the train loader\n",
    "    for X, Y_true in loader:\n",
    "        X = normalize_input_fn(X) # Normalizing the input if necessary\n",
    "        X = X.to(DEVICE)\n",
    "        Y_true = Y_true.to(DEVICE)\n",
    "        # Y_true = normalize_labels_fn(Y_true)\n",
    "        # Y_true[Y_true == positive_class]  = 1 # We \"normalize\" the label of the positive class to be \"1\". Makes our lives easier (see comment below)\n",
    "        \n",
    "        optimizer.zero_grad() if train else None\n",
    "        \n",
    "        # Forward pass\n",
    "        Y_logits, Y_prob = model(X)\n",
    "        _, predicted_labels = torch.max(Y_prob, 1)  # The \"1\" is acutally misleading - it's the dimension to search the max in.\n",
    "                                                        # This actually returns the indices of the highest prediction for each row, \n",
    "                                                        # but since the index is one-to-one with the predicted digit (i.e., 0 or 1), \n",
    "                                                        # we use the index of the max probability as the label that's being predicted\n",
    "        batch_loss = criterion(Y_logits, Y_true) # we use the logits as the parameter since \"CELoss already pefroms softmax internally.\n",
    "        running_loss += batch_loss.item() * X.size(0) # X.size(0) is the size of the BATCH, not the image. \n",
    "                                                # The multiplication is required later for calculating the avg loss of the epoch step.\n",
    "        \n",
    "        # Backward pass, only required in training the model\n",
    "        if train:\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    avg_batch_loss_for_epoch = running_loss / len(loader.dataset)\n",
    "    return model, optimizer, avg_batch_loss_for_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "7e981840-3d2d-4cf4-99bb-82347b160df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_loop(train_loader, validation_loader, criterion, model, optimizer, positive_class=1, num_epochs=10, normalize_input_fn=lambda x: x, \n",
    "             normalize_labels_fn=lambda y: y, print_every=1):\n",
    "    \n",
    "    # Objects for storing metrics\n",
    "    best_loss = 1e10\n",
    "    train_losses = []\n",
    "    validation_losses = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch: {epoch}\\t')\n",
    "        \n",
    "        # Training the model\n",
    "        _, _, train_loss = run_single_epoch(train_loader, criterion, model, optimizer, normalize_input_fn, normalize_labels_fn, positive_class)\n",
    "        train_losses.append(train_loss)\n",
    "        \n",
    "        # No need for validation when working with a score model\n",
    "        validation_losses.append(0)\n",
    "        # # Validation\n",
    "        # with torch.no_grad():\n",
    "        #     _, _, validation_loss = run_single_epoch(validation_loader, criterion, model, None, normalize_input_fn, normalize_labels_fn, positive_class, False)\n",
    "        #     validation_losses.append(validation_loss)\n",
    "        \n",
    "        if epoch % print_every == (print_every - 1):\n",
    "            print(f'{datetime.now().time().replace(microsecond=0)} --- '\n",
    "                  f'Epoch: {epoch}\\t'\n",
    "                  f'Train loss: {train_loss:.4f}\\t'\n",
    "                  # f'Vaildation loss: {validation_loss:.4f}\\t')\n",
    "                  f'Vaildation loss: 0\\t')\n",
    "    \n",
    "    plot_losses_over_epochs(train_losses, validation_losses)\n",
    "        \n",
    "    return model, optimizer, (train_losses, validation_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d4ae6f-9b94-4f17-8a2d-0625afb7dfe4",
   "metadata": {},
   "source": [
    "### LeNet5 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "558223a6-75d2-48f9-8fd1-6165d46c57f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet5(nn.Module):\n",
    "\n",
    "    def __init__(self, n_classes):\n",
    "        \n",
    "        super(LeNet5, self).__init__()\n",
    "        \n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1),\n",
    "            nn.Tanh(),\n",
    "            nn.AvgPool2d(kernel_size=2),\n",
    "            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1),\n",
    "            nn.Tanh(),\n",
    "            nn.AvgPool2d(kernel_size=2),\n",
    "            nn.Conv2d(in_channels=16, out_channels=120, kernel_size=5, stride=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(in_features=120, out_features=84),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(in_features=84, out_features=n_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        logits = self.classifier(x)\n",
    "        probabilities = F.softmax(logits, dim=1)\n",
    "        return logits, probabilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "fc3d7d05-586c-4e42-af9c-d3e93d6f5c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleDataSet(Dataset):\n",
    "    def __init__(self, data, targets):\n",
    "        super(SimpleDataSet, self).__init__()\n",
    "        assert data.shape[0] == targets.shape[0] # assuming shape[0] = dataset size\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.targets.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index], self.targets[index].item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43c239e-e344-4637-9237-8399aa06771b",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f976b72-9af3-4b17-881c-75776abffd25",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90575d37-3c02-4773-8541-fcd1781ab6c3",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ef5767-2829-4cba-9487-1eda3e8296e8",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "9c8f9c0d-79aa-49ad-94d0-8cd3088668b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, test_loader):\n",
    "    SEED = 42\n",
    "    LEARNING_RATE = 1e-3\n",
    "    N_CLASSES = 2\n",
    "\n",
    "    torch.manual_seed(SEED)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    return run_loop(train_loader, test_loader, criterion, model, optimizer, normalize_input_fn=lambda x: x / 255.0, num_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "47ae51f0-5daa-445a-bfdb-62fc6324098e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConcatDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, datasetA, datasetB):\n",
    "        super(ConcatDataset, self).__init__()\n",
    "        self.datasetA = datasetA\n",
    "        self.datasetB = datasetB\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        if i<len(self.datasetA):\n",
    "            return self.datasetA[i]\n",
    "        else:\n",
    "            return self.datasetB[i-len(self.datasetA)]\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.datasetA) + len(self.datasetB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "9c86dc35-165a-4a32-a553-f7d20d4e48a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def clone_and_new_computation_graph(t: torch.Tensor, requires_grad=True) -> torch.Tensor:\n",
    "    '''\n",
    "        Returns: \n",
    "            A Tensor with the same data (copied) as `t`, on a new computation graph\n",
    "    '''\n",
    "    t2 = torch.detach(t).clone()\n",
    "    if requires_grad:\n",
    "        t2.requires_grad_()\n",
    "    return t2\n",
    "\n",
    "\n",
    "def get_synthetic_h0_h1(training_set: SimpleDataSet, test_set: SimpleDataSet) -> tuple[SimpleDataSet, SimpleDataSet, SimpleDataSet, int]:\n",
    "    '''\n",
    "    Parameters:\n",
    "        Training and Test datasets. Each of the following form:\n",
    "            Dataset.data: 4-D tensor (batch size, channels, width, height). This is because nn.Conv2d expects input of this shape.\n",
    "            Dataset.targets: 1-D tensor (target class)\n",
    "    Returns:\n",
    "        H0, H1, H1 with true target values (used for validation), K\n",
    "    '''\n",
    "    \n",
    "    # k = math.floor(len(training_set) / 2) # TODO sample random k instead?\n",
    "    k = math.floor(((len(training_set) + len(training_set)) / 2) - len(test_set)) # TODO sample random k instead?\n",
    "    # k = len(training_set) - 50\n",
    "    original_training_data = training_set.data\n",
    "    original_training_targets = training_set.targets\n",
    "\n",
    "    # Create H0 set by *copying* the training set, and have it use a separate computation graph.\n",
    "    h0_data = clone_and_new_computation_graph(original_training_data[:k])\n",
    "    h0_targets = clone_and_new_computation_graph(original_training_targets[:k], requires_grad=False)\n",
    "    h0_targets[:] = 0\n",
    "\n",
    "    h0_set = SimpleDataSet(h0_data, h0_targets)\n",
    "    \n",
    "    # Create H1 and H1_true_targets sets by *copying* the data and have it use a separate computation graph\n",
    "    h1_0_data = clone_and_new_computation_graph(original_training_data[k:])\n",
    "    h1_0_targets = clone_and_new_computation_graph(original_training_targets[k:], requires_grad=False)\n",
    "    h1_0_targets[:] = 1\n",
    "        \n",
    "    h1_0_data_for_true_targets = clone_and_new_computation_graph(original_training_data[k:])\n",
    "    h1_0_true_targets = clone_and_new_computation_graph(original_training_targets[k:], requires_grad=False)\n",
    "    \n",
    "    original_test_data = test_set.data\n",
    "    original_test_targets = test_set.targets\n",
    "    h1_1_data = clone_and_new_computation_graph(original_test_data)\n",
    "    h1_1_targets = clone_and_new_computation_graph(original_test_targets, requires_grad=False)\n",
    "    h1_1_targets[:] = 1\n",
    "    \n",
    "    h1_1_data_for_true_targets = clone_and_new_computation_graph(original_test_data)\n",
    "    h1_1_true_targets = clone_and_new_computation_graph(original_test_targets, requires_grad=False)\n",
    "    \n",
    "    h1_data = torch.cat((h1_0_data, h1_1_data), 0)\n",
    "    h1_targets = torch.cat((h1_0_targets, h1_1_targets), 0)\n",
    "    \n",
    "    h1_set = SimpleDataSet(h1_data, h1_targets)\n",
    "    \n",
    "    h1_data_true = torch.cat((h1_0_data_for_true_targets, h1_1_data_for_true_targets), 0)\n",
    "    h1_targets_true = torch.cat((h1_0_true_targets, h1_1_true_targets), 0)\n",
    "    \n",
    "    h1_set_with_true_targets = SimpleDataSet(h1_data_true, h1_targets_true)\n",
    "    \n",
    "\n",
    "    return h0_set, h1_set, h1_set_with_true_targets, k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "bbf0a781-c9cd-4d00-a8b3-05641b8e7a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "def run_discovery(training_set, test_set, score_model, auto_econder: Optional[torch.nn.Module]=None, alpha=0.1):\n",
    "    print(\"--------- Discovery Started ---------\")\n",
    "    \n",
    "    train_autoencoder(auto_econder, training_set) if auto_econder is not None else 0 \n",
    "        \n",
    "    # Split the train set to concat with the test set (creating the mixed set for discovery)\n",
    "    h0_set, h1_set, h1_set_with_true_targets, k = get_synthetic_h0_h1(training_set, test_set)\n",
    "    print(F\"Training set size: {len(training_set)}, Test set size: {len(test_set)}\")\n",
    "    print(F\"Selected K: {k}, h0 size: {len(h0_set)} , h1 size: {len(h1_set)}\")\n",
    "    h0h1_set = ConcatDataset(h0_set,h1_set)\n",
    "    h0h1_loader = DataLoader(h0h1_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    # train_loader = DataLoader(training_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    # test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    # Training...\n",
    "    # train_model(score_model, h0h1_loader, None)\n",
    "    \n",
    "    # Got a trained model, let's get the scores\n",
    "    with torch.no_grad():\n",
    "        score_model.eval()\n",
    "        _, probability_scores = score_model(h1_set.data.to(DEVICE)) # probability scores is a tensor of pairs (p(0), p(1)).\n",
    "    probability_of_discovery = probability_scores[:,1].numpy() # We only care about the probability of a discovery (p(1))\n",
    "\n",
    "    # Use BoNuS and Knockoff counting for stating discoveries while keeping FDR\n",
    "    l = len(training_set)-k # This is the length of the \"2nd part\" of the null samples, which will be concatenated to the test sample\n",
    "    m = len(test_set)\n",
    "    \n",
    "    scores_df = pd.DataFrame({'score': probability_of_discovery, 'is_test': np.concatenate((np.repeat(0, l),np.repeat(1,m))),'truth':h1_set_with_true_targets.targets.numpy()})\n",
    "    scores_df.sort_values(by=['score'], inplace=True, ascending=True)\n",
    "    \n",
    "    fdp = 10 # a value which is definitely bigger than alpha\n",
    "    \n",
    "    for lower_bound in range(len(h1_set)):\n",
    "        scores_window_df = scores_df[lower_bound:] # get the subset of the samples we want to test with.\n",
    "        ktest = len(scores_window_df[scores_window_df['is_test']==1]) # This is the \"moving\" k, which changes as we move the lower score bound.\n",
    "        v = len(scores_window_df[scores_window_df['is_test']==0]) # The count of false discoveries that we know of (i.e., training samples)\n",
    "        fdp = ((v+1) / (l+1)) * (m / ktest)\n",
    "        print(F\"ktest: {ktest},\\t\"\n",
    "              F\"v: {v},\\t\"\n",
    "              F\"m: {m},\\t\"\n",
    "              F\"l: {l},\\t\"\n",
    "              F\"fdp: {fdp}\")\n",
    "\n",
    "        if fdp<=alpha:\n",
    "            print(F\"Got FDP of {fdp} <= alpha({alpha}) , for lower bound: {lower_bound}\")\n",
    "            break;\n",
    "    \n",
    "    total_elements = len(scores_window_df)\n",
    "    total_discoveries = ktest\n",
    "    false_discoveries = len(scores_window_df[(scores_window_df['is_test']==1) & (scores_window_df['truth']==0)])\n",
    "    print(F\"Total elements in window: {total_elements}\")\n",
    "    print(F\"Total discoveries in window: {ktest}\")\n",
    "    print(F\"False discoveries: {false_discoveries}\")\n",
    "    \n",
    "    return dict(total_elements=total_elements, total_discoveries=total_discoveries, false_discoveries=false_discoveries)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "d6e556c7-9a5d-4d26-bba3-64222e4a204d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datasets_for_discovery(add_noise=False) -> tuple[SimpleDataSet, SimpleDataSet]:\n",
    "    '''\n",
    "    Returns:\n",
    "        A Tuple of (Training dataset, Test dataset)\n",
    "            Dataset.data: 4-D tensor (batch size, channels, width, height). This is because nn.Conv2d expects input of this shape.\n",
    "            Dataset.targets: 1-D tensor (target class)\n",
    "    '''\n",
    "    \n",
    "    image_padding_to_32 = transforms.Compose([transforms.Resize((32,32)), transforms.ToTensor()])\n",
    "    \n",
    "    if add_noise:\n",
    "        raise NotImplementedError(\"adding noise was not yet implemented\")\n",
    "        \n",
    "    # Get data of 4, then set the targets as \"0\" (as this is our \"null\" class).\n",
    "    training_set_full = datasets.MNIST(root='./data', download=True, transform=image_padding_to_32, train=True)\n",
    "    training_four_index = (training_set_full.targets == 4).nonzero().reshape(-1)\n",
    "    train_four_loader = torch.utils.data.DataLoader(dataset=training_set_full, batch_size=len(training_four_index), shuffle=False, sampler=Data.SubsetRandomSampler(training_four_index))\n",
    "    train_four_data, train_four_targets = next(iter(train_four_loader)) # We only need one iteration, as the loader has the size of the entire relevant sample\n",
    "    \n",
    "    assert len(train_four_targets[(train_four_targets!=4).nonzero().reshape(-1)])==0 # Avoid bugs in data loading. You're welcome hahaha\n",
    "    train_four_targets[(train_four_targets==4).nonzero().reshape(-1)] = 0\n",
    "    \n",
    "    \n",
    "    training_set = SimpleDataSet(train_four_data, train_four_targets)\n",
    "    \n",
    "    test_set_full = datasets.MNIST(root='./data', download=True, transform=image_padding_to_32, train=False)\n",
    "    # test_four_index = torch.logical_or(test_set_full.targets == 4, test_set_full.targets == 9).nonzero().reshape(-1)\n",
    "    test_four_index = (test_set_full.targets == 9).nonzero().reshape(-1)\n",
    "    test_four_loader = torch.utils.data.DataLoader(dataset=test_set_full, batch_size=len(test_four_index), shuffle=False, sampler=Data.SubsetRandomSampler(test_four_index))\n",
    "    test_four_data, test_four_targets = next(iter(test_four_loader))\n",
    "    test_four_targets[(test_four_targets==4).nonzero().reshape(-1)] = 0\n",
    "    test_four_targets[(test_four_targets==9).nonzero().reshape(-1)] = 1\n",
    "    test_set = SimpleDataSet(test_four_data, test_four_targets)\n",
    "    \n",
    "    return training_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "295b1d85-5d39-4fe1-8801-d2cbad527a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- Discovery Started ---------\n",
      "Training set size: 5842, Test set size: 1009\n",
      "Selected K: 4833, h0 size: 4833 , h1 size: 2018\n",
      "ktest: 1009,\tv: 1009,\tm: 1009,\tl: 1009,\tfdp: 1.0\n",
      "ktest: 1009,\tv: 1008,\tm: 1009,\tl: 1009,\tfdp: 0.999009900990099\n",
      "ktest: 1009,\tv: 1007,\tm: 1009,\tl: 1009,\tfdp: 0.998019801980198\n",
      "ktest: 1009,\tv: 1006,\tm: 1009,\tl: 1009,\tfdp: 0.997029702970297\n",
      "ktest: 1009,\tv: 1005,\tm: 1009,\tl: 1009,\tfdp: 0.996039603960396\n",
      "ktest: 1009,\tv: 1004,\tm: 1009,\tl: 1009,\tfdp: 0.995049504950495\n",
      "ktest: 1009,\tv: 1003,\tm: 1009,\tl: 1009,\tfdp: 0.994059405940594\n",
      "ktest: 1009,\tv: 1002,\tm: 1009,\tl: 1009,\tfdp: 0.9930693069306931\n",
      "ktest: 1009,\tv: 1001,\tm: 1009,\tl: 1009,\tfdp: 0.9920792079207921\n",
      "ktest: 1009,\tv: 1000,\tm: 1009,\tl: 1009,\tfdp: 0.9910891089108911\n",
      "ktest: 1009,\tv: 999,\tm: 1009,\tl: 1009,\tfdp: 0.9900990099009901\n",
      "ktest: 1009,\tv: 998,\tm: 1009,\tl: 1009,\tfdp: 0.9891089108910891\n",
      "ktest: 1009,\tv: 997,\tm: 1009,\tl: 1009,\tfdp: 0.9881188118811881\n",
      "ktest: 1009,\tv: 996,\tm: 1009,\tl: 1009,\tfdp: 0.9871287128712871\n",
      "ktest: 1009,\tv: 995,\tm: 1009,\tl: 1009,\tfdp: 0.9861386138613861\n",
      "ktest: 1009,\tv: 994,\tm: 1009,\tl: 1009,\tfdp: 0.9851485148514851\n",
      "ktest: 1009,\tv: 993,\tm: 1009,\tl: 1009,\tfdp: 0.9841584158415841\n",
      "ktest: 1009,\tv: 992,\tm: 1009,\tl: 1009,\tfdp: 0.9831683168316832\n",
      "ktest: 1009,\tv: 991,\tm: 1009,\tl: 1009,\tfdp: 0.9821782178217822\n",
      "ktest: 1009,\tv: 990,\tm: 1009,\tl: 1009,\tfdp: 0.9811881188118812\n",
      "ktest: 1009,\tv: 989,\tm: 1009,\tl: 1009,\tfdp: 0.9801980198019802\n",
      "ktest: 1009,\tv: 988,\tm: 1009,\tl: 1009,\tfdp: 0.9792079207920792\n",
      "ktest: 1009,\tv: 987,\tm: 1009,\tl: 1009,\tfdp: 0.9782178217821782\n",
      "ktest: 1009,\tv: 986,\tm: 1009,\tl: 1009,\tfdp: 0.9772277227722772\n",
      "ktest: 1009,\tv: 985,\tm: 1009,\tl: 1009,\tfdp: 0.9762376237623762\n",
      "ktest: 1009,\tv: 984,\tm: 1009,\tl: 1009,\tfdp: 0.9752475247524752\n",
      "ktest: 1009,\tv: 983,\tm: 1009,\tl: 1009,\tfdp: 0.9742574257425742\n",
      "ktest: 1009,\tv: 982,\tm: 1009,\tl: 1009,\tfdp: 0.9732673267326732\n",
      "ktest: 1009,\tv: 981,\tm: 1009,\tl: 1009,\tfdp: 0.9722772277227723\n",
      "ktest: 1009,\tv: 980,\tm: 1009,\tl: 1009,\tfdp: 0.9712871287128713\n",
      "ktest: 1009,\tv: 979,\tm: 1009,\tl: 1009,\tfdp: 0.9702970297029703\n",
      "ktest: 1009,\tv: 978,\tm: 1009,\tl: 1009,\tfdp: 0.9693069306930693\n",
      "ktest: 1008,\tv: 978,\tm: 1009,\tl: 1009,\tfdp: 0.970268544711614\n",
      "ktest: 1008,\tv: 977,\tm: 1009,\tl: 1009,\tfdp: 0.9692774634606317\n",
      "ktest: 1008,\tv: 976,\tm: 1009,\tl: 1009,\tfdp: 0.9682863822096495\n",
      "ktest: 1008,\tv: 975,\tm: 1009,\tl: 1009,\tfdp: 0.9672953009586672\n",
      "ktest: 1008,\tv: 974,\tm: 1009,\tl: 1009,\tfdp: 0.966304219707685\n",
      "ktest: 1008,\tv: 973,\tm: 1009,\tl: 1009,\tfdp: 0.9653131384567027\n",
      "ktest: 1008,\tv: 972,\tm: 1009,\tl: 1009,\tfdp: 0.9643220572057205\n",
      "ktest: 1008,\tv: 971,\tm: 1009,\tl: 1009,\tfdp: 0.9633309759547383\n",
      "ktest: 1008,\tv: 970,\tm: 1009,\tl: 1009,\tfdp: 0.962339894703756\n",
      "ktest: 1008,\tv: 969,\tm: 1009,\tl: 1009,\tfdp: 0.9613488134527738\n",
      "ktest: 1008,\tv: 968,\tm: 1009,\tl: 1009,\tfdp: 0.9603577322017915\n",
      "ktest: 1008,\tv: 967,\tm: 1009,\tl: 1009,\tfdp: 0.9593666509508093\n",
      "ktest: 1008,\tv: 966,\tm: 1009,\tl: 1009,\tfdp: 0.9583755696998271\n",
      "ktest: 1008,\tv: 965,\tm: 1009,\tl: 1009,\tfdp: 0.9573844884488448\n",
      "ktest: 1008,\tv: 964,\tm: 1009,\tl: 1009,\tfdp: 0.9563934071978626\n",
      "ktest: 1008,\tv: 963,\tm: 1009,\tl: 1009,\tfdp: 0.9554023259468803\n",
      "ktest: 1008,\tv: 962,\tm: 1009,\tl: 1009,\tfdp: 0.9544112446958981\n",
      "ktest: 1008,\tv: 961,\tm: 1009,\tl: 1009,\tfdp: 0.9534201634449159\n",
      "ktest: 1008,\tv: 960,\tm: 1009,\tl: 1009,\tfdp: 0.9524290821939336\n",
      "ktest: 1008,\tv: 959,\tm: 1009,\tl: 1009,\tfdp: 0.9514380009429514\n",
      "ktest: 1008,\tv: 958,\tm: 1009,\tl: 1009,\tfdp: 0.9504469196919691\n",
      "ktest: 1008,\tv: 957,\tm: 1009,\tl: 1009,\tfdp: 0.9494558384409869\n",
      "ktest: 1008,\tv: 956,\tm: 1009,\tl: 1009,\tfdp: 0.9484647571900047\n",
      "ktest: 1008,\tv: 955,\tm: 1009,\tl: 1009,\tfdp: 0.9474736759390224\n",
      "ktest: 1008,\tv: 954,\tm: 1009,\tl: 1009,\tfdp: 0.9464825946880402\n",
      "ktest: 1008,\tv: 953,\tm: 1009,\tl: 1009,\tfdp: 0.945491513437058\n",
      "ktest: 1008,\tv: 952,\tm: 1009,\tl: 1009,\tfdp: 0.9445004321860757\n",
      "ktest: 1008,\tv: 951,\tm: 1009,\tl: 1009,\tfdp: 0.9435093509350935\n",
      "ktest: 1008,\tv: 950,\tm: 1009,\tl: 1009,\tfdp: 0.9425182696841112\n",
      "ktest: 1008,\tv: 949,\tm: 1009,\tl: 1009,\tfdp: 0.941527188433129\n",
      "ktest: 1008,\tv: 948,\tm: 1009,\tl: 1009,\tfdp: 0.9405361071821468\n",
      "ktest: 1008,\tv: 947,\tm: 1009,\tl: 1009,\tfdp: 0.9395450259311645\n",
      "ktest: 1008,\tv: 946,\tm: 1009,\tl: 1009,\tfdp: 0.9385539446801823\n",
      "ktest: 1008,\tv: 945,\tm: 1009,\tl: 1009,\tfdp: 0.9375628634292001\n",
      "ktest: 1008,\tv: 944,\tm: 1009,\tl: 1009,\tfdp: 0.9365717821782179\n",
      "ktest: 1008,\tv: 943,\tm: 1009,\tl: 1009,\tfdp: 0.9355807009272357\n",
      "ktest: 1008,\tv: 942,\tm: 1009,\tl: 1009,\tfdp: 0.9345896196762534\n",
      "ktest: 1008,\tv: 941,\tm: 1009,\tl: 1009,\tfdp: 0.9335985384252712\n",
      "ktest: 1008,\tv: 940,\tm: 1009,\tl: 1009,\tfdp: 0.932607457174289\n",
      "ktest: 1008,\tv: 939,\tm: 1009,\tl: 1009,\tfdp: 0.9316163759233067\n",
      "ktest: 1008,\tv: 938,\tm: 1009,\tl: 1009,\tfdp: 0.9306252946723245\n",
      "ktest: 1008,\tv: 937,\tm: 1009,\tl: 1009,\tfdp: 0.9296342134213422\n",
      "ktest: 1008,\tv: 936,\tm: 1009,\tl: 1009,\tfdp: 0.92864313217036\n",
      "ktest: 1008,\tv: 935,\tm: 1009,\tl: 1009,\tfdp: 0.9276520509193777\n",
      "ktest: 1008,\tv: 934,\tm: 1009,\tl: 1009,\tfdp: 0.9266609696683955\n",
      "ktest: 1008,\tv: 933,\tm: 1009,\tl: 1009,\tfdp: 0.9256698884174132\n",
      "ktest: 1008,\tv: 932,\tm: 1009,\tl: 1009,\tfdp: 0.9246788071664309\n",
      "ktest: 1008,\tv: 931,\tm: 1009,\tl: 1009,\tfdp: 0.9236877259154487\n",
      "ktest: 1008,\tv: 930,\tm: 1009,\tl: 1009,\tfdp: 0.9226966446644664\n",
      "ktest: 1008,\tv: 929,\tm: 1009,\tl: 1009,\tfdp: 0.9217055634134842\n",
      "ktest: 1008,\tv: 928,\tm: 1009,\tl: 1009,\tfdp: 0.920714482162502\n",
      "ktest: 1008,\tv: 927,\tm: 1009,\tl: 1009,\tfdp: 0.9197234009115197\n",
      "ktest: 1008,\tv: 926,\tm: 1009,\tl: 1009,\tfdp: 0.9187323196605375\n",
      "ktest: 1008,\tv: 925,\tm: 1009,\tl: 1009,\tfdp: 0.9177412384095552\n",
      "ktest: 1008,\tv: 924,\tm: 1009,\tl: 1009,\tfdp: 0.916750157158573\n",
      "ktest: 1008,\tv: 923,\tm: 1009,\tl: 1009,\tfdp: 0.9157590759075908\n",
      "ktest: 1008,\tv: 922,\tm: 1009,\tl: 1009,\tfdp: 0.9147679946566085\n",
      "ktest: 1008,\tv: 921,\tm: 1009,\tl: 1009,\tfdp: 0.9137769134056263\n",
      "ktest: 1007,\tv: 921,\tm: 1009,\tl: 1009,\tfdp: 0.9146843383444602\n",
      "ktest: 1007,\tv: 920,\tm: 1009,\tl: 1009,\tfdp: 0.9136922729015703\n",
      "ktest: 1007,\tv: 919,\tm: 1009,\tl: 1009,\tfdp: 0.9127002074586804\n",
      "ktest: 1007,\tv: 918,\tm: 1009,\tl: 1009,\tfdp: 0.9117081420157905\n",
      "ktest: 1007,\tv: 917,\tm: 1009,\tl: 1009,\tfdp: 0.9107160765729007\n",
      "ktest: 1007,\tv: 916,\tm: 1009,\tl: 1009,\tfdp: 0.9097240111300108\n",
      "ktest: 1007,\tv: 915,\tm: 1009,\tl: 1009,\tfdp: 0.9087319456871209\n",
      "ktest: 1007,\tv: 914,\tm: 1009,\tl: 1009,\tfdp: 0.907739880244231\n",
      "ktest: 1007,\tv: 913,\tm: 1009,\tl: 1009,\tfdp: 0.9067478148013411\n",
      "ktest: 1007,\tv: 912,\tm: 1009,\tl: 1009,\tfdp: 0.9057557493584513\n",
      "ktest: 1007,\tv: 911,\tm: 1009,\tl: 1009,\tfdp: 0.9047636839155614\n",
      "ktest: 1007,\tv: 910,\tm: 1009,\tl: 1009,\tfdp: 0.9037716184726715\n",
      "ktest: 1006,\tv: 910,\tm: 1009,\tl: 1009,\tfdp: 0.9046699998031613\n",
      "ktest: 1006,\tv: 909,\tm: 1009,\tl: 1009,\tfdp: 0.9036769482117198\n",
      "ktest: 1006,\tv: 908,\tm: 1009,\tl: 1009,\tfdp: 0.9026838966202785\n",
      "ktest: 1006,\tv: 907,\tm: 1009,\tl: 1009,\tfdp: 0.901690845028837\n",
      "ktest: 1006,\tv: 906,\tm: 1009,\tl: 1009,\tfdp: 0.9006977934373955\n",
      "ktest: 1006,\tv: 905,\tm: 1009,\tl: 1009,\tfdp: 0.8997047418459541\n",
      "ktest: 1005,\tv: 905,\tm: 1009,\tl: 1009,\tfdp: 0.9005999704448056\n",
      "ktest: 1005,\tv: 904,\tm: 1009,\tl: 1009,\tfdp: 0.8996059307423279\n",
      "ktest: 1005,\tv: 903,\tm: 1009,\tl: 1009,\tfdp: 0.8986118910398502\n",
      "ktest: 1005,\tv: 902,\tm: 1009,\tl: 1009,\tfdp: 0.8976178513373725\n",
      "ktest: 1005,\tv: 901,\tm: 1009,\tl: 1009,\tfdp: 0.8966238116348948\n",
      "ktest: 1005,\tv: 900,\tm: 1009,\tl: 1009,\tfdp: 0.895629771932417\n",
      "ktest: 1005,\tv: 899,\tm: 1009,\tl: 1009,\tfdp: 0.8946357322299393\n",
      "ktest: 1005,\tv: 898,\tm: 1009,\tl: 1009,\tfdp: 0.8936416925274616\n",
      "ktest: 1005,\tv: 897,\tm: 1009,\tl: 1009,\tfdp: 0.8926476528249839\n",
      "ktest: 1005,\tv: 896,\tm: 1009,\tl: 1009,\tfdp: 0.8916536131225062\n",
      "ktest: 1004,\tv: 896,\tm: 1009,\tl: 1009,\tfdp: 0.8925417143307957\n",
      "ktest: 1004,\tv: 895,\tm: 1009,\tl: 1009,\tfdp: 0.8915466845489329\n",
      "ktest: 1004,\tv: 894,\tm: 1009,\tl: 1009,\tfdp: 0.8905516547670703\n",
      "ktest: 1004,\tv: 893,\tm: 1009,\tl: 1009,\tfdp: 0.8895566249852077\n",
      "ktest: 1004,\tv: 892,\tm: 1009,\tl: 1009,\tfdp: 0.888561595203345\n",
      "ktest: 1004,\tv: 891,\tm: 1009,\tl: 1009,\tfdp: 0.8875665654214824\n",
      "ktest: 1004,\tv: 890,\tm: 1009,\tl: 1009,\tfdp: 0.8865715356396198\n",
      "ktest: 1004,\tv: 889,\tm: 1009,\tl: 1009,\tfdp: 0.885576505857757\n",
      "ktest: 1004,\tv: 888,\tm: 1009,\tl: 1009,\tfdp: 0.8845814760758944\n",
      "ktest: 1004,\tv: 887,\tm: 1009,\tl: 1009,\tfdp: 0.8835864462940318\n",
      "ktest: 1004,\tv: 886,\tm: 1009,\tl: 1009,\tfdp: 0.8825914165121691\n",
      "ktest: 1004,\tv: 885,\tm: 1009,\tl: 1009,\tfdp: 0.8815963867303065\n",
      "ktest: 1004,\tv: 884,\tm: 1009,\tl: 1009,\tfdp: 0.8806013569484439\n",
      "ktest: 1004,\tv: 883,\tm: 1009,\tl: 1009,\tfdp: 0.8796063271665812\n",
      "ktest: 1004,\tv: 882,\tm: 1009,\tl: 1009,\tfdp: 0.8786112973847185\n",
      "ktest: 1004,\tv: 881,\tm: 1009,\tl: 1009,\tfdp: 0.8776162676028559\n",
      "ktest: 1004,\tv: 880,\tm: 1009,\tl: 1009,\tfdp: 0.8766212378209932\n",
      "ktest: 1004,\tv: 879,\tm: 1009,\tl: 1009,\tfdp: 0.8756262080391306\n",
      "ktest: 1004,\tv: 878,\tm: 1009,\tl: 1009,\tfdp: 0.874631178257268\n",
      "ktest: 1004,\tv: 877,\tm: 1009,\tl: 1009,\tfdp: 0.8736361484754053\n",
      "ktest: 1004,\tv: 876,\tm: 1009,\tl: 1009,\tfdp: 0.8726411186935427\n",
      "ktest: 1004,\tv: 875,\tm: 1009,\tl: 1009,\tfdp: 0.87164608891168\n",
      "ktest: 1004,\tv: 874,\tm: 1009,\tl: 1009,\tfdp: 0.8706510591298173\n",
      "ktest: 1004,\tv: 873,\tm: 1009,\tl: 1009,\tfdp: 0.8696560293479547\n",
      "ktest: 1004,\tv: 872,\tm: 1009,\tl: 1009,\tfdp: 0.8686609995660921\n",
      "ktest: 1004,\tv: 871,\tm: 1009,\tl: 1009,\tfdp: 0.8676659697842294\n",
      "ktest: 1004,\tv: 870,\tm: 1009,\tl: 1009,\tfdp: 0.8666709400023668\n",
      "ktest: 1004,\tv: 869,\tm: 1009,\tl: 1009,\tfdp: 0.865675910220504\n",
      "ktest: 1004,\tv: 868,\tm: 1009,\tl: 1009,\tfdp: 0.8646808804386414\n",
      "ktest: 1004,\tv: 867,\tm: 1009,\tl: 1009,\tfdp: 0.8636858506567788\n",
      "ktest: 1004,\tv: 866,\tm: 1009,\tl: 1009,\tfdp: 0.8626908208749161\n",
      "ktest: 1004,\tv: 865,\tm: 1009,\tl: 1009,\tfdp: 0.8616957910930535\n",
      "ktest: 1003,\tv: 865,\tm: 1009,\tl: 1009,\tfdp: 0.8625549095288392\n",
      "ktest: 1003,\tv: 864,\tm: 1009,\tl: 1009,\tfdp: 0.8615588876933555\n",
      "ktest: 1003,\tv: 863,\tm: 1009,\tl: 1009,\tfdp: 0.8605628658578719\n",
      "ktest: 1003,\tv: 862,\tm: 1009,\tl: 1009,\tfdp: 0.8595668440223883\n",
      "ktest: 1003,\tv: 861,\tm: 1009,\tl: 1009,\tfdp: 0.8585708221869046\n",
      "ktest: 1003,\tv: 860,\tm: 1009,\tl: 1009,\tfdp: 0.8575748003514209\n",
      "ktest: 1002,\tv: 860,\tm: 1009,\tl: 1009,\tfdp: 0.858430663425624\n",
      "ktest: 1002,\tv: 859,\tm: 1009,\tl: 1009,\tfdp: 0.8574336475563724\n",
      "ktest: 1002,\tv: 858,\tm: 1009,\tl: 1009,\tfdp: 0.8564366316871208\n",
      "ktest: 1002,\tv: 857,\tm: 1009,\tl: 1009,\tfdp: 0.8554396158178692\n",
      "ktest: 1002,\tv: 856,\tm: 1009,\tl: 1009,\tfdp: 0.8544425999486177\n",
      "ktest: 1002,\tv: 855,\tm: 1009,\tl: 1009,\tfdp: 0.8534455840793661\n",
      "ktest: 1002,\tv: 854,\tm: 1009,\tl: 1009,\tfdp: 0.8524485682101145\n",
      "ktest: 1002,\tv: 853,\tm: 1009,\tl: 1009,\tfdp: 0.8514515523408629\n",
      "ktest: 1002,\tv: 852,\tm: 1009,\tl: 1009,\tfdp: 0.8504545364716113\n",
      "ktest: 1002,\tv: 851,\tm: 1009,\tl: 1009,\tfdp: 0.8494575206023597\n",
      "ktest: 1002,\tv: 850,\tm: 1009,\tl: 1009,\tfdp: 0.8484605047331081\n",
      "ktest: 1002,\tv: 849,\tm: 1009,\tl: 1009,\tfdp: 0.8474634888638565\n",
      "ktest: 1002,\tv: 848,\tm: 1009,\tl: 1009,\tfdp: 0.8464664729946049\n",
      "ktest: 1002,\tv: 847,\tm: 1009,\tl: 1009,\tfdp: 0.8454694571253533\n",
      "ktest: 1002,\tv: 846,\tm: 1009,\tl: 1009,\tfdp: 0.8444724412561017\n",
      "ktest: 1002,\tv: 845,\tm: 1009,\tl: 1009,\tfdp: 0.84347542538685\n",
      "ktest: 1002,\tv: 844,\tm: 1009,\tl: 1009,\tfdp: 0.8424784095175984\n",
      "ktest: 1002,\tv: 843,\tm: 1009,\tl: 1009,\tfdp: 0.8414813936483468\n",
      "ktest: 1002,\tv: 842,\tm: 1009,\tl: 1009,\tfdp: 0.8404843777790953\n",
      "ktest: 1002,\tv: 841,\tm: 1009,\tl: 1009,\tfdp: 0.8394873619098437\n",
      "ktest: 1002,\tv: 840,\tm: 1009,\tl: 1009,\tfdp: 0.8384903460405921\n",
      "ktest: 1002,\tv: 839,\tm: 1009,\tl: 1009,\tfdp: 0.8374933301713405\n",
      "ktest: 1002,\tv: 838,\tm: 1009,\tl: 1009,\tfdp: 0.8364963143020889\n",
      "ktest: 1002,\tv: 837,\tm: 1009,\tl: 1009,\tfdp: 0.8354992984328373\n",
      "ktest: 1002,\tv: 836,\tm: 1009,\tl: 1009,\tfdp: 0.8345022825635857\n",
      "ktest: 1002,\tv: 835,\tm: 1009,\tl: 1009,\tfdp: 0.8335052666943341\n",
      "ktest: 1002,\tv: 834,\tm: 1009,\tl: 1009,\tfdp: 0.8325082508250825\n",
      "ktest: 1002,\tv: 833,\tm: 1009,\tl: 1009,\tfdp: 0.8315112349558309\n",
      "ktest: 1002,\tv: 832,\tm: 1009,\tl: 1009,\tfdp: 0.8305142190865793\n",
      "ktest: 1002,\tv: 831,\tm: 1009,\tl: 1009,\tfdp: 0.8295172032173277\n",
      "ktest: 1002,\tv: 830,\tm: 1009,\tl: 1009,\tfdp: 0.8285201873480761\n",
      "ktest: 1002,\tv: 829,\tm: 1009,\tl: 1009,\tfdp: 0.8275231714788246\n",
      "ktest: 1002,\tv: 828,\tm: 1009,\tl: 1009,\tfdp: 0.826526155609573\n",
      "ktest: 1002,\tv: 827,\tm: 1009,\tl: 1009,\tfdp: 0.8255291397403214\n",
      "ktest: 1002,\tv: 826,\tm: 1009,\tl: 1009,\tfdp: 0.8245321238710698\n",
      "ktest: 1002,\tv: 825,\tm: 1009,\tl: 1009,\tfdp: 0.8235351080018182\n",
      "ktest: 1001,\tv: 825,\tm: 1009,\tl: 1009,\tfdp: 0.8243578203974242\n",
      "ktest: 1001,\tv: 824,\tm: 1009,\tl: 1009,\tfdp: 0.8233598085083232\n",
      "ktest: 1001,\tv: 823,\tm: 1009,\tl: 1009,\tfdp: 0.8223617966192223\n",
      "ktest: 1001,\tv: 822,\tm: 1009,\tl: 1009,\tfdp: 0.8213637847301213\n",
      "ktest: 1001,\tv: 821,\tm: 1009,\tl: 1009,\tfdp: 0.8203657728410203\n",
      "ktest: 1001,\tv: 820,\tm: 1009,\tl: 1009,\tfdp: 0.8193677609519193\n",
      "ktest: 1001,\tv: 819,\tm: 1009,\tl: 1009,\tfdp: 0.8183697490628183\n",
      "ktest: 1001,\tv: 818,\tm: 1009,\tl: 1009,\tfdp: 0.8173717371737174\n",
      "ktest: 1001,\tv: 817,\tm: 1009,\tl: 1009,\tfdp: 0.8163737252846164\n",
      "ktest: 1001,\tv: 816,\tm: 1009,\tl: 1009,\tfdp: 0.8153757133955154\n",
      "ktest: 1001,\tv: 815,\tm: 1009,\tl: 1009,\tfdp: 0.8143777015064144\n",
      "ktest: 1001,\tv: 814,\tm: 1009,\tl: 1009,\tfdp: 0.8133796896173134\n",
      "ktest: 1001,\tv: 813,\tm: 1009,\tl: 1009,\tfdp: 0.8123816777282123\n",
      "ktest: 1001,\tv: 812,\tm: 1009,\tl: 1009,\tfdp: 0.8113836658391114\n",
      "ktest: 1001,\tv: 811,\tm: 1009,\tl: 1009,\tfdp: 0.8103856539500104\n",
      "ktest: 1001,\tv: 810,\tm: 1009,\tl: 1009,\tfdp: 0.8093876420609094\n",
      "ktest: 1001,\tv: 809,\tm: 1009,\tl: 1009,\tfdp: 0.8083896301718084\n",
      "ktest: 1001,\tv: 808,\tm: 1009,\tl: 1009,\tfdp: 0.8073916182827074\n",
      "ktest: 1001,\tv: 807,\tm: 1009,\tl: 1009,\tfdp: 0.8063936063936064\n",
      "ktest: 1001,\tv: 806,\tm: 1009,\tl: 1009,\tfdp: 0.8053955945045054\n",
      "ktest: 1001,\tv: 805,\tm: 1009,\tl: 1009,\tfdp: 0.8043975826154044\n",
      "ktest: 1001,\tv: 804,\tm: 1009,\tl: 1009,\tfdp: 0.8033995707263034\n",
      "ktest: 1001,\tv: 803,\tm: 1009,\tl: 1009,\tfdp: 0.8024015588372024\n",
      "ktest: 1001,\tv: 802,\tm: 1009,\tl: 1009,\tfdp: 0.8014035469481015\n",
      "ktest: 1001,\tv: 801,\tm: 1009,\tl: 1009,\tfdp: 0.8004055350590004\n",
      "ktest: 1001,\tv: 800,\tm: 1009,\tl: 1009,\tfdp: 0.7994075231698994\n",
      "ktest: 1001,\tv: 799,\tm: 1009,\tl: 1009,\tfdp: 0.7984095112807984\n",
      "ktest: 1001,\tv: 798,\tm: 1009,\tl: 1009,\tfdp: 0.7974114993916974\n",
      "ktest: 1001,\tv: 797,\tm: 1009,\tl: 1009,\tfdp: 0.7964134875025964\n",
      "ktest: 1001,\tv: 796,\tm: 1009,\tl: 1009,\tfdp: 0.7954154756134955\n",
      "ktest: 1001,\tv: 795,\tm: 1009,\tl: 1009,\tfdp: 0.7944174637243944\n",
      "ktest: 1001,\tv: 794,\tm: 1009,\tl: 1009,\tfdp: 0.7934194518352934\n",
      "ktest: 1000,\tv: 794,\tm: 1009,\tl: 1009,\tfdp: 0.7942128712871287\n",
      "ktest: 1000,\tv: 793,\tm: 1009,\tl: 1009,\tfdp: 0.7932138613861386\n",
      "ktest: 1000,\tv: 792,\tm: 1009,\tl: 1009,\tfdp: 0.7922148514851485\n",
      "ktest: 1000,\tv: 791,\tm: 1009,\tl: 1009,\tfdp: 0.7912158415841584\n",
      "ktest: 1000,\tv: 790,\tm: 1009,\tl: 1009,\tfdp: 0.7902168316831683\n",
      "ktest: 1000,\tv: 789,\tm: 1009,\tl: 1009,\tfdp: 0.7892178217821781\n",
      "ktest: 1000,\tv: 788,\tm: 1009,\tl: 1009,\tfdp: 0.788218811881188\n",
      "ktest: 1000,\tv: 787,\tm: 1009,\tl: 1009,\tfdp: 0.7872198019801979\n",
      "ktest: 1000,\tv: 786,\tm: 1009,\tl: 1009,\tfdp: 0.7862207920792079\n",
      "ktest: 1000,\tv: 785,\tm: 1009,\tl: 1009,\tfdp: 0.7852217821782178\n",
      "ktest: 999,\tv: 785,\tm: 1009,\tl: 1009,\tfdp: 0.786007789968186\n",
      "ktest: 999,\tv: 784,\tm: 1009,\tl: 1009,\tfdp: 0.785007780057285\n",
      "ktest: 999,\tv: 783,\tm: 1009,\tl: 1009,\tfdp: 0.784007770146384\n",
      "ktest: 999,\tv: 782,\tm: 1009,\tl: 1009,\tfdp: 0.783007760235483\n",
      "ktest: 999,\tv: 781,\tm: 1009,\tl: 1009,\tfdp: 0.782007750324582\n",
      "ktest: 999,\tv: 780,\tm: 1009,\tl: 1009,\tfdp: 0.781007740413681\n",
      "ktest: 999,\tv: 779,\tm: 1009,\tl: 1009,\tfdp: 0.78000773050278\n",
      "ktest: 999,\tv: 778,\tm: 1009,\tl: 1009,\tfdp: 0.7790077205918791\n",
      "ktest: 999,\tv: 777,\tm: 1009,\tl: 1009,\tfdp: 0.7780077106809781\n",
      "ktest: 999,\tv: 776,\tm: 1009,\tl: 1009,\tfdp: 0.777007700770077\n",
      "ktest: 999,\tv: 775,\tm: 1009,\tl: 1009,\tfdp: 0.776007690859176\n",
      "ktest: 999,\tv: 774,\tm: 1009,\tl: 1009,\tfdp: 0.775007680948275\n",
      "ktest: 999,\tv: 773,\tm: 1009,\tl: 1009,\tfdp: 0.774007671037374\n",
      "ktest: 999,\tv: 772,\tm: 1009,\tl: 1009,\tfdp: 0.773007661126473\n",
      "ktest: 999,\tv: 771,\tm: 1009,\tl: 1009,\tfdp: 0.772007651215572\n",
      "ktest: 999,\tv: 770,\tm: 1009,\tl: 1009,\tfdp: 0.771007641304671\n",
      "ktest: 998,\tv: 770,\tm: 1009,\tl: 1009,\tfdp: 0.7717801940514692\n",
      "ktest: 998,\tv: 769,\tm: 1009,\tl: 1009,\tfdp: 0.7707791821266294\n",
      "ktest: 998,\tv: 768,\tm: 1009,\tl: 1009,\tfdp: 0.7697781702017897\n",
      "ktest: 998,\tv: 767,\tm: 1009,\tl: 1009,\tfdp: 0.7687771582769499\n",
      "ktest: 998,\tv: 766,\tm: 1009,\tl: 1009,\tfdp: 0.7677761463521101\n",
      "ktest: 998,\tv: 765,\tm: 1009,\tl: 1009,\tfdp: 0.7667751344272704\n",
      "ktest: 998,\tv: 764,\tm: 1009,\tl: 1009,\tfdp: 0.7657741225024306\n",
      "ktest: 998,\tv: 763,\tm: 1009,\tl: 1009,\tfdp: 0.7647731105775908\n",
      "ktest: 998,\tv: 762,\tm: 1009,\tl: 1009,\tfdp: 0.763772098652751\n",
      "ktest: 998,\tv: 761,\tm: 1009,\tl: 1009,\tfdp: 0.7627710867279113\n",
      "ktest: 998,\tv: 760,\tm: 1009,\tl: 1009,\tfdp: 0.7617700748030715\n",
      "ktest: 998,\tv: 759,\tm: 1009,\tl: 1009,\tfdp: 0.7607690628782316\n",
      "ktest: 997,\tv: 759,\tm: 1009,\tl: 1009,\tfdp: 0.7615321211158227\n",
      "ktest: 997,\tv: 758,\tm: 1009,\tl: 1009,\tfdp: 0.7605301051669862\n",
      "ktest: 997,\tv: 757,\tm: 1009,\tl: 1009,\tfdp: 0.7595280892181495\n",
      "ktest: 997,\tv: 756,\tm: 1009,\tl: 1009,\tfdp: 0.7585260732693129\n",
      "ktest: 997,\tv: 755,\tm: 1009,\tl: 1009,\tfdp: 0.7575240573204762\n",
      "ktest: 996,\tv: 755,\tm: 1009,\tl: 1009,\tfdp: 0.7582846236430871\n",
      "ktest: 996,\tv: 754,\tm: 1009,\tl: 1009,\tfdp: 0.7572816016541413\n",
      "ktest: 996,\tv: 753,\tm: 1009,\tl: 1009,\tfdp: 0.7562785796651954\n",
      "ktest: 996,\tv: 752,\tm: 1009,\tl: 1009,\tfdp: 0.7552755576762495\n",
      "ktest: 996,\tv: 751,\tm: 1009,\tl: 1009,\tfdp: 0.7542725356873036\n",
      "ktest: 996,\tv: 750,\tm: 1009,\tl: 1009,\tfdp: 0.7532695136983577\n",
      "ktest: 996,\tv: 749,\tm: 1009,\tl: 1009,\tfdp: 0.7522664917094118\n",
      "ktest: 996,\tv: 748,\tm: 1009,\tl: 1009,\tfdp: 0.751263469720466\n",
      "ktest: 996,\tv: 747,\tm: 1009,\tl: 1009,\tfdp: 0.7502604477315201\n",
      "ktest: 996,\tv: 746,\tm: 1009,\tl: 1009,\tfdp: 0.7492574257425743\n",
      "ktest: 996,\tv: 745,\tm: 1009,\tl: 1009,\tfdp: 0.7482544037536283\n",
      "ktest: 996,\tv: 744,\tm: 1009,\tl: 1009,\tfdp: 0.7472513817646824\n",
      "ktest: 996,\tv: 743,\tm: 1009,\tl: 1009,\tfdp: 0.7462483597757366\n",
      "ktest: 996,\tv: 742,\tm: 1009,\tl: 1009,\tfdp: 0.7452453377867907\n",
      "ktest: 995,\tv: 742,\tm: 1009,\tl: 1009,\tfdp: 0.7459943280760236\n",
      "ktest: 995,\tv: 741,\tm: 1009,\tl: 1009,\tfdp: 0.7449902980247772\n",
      "ktest: 995,\tv: 740,\tm: 1009,\tl: 1009,\tfdp: 0.743986267973531\n",
      "ktest: 995,\tv: 739,\tm: 1009,\tl: 1009,\tfdp: 0.7429822379222846\n",
      "ktest: 995,\tv: 738,\tm: 1009,\tl: 1009,\tfdp: 0.7419782078710383\n",
      "ktest: 995,\tv: 737,\tm: 1009,\tl: 1009,\tfdp: 0.7409741778197919\n",
      "ktest: 995,\tv: 736,\tm: 1009,\tl: 1009,\tfdp: 0.7399701477685456\n",
      "ktest: 995,\tv: 735,\tm: 1009,\tl: 1009,\tfdp: 0.7389661177172993\n",
      "ktest: 995,\tv: 734,\tm: 1009,\tl: 1009,\tfdp: 0.737962087666053\n",
      "ktest: 995,\tv: 733,\tm: 1009,\tl: 1009,\tfdp: 0.7369580576148066\n",
      "ktest: 995,\tv: 732,\tm: 1009,\tl: 1009,\tfdp: 0.7359540275635603\n",
      "ktest: 994,\tv: 732,\tm: 1009,\tl: 1009,\tfdp: 0.73669442396956\n",
      "ktest: 994,\tv: 731,\tm: 1009,\tl: 1009,\tfdp: 0.7356893838277188\n",
      "ktest: 994,\tv: 730,\tm: 1009,\tl: 1009,\tfdp: 0.7346843436858776\n",
      "ktest: 994,\tv: 729,\tm: 1009,\tl: 1009,\tfdp: 0.7336793035440365\n",
      "ktest: 993,\tv: 729,\tm: 1009,\tl: 1009,\tfdp: 0.7344181548064171\n",
      "ktest: 993,\tv: 728,\tm: 1009,\tl: 1009,\tfdp: 0.7334121025395591\n",
      "ktest: 993,\tv: 727,\tm: 1009,\tl: 1009,\tfdp: 0.732406050272701\n",
      "ktest: 993,\tv: 726,\tm: 1009,\tl: 1009,\tfdp: 0.7313999980058429\n",
      "ktest: 993,\tv: 725,\tm: 1009,\tl: 1009,\tfdp: 0.7303939457389848\n",
      "ktest: 992,\tv: 725,\tm: 1009,\tl: 1009,\tfdp: 0.7311302299584796\n",
      "ktest: 992,\tv: 724,\tm: 1009,\tl: 1009,\tfdp: 0.73012316352603\n",
      "ktest: 992,\tv: 723,\tm: 1009,\tl: 1009,\tfdp: 0.7291160970935803\n",
      "ktest: 992,\tv: 722,\tm: 1009,\tl: 1009,\tfdp: 0.7281090306611305\n",
      "ktest: 992,\tv: 721,\tm: 1009,\tl: 1009,\tfdp: 0.7271019642286809\n",
      "ktest: 992,\tv: 720,\tm: 1009,\tl: 1009,\tfdp: 0.7260948977962312\n",
      "ktest: 992,\tv: 719,\tm: 1009,\tl: 1009,\tfdp: 0.7250878313637815\n",
      "ktest: 992,\tv: 718,\tm: 1009,\tl: 1009,\tfdp: 0.7240807649313318\n",
      "ktest: 992,\tv: 717,\tm: 1009,\tl: 1009,\tfdp: 0.723073698498882\n",
      "ktest: 992,\tv: 716,\tm: 1009,\tl: 1009,\tfdp: 0.7220666320664324\n",
      "ktest: 992,\tv: 715,\tm: 1009,\tl: 1009,\tfdp: 0.7210595656339827\n",
      "ktest: 992,\tv: 714,\tm: 1009,\tl: 1009,\tfdp: 0.720052499201533\n",
      "ktest: 992,\tv: 713,\tm: 1009,\tl: 1009,\tfdp: 0.7190454327690833\n",
      "ktest: 992,\tv: 712,\tm: 1009,\tl: 1009,\tfdp: 0.7180383663366335\n",
      "ktest: 992,\tv: 711,\tm: 1009,\tl: 1009,\tfdp: 0.7170312999041839\n",
      "ktest: 992,\tv: 710,\tm: 1009,\tl: 1009,\tfdp: 0.7160242334717342\n",
      "ktest: 992,\tv: 709,\tm: 1009,\tl: 1009,\tfdp: 0.7150171670392845\n",
      "ktest: 992,\tv: 708,\tm: 1009,\tl: 1009,\tfdp: 0.7140101006068348\n",
      "ktest: 991,\tv: 708,\tm: 1009,\tl: 1009,\tfdp: 0.7147305951584058\n",
      "ktest: 991,\tv: 707,\tm: 1009,\tl: 1009,\tfdp: 0.7137225125136125\n",
      "ktest: 990,\tv: 707,\tm: 1009,\tl: 1009,\tfdp: 0.7144434443444344\n",
      "ktest: 990,\tv: 706,\tm: 1009,\tl: 1009,\tfdp: 0.7134343434343434\n",
      "ktest: 990,\tv: 705,\tm: 1009,\tl: 1009,\tfdp: 0.7124252425242524\n",
      "ktest: 990,\tv: 704,\tm: 1009,\tl: 1009,\tfdp: 0.7114161416141613\n",
      "ktest: 990,\tv: 703,\tm: 1009,\tl: 1009,\tfdp: 0.7104070407040703\n",
      "ktest: 989,\tv: 703,\tm: 1009,\tl: 1009,\tfdp: 0.7111253491375426\n",
      "ktest: 989,\tv: 702,\tm: 1009,\tl: 1009,\tfdp: 0.7101152279029722\n",
      "ktest: 989,\tv: 701,\tm: 1009,\tl: 1009,\tfdp: 0.7091051066684019\n",
      "ktest: 989,\tv: 700,\tm: 1009,\tl: 1009,\tfdp: 0.7080949854338314\n",
      "ktest: 989,\tv: 699,\tm: 1009,\tl: 1009,\tfdp: 0.7070848641992611\n",
      "ktest: 989,\tv: 698,\tm: 1009,\tl: 1009,\tfdp: 0.7060747429646907\n",
      "ktest: 989,\tv: 697,\tm: 1009,\tl: 1009,\tfdp: 0.7050646217301203\n",
      "ktest: 988,\tv: 697,\tm: 1009,\tl: 1009,\tfdp: 0.7057782498897662\n",
      "ktest: 988,\tv: 696,\tm: 1009,\tl: 1009,\tfdp: 0.7047671062652824\n",
      "ktest: 988,\tv: 695,\tm: 1009,\tl: 1009,\tfdp: 0.7037559626407984\n",
      "ktest: 988,\tv: 694,\tm: 1009,\tl: 1009,\tfdp: 0.7027448190163146\n",
      "ktest: 988,\tv: 693,\tm: 1009,\tl: 1009,\tfdp: 0.7017336753918307\n",
      "ktest: 988,\tv: 692,\tm: 1009,\tl: 1009,\tfdp: 0.7007225317673469\n",
      "ktest: 988,\tv: 691,\tm: 1009,\tl: 1009,\tfdp: 0.6997113881428629\n",
      "ktest: 988,\tv: 690,\tm: 1009,\tl: 1009,\tfdp: 0.698700244518379\n",
      "ktest: 988,\tv: 689,\tm: 1009,\tl: 1009,\tfdp: 0.6976891008938951\n",
      "ktest: 988,\tv: 688,\tm: 1009,\tl: 1009,\tfdp: 0.6966779572694112\n",
      "ktest: 988,\tv: 687,\tm: 1009,\tl: 1009,\tfdp: 0.6956668136449273\n",
      "ktest: 988,\tv: 686,\tm: 1009,\tl: 1009,\tfdp: 0.6946556700204434\n",
      "ktest: 988,\tv: 685,\tm: 1009,\tl: 1009,\tfdp: 0.6936445263959595\n",
      "ktest: 988,\tv: 684,\tm: 1009,\tl: 1009,\tfdp: 0.6926333827714756\n",
      "ktest: 988,\tv: 683,\tm: 1009,\tl: 1009,\tfdp: 0.6916222391469917\n",
      "ktest: 988,\tv: 682,\tm: 1009,\tl: 1009,\tfdp: 0.6906110955225078\n",
      "ktest: 988,\tv: 681,\tm: 1009,\tl: 1009,\tfdp: 0.6895999518980238\n",
      "ktest: 988,\tv: 680,\tm: 1009,\tl: 1009,\tfdp: 0.68858880827354\n",
      "ktest: 988,\tv: 679,\tm: 1009,\tl: 1009,\tfdp: 0.687577664649056\n",
      "ktest: 988,\tv: 678,\tm: 1009,\tl: 1009,\tfdp: 0.6865665210245722\n",
      "ktest: 988,\tv: 677,\tm: 1009,\tl: 1009,\tfdp: 0.6855553774000882\n",
      "ktest: 988,\tv: 676,\tm: 1009,\tl: 1009,\tfdp: 0.6845442337756044\n",
      "ktest: 988,\tv: 675,\tm: 1009,\tl: 1009,\tfdp: 0.6835330901511204\n",
      "ktest: 987,\tv: 675,\tm: 1009,\tl: 1009,\tfdp: 0.6842256262100376\n",
      "ktest: 987,\tv: 674,\tm: 1009,\tl: 1009,\tfdp: 0.683213458123928\n",
      "ktest: 987,\tv: 673,\tm: 1009,\tl: 1009,\tfdp: 0.6822012900378185\n",
      "ktest: 987,\tv: 672,\tm: 1009,\tl: 1009,\tfdp: 0.681189121951709\n",
      "ktest: 986,\tv: 672,\tm: 1009,\tl: 1009,\tfdp: 0.6818799831301589\n",
      "ktest: 986,\tv: 671,\tm: 1009,\tl: 1009,\tfdp: 0.6808667885044082\n",
      "ktest: 986,\tv: 670,\tm: 1009,\tl: 1009,\tfdp: 0.6798535938786576\n",
      "ktest: 986,\tv: 669,\tm: 1009,\tl: 1009,\tfdp: 0.678840399252907\n",
      "ktest: 986,\tv: 668,\tm: 1009,\tl: 1009,\tfdp: 0.6778272046271564\n",
      "ktest: 986,\tv: 667,\tm: 1009,\tl: 1009,\tfdp: 0.6768140100014058\n",
      "ktest: 986,\tv: 666,\tm: 1009,\tl: 1009,\tfdp: 0.6758008153756552\n",
      "ktest: 986,\tv: 665,\tm: 1009,\tl: 1009,\tfdp: 0.6747876207499046\n",
      "ktest: 986,\tv: 664,\tm: 1009,\tl: 1009,\tfdp: 0.673774426124154\n",
      "ktest: 986,\tv: 663,\tm: 1009,\tl: 1009,\tfdp: 0.6727612314984034\n",
      "ktest: 986,\tv: 662,\tm: 1009,\tl: 1009,\tfdp: 0.6717480368726527\n",
      "ktest: 986,\tv: 661,\tm: 1009,\tl: 1009,\tfdp: 0.6707348422469022\n",
      "ktest: 986,\tv: 660,\tm: 1009,\tl: 1009,\tfdp: 0.6697216476211515\n",
      "ktest: 986,\tv: 659,\tm: 1009,\tl: 1009,\tfdp: 0.6687084529954009\n",
      "ktest: 986,\tv: 658,\tm: 1009,\tl: 1009,\tfdp: 0.6676952583696503\n",
      "ktest: 986,\tv: 657,\tm: 1009,\tl: 1009,\tfdp: 0.6666820637438997\n",
      "ktest: 986,\tv: 656,\tm: 1009,\tl: 1009,\tfdp: 0.6656688691181492\n",
      "ktest: 985,\tv: 656,\tm: 1009,\tl: 1009,\tfdp: 0.6663446750766446\n",
      "ktest: 985,\tv: 655,\tm: 1009,\tl: 1009,\tfdp: 0.6653304518269085\n",
      "ktest: 985,\tv: 654,\tm: 1009,\tl: 1009,\tfdp: 0.6643162285771724\n",
      "ktest: 984,\tv: 654,\tm: 1009,\tl: 1009,\tfdp: 0.6649913466956452\n",
      "ktest: 984,\tv: 653,\tm: 1009,\tl: 1009,\tfdp: 0.6639760927312244\n",
      "ktest: 984,\tv: 652,\tm: 1009,\tl: 1009,\tfdp: 0.6629608387668036\n",
      "ktest: 984,\tv: 651,\tm: 1009,\tl: 1009,\tfdp: 0.6619455848023826\n",
      "ktest: 984,\tv: 650,\tm: 1009,\tl: 1009,\tfdp: 0.6609303308379618\n",
      "ktest: 984,\tv: 649,\tm: 1009,\tl: 1009,\tfdp: 0.659915076873541\n",
      "ktest: 984,\tv: 648,\tm: 1009,\tl: 1009,\tfdp: 0.6588998229091202\n",
      "ktest: 984,\tv: 647,\tm: 1009,\tl: 1009,\tfdp: 0.6578845689446994\n",
      "ktest: 984,\tv: 646,\tm: 1009,\tl: 1009,\tfdp: 0.6568693149802786\n",
      "ktest: 984,\tv: 645,\tm: 1009,\tl: 1009,\tfdp: 0.6558540610158576\n",
      "ktest: 984,\tv: 644,\tm: 1009,\tl: 1009,\tfdp: 0.6548388070514368\n",
      "ktest: 984,\tv: 643,\tm: 1009,\tl: 1009,\tfdp: 0.653823553087016\n",
      "ktest: 984,\tv: 642,\tm: 1009,\tl: 1009,\tfdp: 0.6528082991225952\n",
      "ktest: 984,\tv: 641,\tm: 1009,\tl: 1009,\tfdp: 0.6517930451581744\n",
      "ktest: 984,\tv: 640,\tm: 1009,\tl: 1009,\tfdp: 0.6507777911937536\n",
      "ktest: 984,\tv: 639,\tm: 1009,\tl: 1009,\tfdp: 0.6497625372293326\n",
      "ktest: 984,\tv: 638,\tm: 1009,\tl: 1009,\tfdp: 0.6487472832649118\n",
      "ktest: 984,\tv: 637,\tm: 1009,\tl: 1009,\tfdp: 0.647732029300491\n",
      "ktest: 984,\tv: 636,\tm: 1009,\tl: 1009,\tfdp: 0.6467167753360702\n",
      "ktest: 984,\tv: 635,\tm: 1009,\tl: 1009,\tfdp: 0.6457015213716494\n",
      "ktest: 984,\tv: 634,\tm: 1009,\tl: 1009,\tfdp: 0.6446862674072286\n",
      "ktest: 984,\tv: 633,\tm: 1009,\tl: 1009,\tfdp: 0.6436710134428076\n",
      "ktest: 984,\tv: 632,\tm: 1009,\tl: 1009,\tfdp: 0.6426557594783868\n",
      "ktest: 984,\tv: 631,\tm: 1009,\tl: 1009,\tfdp: 0.641640505513966\n",
      "ktest: 984,\tv: 630,\tm: 1009,\tl: 1009,\tfdp: 0.6406252515495452\n",
      "ktest: 984,\tv: 629,\tm: 1009,\tl: 1009,\tfdp: 0.6396099975851244\n",
      "ktest: 984,\tv: 628,\tm: 1009,\tl: 1009,\tfdp: 0.6385947436207036\n",
      "ktest: 984,\tv: 627,\tm: 1009,\tl: 1009,\tfdp: 0.6375794896562826\n",
      "ktest: 984,\tv: 626,\tm: 1009,\tl: 1009,\tfdp: 0.6365642356918618\n",
      "ktest: 984,\tv: 625,\tm: 1009,\tl: 1009,\tfdp: 0.635548981727441\n",
      "ktest: 984,\tv: 624,\tm: 1009,\tl: 1009,\tfdp: 0.6345337277630202\n",
      "ktest: 984,\tv: 623,\tm: 1009,\tl: 1009,\tfdp: 0.6335184737985994\n",
      "ktest: 984,\tv: 622,\tm: 1009,\tl: 1009,\tfdp: 0.6325032198341786\n",
      "ktest: 984,\tv: 621,\tm: 1009,\tl: 1009,\tfdp: 0.6314879658697576\n",
      "ktest: 984,\tv: 620,\tm: 1009,\tl: 1009,\tfdp: 0.6304727119053368\n",
      "ktest: 983,\tv: 620,\tm: 1009,\tl: 1009,\tfdp: 0.6311140880110392\n",
      "ktest: 983,\tv: 619,\tm: 1009,\tl: 1009,\tfdp: 0.6300978012348539\n",
      "ktest: 983,\tv: 618,\tm: 1009,\tl: 1009,\tfdp: 0.6290815144586687\n",
      "ktest: 983,\tv: 617,\tm: 1009,\tl: 1009,\tfdp: 0.6280652276824834\n",
      "ktest: 983,\tv: 616,\tm: 1009,\tl: 1009,\tfdp: 0.6270489409062981\n",
      "ktest: 983,\tv: 615,\tm: 1009,\tl: 1009,\tfdp: 0.6260326541301129\n",
      "ktest: 983,\tv: 614,\tm: 1009,\tl: 1009,\tfdp: 0.6250163673539276\n",
      "ktest: 983,\tv: 613,\tm: 1009,\tl: 1009,\tfdp: 0.6240000805777424\n",
      "ktest: 983,\tv: 612,\tm: 1009,\tl: 1009,\tfdp: 0.6229837938015571\n",
      "ktest: 983,\tv: 611,\tm: 1009,\tl: 1009,\tfdp: 0.6219675070253718\n",
      "ktest: 983,\tv: 610,\tm: 1009,\tl: 1009,\tfdp: 0.6209512202491867\n",
      "ktest: 983,\tv: 609,\tm: 1009,\tl: 1009,\tfdp: 0.6199349334730014\n",
      "ktest: 983,\tv: 608,\tm: 1009,\tl: 1009,\tfdp: 0.6189186466968162\n",
      "ktest: 983,\tv: 607,\tm: 1009,\tl: 1009,\tfdp: 0.6179023599206309\n",
      "ktest: 983,\tv: 606,\tm: 1009,\tl: 1009,\tfdp: 0.6168860731444457\n",
      "ktest: 983,\tv: 605,\tm: 1009,\tl: 1009,\tfdp: 0.6158697863682604\n",
      "ktest: 983,\tv: 604,\tm: 1009,\tl: 1009,\tfdp: 0.6148534995920751\n",
      "ktest: 983,\tv: 603,\tm: 1009,\tl: 1009,\tfdp: 0.6138372128158899\n",
      "ktest: 983,\tv: 602,\tm: 1009,\tl: 1009,\tfdp: 0.6128209260397046\n",
      "ktest: 982,\tv: 602,\tm: 1009,\tl: 1009,\tfdp: 0.6134449799358754\n",
      "ktest: 982,\tv: 601,\tm: 1009,\tl: 1009,\tfdp: 0.6124276582444396\n",
      "ktest: 982,\tv: 600,\tm: 1009,\tl: 1009,\tfdp: 0.6114103365530036\n",
      "ktest: 982,\tv: 599,\tm: 1009,\tl: 1009,\tfdp: 0.6103930148615676\n",
      "ktest: 982,\tv: 598,\tm: 1009,\tl: 1009,\tfdp: 0.6093756931701316\n",
      "ktest: 982,\tv: 597,\tm: 1009,\tl: 1009,\tfdp: 0.6083583714786958\n",
      "ktest: 982,\tv: 596,\tm: 1009,\tl: 1009,\tfdp: 0.6073410497872598\n",
      "ktest: 982,\tv: 595,\tm: 1009,\tl: 1009,\tfdp: 0.6063237280958238\n",
      "ktest: 982,\tv: 594,\tm: 1009,\tl: 1009,\tfdp: 0.6053064064043879\n",
      "ktest: 981,\tv: 594,\tm: 1009,\tl: 1009,\tfdp: 0.6059234363803353\n",
      "ktest: 981,\tv: 593,\tm: 1009,\tl: 1009,\tfdp: 0.6049050776637297\n",
      "ktest: 981,\tv: 592,\tm: 1009,\tl: 1009,\tfdp: 0.6038867189471241\n",
      "ktest: 981,\tv: 591,\tm: 1009,\tl: 1009,\tfdp: 0.6028683602305185\n",
      "ktest: 981,\tv: 590,\tm: 1009,\tl: 1009,\tfdp: 0.6018500015139129\n",
      "ktest: 981,\tv: 589,\tm: 1009,\tl: 1009,\tfdp: 0.6008316427973073\n",
      "ktest: 981,\tv: 588,\tm: 1009,\tl: 1009,\tfdp: 0.5998132840807017\n",
      "ktest: 981,\tv: 587,\tm: 1009,\tl: 1009,\tfdp: 0.5987949253640961\n",
      "ktest: 981,\tv: 586,\tm: 1009,\tl: 1009,\tfdp: 0.5977765666474905\n",
      "ktest: 981,\tv: 585,\tm: 1009,\tl: 1009,\tfdp: 0.5967582079308849\n",
      "ktest: 981,\tv: 584,\tm: 1009,\tl: 1009,\tfdp: 0.5957398492142792\n",
      "ktest: 981,\tv: 583,\tm: 1009,\tl: 1009,\tfdp: 0.5947214904976736\n",
      "ktest: 981,\tv: 582,\tm: 1009,\tl: 1009,\tfdp: 0.593703131781068\n",
      "ktest: 981,\tv: 581,\tm: 1009,\tl: 1009,\tfdp: 0.5926847730644624\n",
      "ktest: 981,\tv: 580,\tm: 1009,\tl: 1009,\tfdp: 0.5916664143478568\n",
      "ktest: 981,\tv: 579,\tm: 1009,\tl: 1009,\tfdp: 0.5906480556312512\n",
      "ktest: 981,\tv: 578,\tm: 1009,\tl: 1009,\tfdp: 0.5896296969146456\n",
      "ktest: 981,\tv: 577,\tm: 1009,\tl: 1009,\tfdp: 0.58861133819804\n",
      "ktest: 981,\tv: 576,\tm: 1009,\tl: 1009,\tfdp: 0.5875929794814344\n",
      "ktest: 981,\tv: 575,\tm: 1009,\tl: 1009,\tfdp: 0.5865746207648288\n",
      "ktest: 981,\tv: 574,\tm: 1009,\tl: 1009,\tfdp: 0.5855562620482232\n",
      "ktest: 981,\tv: 573,\tm: 1009,\tl: 1009,\tfdp: 0.5845379033316176\n",
      "ktest: 981,\tv: 572,\tm: 1009,\tl: 1009,\tfdp: 0.583519544615012\n",
      "ktest: 981,\tv: 571,\tm: 1009,\tl: 1009,\tfdp: 0.5825011858984064\n",
      "ktest: 981,\tv: 570,\tm: 1009,\tl: 1009,\tfdp: 0.5814828271818008\n",
      "ktest: 981,\tv: 569,\tm: 1009,\tl: 1009,\tfdp: 0.5804644684651952\n",
      "ktest: 981,\tv: 568,\tm: 1009,\tl: 1009,\tfdp: 0.5794461097485896\n",
      "ktest: 981,\tv: 567,\tm: 1009,\tl: 1009,\tfdp: 0.5784277510319841\n",
      "ktest: 981,\tv: 566,\tm: 1009,\tl: 1009,\tfdp: 0.5774093923153785\n",
      "ktest: 980,\tv: 566,\tm: 1009,\tl: 1009,\tfdp: 0.5779985855728431\n",
      "ktest: 980,\tv: 565,\tm: 1009,\tl: 1009,\tfdp: 0.5769791877146899\n",
      "ktest: 980,\tv: 564,\tm: 1009,\tl: 1009,\tfdp: 0.5759597898565367\n",
      "ktest: 980,\tv: 563,\tm: 1009,\tl: 1009,\tfdp: 0.5749403919983835\n",
      "ktest: 979,\tv: 563,\tm: 1009,\tl: 1009,\tfdp: 0.5755276651260632\n",
      "ktest: 979,\tv: 562,\tm: 1009,\tl: 1009,\tfdp: 0.5745072260034993\n",
      "ktest: 979,\tv: 561,\tm: 1009,\tl: 1009,\tfdp: 0.5734867868809354\n",
      "ktest: 979,\tv: 560,\tm: 1009,\tl: 1009,\tfdp: 0.5724663477583715\n",
      "ktest: 979,\tv: 559,\tm: 1009,\tl: 1009,\tfdp: 0.5714459086358075\n",
      "ktest: 978,\tv: 559,\tm: 1009,\tl: 1009,\tfdp: 0.572030209155885\n",
      "ktest: 978,\tv: 558,\tm: 1009,\tl: 1009,\tfdp: 0.5710087266395352\n",
      "ktest: 978,\tv: 557,\tm: 1009,\tl: 1009,\tfdp: 0.5699872441231854\n",
      "ktest: 978,\tv: 556,\tm: 1009,\tl: 1009,\tfdp: 0.5689657616068355\n",
      "ktest: 978,\tv: 555,\tm: 1009,\tl: 1009,\tfdp: 0.5679442790904857\n",
      "ktest: 978,\tv: 554,\tm: 1009,\tl: 1009,\tfdp: 0.5669227965741359\n",
      "ktest: 978,\tv: 553,\tm: 1009,\tl: 1009,\tfdp: 0.5659013140577862\n",
      "ktest: 978,\tv: 552,\tm: 1009,\tl: 1009,\tfdp: 0.5648798315414364\n",
      "ktest: 978,\tv: 551,\tm: 1009,\tl: 1009,\tfdp: 0.5638583490250866\n",
      "ktest: 978,\tv: 550,\tm: 1009,\tl: 1009,\tfdp: 0.5628368665087368\n",
      "ktest: 978,\tv: 549,\tm: 1009,\tl: 1009,\tfdp: 0.561815383992387\n",
      "ktest: 978,\tv: 548,\tm: 1009,\tl: 1009,\tfdp: 0.5607939014760372\n",
      "ktest: 978,\tv: 547,\tm: 1009,\tl: 1009,\tfdp: 0.5597724189596874\n",
      "ktest: 978,\tv: 546,\tm: 1009,\tl: 1009,\tfdp: 0.5587509364433376\n",
      "ktest: 978,\tv: 545,\tm: 1009,\tl: 1009,\tfdp: 0.5577294539269878\n",
      "ktest: 978,\tv: 544,\tm: 1009,\tl: 1009,\tfdp: 0.556707971410638\n",
      "ktest: 978,\tv: 543,\tm: 1009,\tl: 1009,\tfdp: 0.5556864888942882\n",
      "ktest: 978,\tv: 542,\tm: 1009,\tl: 1009,\tfdp: 0.5546650063779385\n",
      "ktest: 978,\tv: 541,\tm: 1009,\tl: 1009,\tfdp: 0.5536435238615887\n",
      "ktest: 977,\tv: 541,\tm: 1009,\tl: 1009,\tfdp: 0.5542102009586835\n",
      "ktest: 977,\tv: 540,\tm: 1009,\tl: 1009,\tfdp: 0.5531876729126343\n",
      "ktest: 977,\tv: 539,\tm: 1009,\tl: 1009,\tfdp: 0.552165144866585\n",
      "ktest: 977,\tv: 538,\tm: 1009,\tl: 1009,\tfdp: 0.5511426168205358\n",
      "ktest: 977,\tv: 537,\tm: 1009,\tl: 1009,\tfdp: 0.5501200887744865\n",
      "ktest: 977,\tv: 536,\tm: 1009,\tl: 1009,\tfdp: 0.5490975607284373\n",
      "ktest: 976,\tv: 536,\tm: 1009,\tl: 1009,\tfdp: 0.5496601606881999\n",
      "ktest: 976,\tv: 535,\tm: 1009,\tl: 1009,\tfdp: 0.5486365849699724\n",
      "ktest: 976,\tv: 534,\tm: 1009,\tl: 1009,\tfdp: 0.5476130092517448\n",
      "ktest: 976,\tv: 533,\tm: 1009,\tl: 1009,\tfdp: 0.5465894335335173\n",
      "ktest: 975,\tv: 533,\tm: 1009,\tl: 1009,\tfdp: 0.5471500380807313\n",
      "ktest: 975,\tv: 532,\tm: 1009,\tl: 1009,\tfdp: 0.5461254125412541\n",
      "ktest: 975,\tv: 531,\tm: 1009,\tl: 1009,\tfdp: 0.5451007870017771\n",
      "ktest: 975,\tv: 530,\tm: 1009,\tl: 1009,\tfdp: 0.5440761614623001\n",
      "ktest: 975,\tv: 529,\tm: 1009,\tl: 1009,\tfdp: 0.5430515359228231\n",
      "ktest: 975,\tv: 528,\tm: 1009,\tl: 1009,\tfdp: 0.542026910383346\n",
      "ktest: 975,\tv: 527,\tm: 1009,\tl: 1009,\tfdp: 0.541002284843869\n",
      "ktest: 975,\tv: 526,\tm: 1009,\tl: 1009,\tfdp: 0.539977659304392\n",
      "ktest: 975,\tv: 525,\tm: 1009,\tl: 1009,\tfdp: 0.538953033764915\n",
      "ktest: 975,\tv: 524,\tm: 1009,\tl: 1009,\tfdp: 0.537928408225438\n",
      "ktest: 975,\tv: 523,\tm: 1009,\tl: 1009,\tfdp: 0.536903782685961\n",
      "ktest: 975,\tv: 522,\tm: 1009,\tl: 1009,\tfdp: 0.5358791571464839\n",
      "ktest: 975,\tv: 521,\tm: 1009,\tl: 1009,\tfdp: 0.5348545316070069\n",
      "ktest: 975,\tv: 520,\tm: 1009,\tl: 1009,\tfdp: 0.5338299060675299\n",
      "ktest: 975,\tv: 519,\tm: 1009,\tl: 1009,\tfdp: 0.5328052805280529\n",
      "ktest: 975,\tv: 518,\tm: 1009,\tl: 1009,\tfdp: 0.5317806549885759\n",
      "ktest: 974,\tv: 518,\tm: 1009,\tl: 1009,\tfdp: 0.5323266310203916\n",
      "ktest: 974,\tv: 517,\tm: 1009,\tl: 1009,\tfdp: 0.5313009535039745\n",
      "ktest: 974,\tv: 516,\tm: 1009,\tl: 1009,\tfdp: 0.5302752759875576\n",
      "ktest: 974,\tv: 515,\tm: 1009,\tl: 1009,\tfdp: 0.5292495984711407\n",
      "ktest: 974,\tv: 514,\tm: 1009,\tl: 1009,\tfdp: 0.5282239209547238\n",
      "ktest: 974,\tv: 513,\tm: 1009,\tl: 1009,\tfdp: 0.5271982434383068\n",
      "ktest: 974,\tv: 512,\tm: 1009,\tl: 1009,\tfdp: 0.5261725659218899\n",
      "ktest: 974,\tv: 511,\tm: 1009,\tl: 1009,\tfdp: 0.525146888405473\n",
      "ktest: 974,\tv: 510,\tm: 1009,\tl: 1009,\tfdp: 0.524121210889056\n",
      "ktest: 974,\tv: 509,\tm: 1009,\tl: 1009,\tfdp: 0.523095533372639\n",
      "ktest: 974,\tv: 508,\tm: 1009,\tl: 1009,\tfdp: 0.5220698558562221\n",
      "ktest: 974,\tv: 507,\tm: 1009,\tl: 1009,\tfdp: 0.5210441783398052\n",
      "ktest: 974,\tv: 506,\tm: 1009,\tl: 1009,\tfdp: 0.5200185008233883\n",
      "ktest: 974,\tv: 505,\tm: 1009,\tl: 1009,\tfdp: 0.5189928233069713\n",
      "ktest: 974,\tv: 504,\tm: 1009,\tl: 1009,\tfdp: 0.5179671457905544\n",
      "ktest: 974,\tv: 503,\tm: 1009,\tl: 1009,\tfdp: 0.5169414682741375\n",
      "ktest: 974,\tv: 502,\tm: 1009,\tl: 1009,\tfdp: 0.5159157907577204\n",
      "ktest: 974,\tv: 501,\tm: 1009,\tl: 1009,\tfdp: 0.5148901132413035\n",
      "ktest: 974,\tv: 500,\tm: 1009,\tl: 1009,\tfdp: 0.5138644357248866\n",
      "ktest: 974,\tv: 499,\tm: 1009,\tl: 1009,\tfdp: 0.5128387582084697\n",
      "ktest: 974,\tv: 498,\tm: 1009,\tl: 1009,\tfdp: 0.5118130806920527\n",
      "ktest: 973,\tv: 498,\tm: 1009,\tl: 1009,\tfdp: 0.5123390961912224\n",
      "ktest: 973,\tv: 497,\tm: 1009,\tl: 1009,\tfdp: 0.5113123645355286\n",
      "ktest: 973,\tv: 496,\tm: 1009,\tl: 1009,\tfdp: 0.5102856328798347\n",
      "ktest: 973,\tv: 495,\tm: 1009,\tl: 1009,\tfdp: 0.509258901224141\n",
      "ktest: 973,\tv: 494,\tm: 1009,\tl: 1009,\tfdp: 0.5082321695684471\n",
      "ktest: 973,\tv: 493,\tm: 1009,\tl: 1009,\tfdp: 0.5072054379127533\n",
      "ktest: 973,\tv: 492,\tm: 1009,\tl: 1009,\tfdp: 0.5061787062570594\n",
      "ktest: 973,\tv: 491,\tm: 1009,\tl: 1009,\tfdp: 0.5051519746013656\n",
      "ktest: 973,\tv: 490,\tm: 1009,\tl: 1009,\tfdp: 0.5041252429456717\n",
      "ktest: 973,\tv: 489,\tm: 1009,\tl: 1009,\tfdp: 0.503098511289978\n",
      "ktest: 972,\tv: 489,\tm: 1009,\tl: 1009,\tfdp: 0.5036161023509759\n",
      "ktest: 972,\tv: 488,\tm: 1009,\tl: 1009,\tfdp: 0.5025883143869943\n",
      "ktest: 972,\tv: 487,\tm: 1009,\tl: 1009,\tfdp: 0.5015605264230126\n",
      "ktest: 971,\tv: 487,\tm: 1009,\tl: 1009,\tfdp: 0.5020770666150034\n",
      "ktest: 971,\tv: 486,\tm: 1009,\tl: 1009,\tfdp: 0.5010482201670219\n",
      "ktest: 971,\tv: 485,\tm: 1009,\tl: 1009,\tfdp: 0.5000193737190403\n",
      "ktest: 971,\tv: 484,\tm: 1009,\tl: 1009,\tfdp: 0.4989905272710587\n",
      "ktest: 971,\tv: 483,\tm: 1009,\tl: 1009,\tfdp: 0.4979616808230771\n",
      "ktest: 971,\tv: 482,\tm: 1009,\tl: 1009,\tfdp: 0.49693283437509556\n",
      "ktest: 971,\tv: 481,\tm: 1009,\tl: 1009,\tfdp: 0.495903987927114\n",
      "ktest: 971,\tv: 480,\tm: 1009,\tl: 1009,\tfdp: 0.4948751414791324\n",
      "ktest: 971,\tv: 479,\tm: 1009,\tl: 1009,\tfdp: 0.49384629503115085\n",
      "ktest: 971,\tv: 478,\tm: 1009,\tl: 1009,\tfdp: 0.4928174485831693\n",
      "ktest: 971,\tv: 477,\tm: 1009,\tl: 1009,\tfdp: 0.49178860213518777\n",
      "ktest: 971,\tv: 476,\tm: 1009,\tl: 1009,\tfdp: 0.4907597556872062\n",
      "ktest: 971,\tv: 475,\tm: 1009,\tl: 1009,\tfdp: 0.48973090923922463\n",
      "ktest: 971,\tv: 474,\tm: 1009,\tl: 1009,\tfdp: 0.48870206279124306\n",
      "ktest: 971,\tv: 473,\tm: 1009,\tl: 1009,\tfdp: 0.4876732163432615\n",
      "ktest: 971,\tv: 472,\tm: 1009,\tl: 1009,\tfdp: 0.48664436989528\n",
      "ktest: 971,\tv: 471,\tm: 1009,\tl: 1009,\tfdp: 0.4856155234472984\n",
      "ktest: 971,\tv: 470,\tm: 1009,\tl: 1009,\tfdp: 0.48458667699931685\n",
      "ktest: 971,\tv: 469,\tm: 1009,\tl: 1009,\tfdp: 0.4835578305513353\n",
      "ktest: 971,\tv: 468,\tm: 1009,\tl: 1009,\tfdp: 0.4825289841033537\n",
      "ktest: 971,\tv: 467,\tm: 1009,\tl: 1009,\tfdp: 0.48150013765537214\n",
      "ktest: 971,\tv: 466,\tm: 1009,\tl: 1009,\tfdp: 0.48047129120739057\n",
      "ktest: 970,\tv: 466,\tm: 1009,\tl: 1009,\tfdp: 0.4809666224354395\n",
      "ktest: 970,\tv: 465,\tm: 1009,\tl: 1009,\tfdp: 0.47993671532101667\n",
      "ktest: 970,\tv: 464,\tm: 1009,\tl: 1009,\tfdp: 0.4789068082065939\n",
      "ktest: 970,\tv: 463,\tm: 1009,\tl: 1009,\tfdp: 0.4778769010921711\n",
      "ktest: 970,\tv: 462,\tm: 1009,\tl: 1009,\tfdp: 0.4768469939777483\n",
      "ktest: 970,\tv: 461,\tm: 1009,\tl: 1009,\tfdp: 0.4758170868633256\n",
      "ktest: 970,\tv: 460,\tm: 1009,\tl: 1009,\tfdp: 0.4747871797489028\n",
      "ktest: 970,\tv: 459,\tm: 1009,\tl: 1009,\tfdp: 0.47375727263448\n",
      "ktest: 970,\tv: 458,\tm: 1009,\tl: 1009,\tfdp: 0.47272736552005723\n",
      "ktest: 970,\tv: 457,\tm: 1009,\tl: 1009,\tfdp: 0.47169745840563443\n",
      "ktest: 970,\tv: 456,\tm: 1009,\tl: 1009,\tfdp: 0.4706675512912116\n",
      "ktest: 970,\tv: 455,\tm: 1009,\tl: 1009,\tfdp: 0.4696376441767889\n",
      "ktest: 970,\tv: 454,\tm: 1009,\tl: 1009,\tfdp: 0.4686077370623661\n",
      "ktest: 970,\tv: 453,\tm: 1009,\tl: 1009,\tfdp: 0.4675778299479433\n",
      "ktest: 969,\tv: 453,\tm: 1009,\tl: 1009,\tfdp: 0.46806036640815785\n",
      "ktest: 969,\tv: 452,\tm: 1009,\tl: 1009,\tfdp: 0.4670293964380958\n",
      "ktest: 969,\tv: 451,\tm: 1009,\tl: 1009,\tfdp: 0.4659984264680338\n",
      "ktest: 969,\tv: 450,\tm: 1009,\tl: 1009,\tfdp: 0.4649674564979718\n",
      "ktest: 968,\tv: 450,\tm: 1009,\tl: 1009,\tfdp: 0.46544779477947795\n",
      "ktest: 968,\tv: 449,\tm: 1009,\tl: 1009,\tfdp: 0.464415759757794\n",
      "ktest: 968,\tv: 448,\tm: 1009,\tl: 1009,\tfdp: 0.46338372473611\n",
      "ktest: 968,\tv: 447,\tm: 1009,\tl: 1009,\tfdp: 0.46235168971442603\n",
      "ktest: 968,\tv: 446,\tm: 1009,\tl: 1009,\tfdp: 0.46131965469274205\n",
      "ktest: 968,\tv: 445,\tm: 1009,\tl: 1009,\tfdp: 0.460287619671058\n",
      "ktest: 968,\tv: 444,\tm: 1009,\tl: 1009,\tfdp: 0.45925558464937405\n",
      "ktest: 968,\tv: 443,\tm: 1009,\tl: 1009,\tfdp: 0.4582235496276901\n",
      "ktest: 968,\tv: 442,\tm: 1009,\tl: 1009,\tfdp: 0.4571915146060061\n",
      "ktest: 968,\tv: 441,\tm: 1009,\tl: 1009,\tfdp: 0.45615947958432207\n",
      "ktest: 968,\tv: 440,\tm: 1009,\tl: 1009,\tfdp: 0.4551274445626381\n",
      "ktest: 968,\tv: 439,\tm: 1009,\tl: 1009,\tfdp: 0.4540954095409541\n",
      "ktest: 968,\tv: 438,\tm: 1009,\tl: 1009,\tfdp: 0.45306337451927015\n",
      "ktest: 968,\tv: 437,\tm: 1009,\tl: 1009,\tfdp: 0.4520313394975861\n",
      "ktest: 968,\tv: 436,\tm: 1009,\tl: 1009,\tfdp: 0.45099930447590214\n",
      "ktest: 968,\tv: 435,\tm: 1009,\tl: 1009,\tfdp: 0.44996726945421817\n",
      "ktest: 968,\tv: 434,\tm: 1009,\tl: 1009,\tfdp: 0.4489352344325342\n",
      "ktest: 968,\tv: 433,\tm: 1009,\tl: 1009,\tfdp: 0.4479031994108502\n",
      "ktest: 968,\tv: 432,\tm: 1009,\tl: 1009,\tfdp: 0.4468711643891662\n",
      "ktest: 968,\tv: 431,\tm: 1009,\tl: 1009,\tfdp: 0.4458391293674822\n",
      "ktest: 968,\tv: 430,\tm: 1009,\tl: 1009,\tfdp: 0.44480709434579824\n",
      "ktest: 968,\tv: 429,\tm: 1009,\tl: 1009,\tfdp: 0.44377505932411426\n",
      "ktest: 968,\tv: 428,\tm: 1009,\tl: 1009,\tfdp: 0.44274302430243023\n",
      "ktest: 967,\tv: 428,\tm: 1009,\tl: 1009,\tfdp: 0.44320087644752065\n",
      "ktest: 967,\tv: 427,\tm: 1009,\tl: 1009,\tfdp: 0.4421677741714192\n",
      "ktest: 967,\tv: 426,\tm: 1009,\tl: 1009,\tfdp: 0.4411346718953178\n",
      "ktest: 967,\tv: 425,\tm: 1009,\tl: 1009,\tfdp: 0.4401015696192163\n",
      "ktest: 967,\tv: 424,\tm: 1009,\tl: 1009,\tfdp: 0.4390684673431149\n",
      "ktest: 967,\tv: 423,\tm: 1009,\tl: 1009,\tfdp: 0.4380353650670134\n",
      "ktest: 966,\tv: 423,\tm: 1009,\tl: 1009,\tfdp: 0.438488817825882\n",
      "ktest: 966,\tv: 422,\tm: 1009,\tl: 1009,\tfdp: 0.4374546460857266\n",
      "ktest: 966,\tv: 421,\tm: 1009,\tl: 1009,\tfdp: 0.43642047434557124\n",
      "ktest: 966,\tv: 420,\tm: 1009,\tl: 1009,\tfdp: 0.43538630260541583\n",
      "ktest: 966,\tv: 419,\tm: 1009,\tl: 1009,\tfdp: 0.4343521308652605\n",
      "ktest: 966,\tv: 418,\tm: 1009,\tl: 1009,\tfdp: 0.43331795912510507\n",
      "ktest: 965,\tv: 418,\tm: 1009,\tl: 1009,\tfdp: 0.4337669932796388\n",
      "ktest: 965,\tv: 417,\tm: 1009,\tl: 1009,\tfdp: 0.43273174985892365\n",
      "ktest: 965,\tv: 416,\tm: 1009,\tl: 1009,\tfdp: 0.4316965064382085\n",
      "ktest: 965,\tv: 415,\tm: 1009,\tl: 1009,\tfdp: 0.4306612630174934\n",
      "ktest: 965,\tv: 414,\tm: 1009,\tl: 1009,\tfdp: 0.42962601959677826\n",
      "ktest: 965,\tv: 413,\tm: 1009,\tl: 1009,\tfdp: 0.4285907761760631\n",
      "ktest: 965,\tv: 412,\tm: 1009,\tl: 1009,\tfdp: 0.427555532755348\n",
      "ktest: 964,\tv: 412,\tm: 1009,\tl: 1009,\tfdp: 0.4279990550922312\n",
      "ktest: 964,\tv: 411,\tm: 1009,\tl: 1009,\tfdp: 0.42696273776755267\n",
      "ktest: 964,\tv: 410,\tm: 1009,\tl: 1009,\tfdp: 0.42592642044287415\n",
      "ktest: 963,\tv: 410,\tm: 1009,\tl: 1009,\tfdp: 0.4263687116375189\n",
      "ktest: 963,\tv: 409,\tm: 1009,\tl: 1009,\tfdp: 0.4253313181785469\n",
      "ktest: 963,\tv: 408,\tm: 1009,\tl: 1009,\tfdp: 0.42429392471957483\n",
      "ktest: 962,\tv: 408,\tm: 1009,\tl: 1009,\tfdp: 0.4247349786953748\n",
      "ktest: 962,\tv: 407,\tm: 1009,\tl: 1009,\tfdp: 0.42369650686482374\n",
      "ktest: 962,\tv: 406,\tm: 1009,\tl: 1009,\tfdp: 0.4226580350342727\n",
      "ktest: 962,\tv: 405,\tm: 1009,\tl: 1009,\tfdp: 0.4216195632037217\n",
      "ktest: 962,\tv: 404,\tm: 1009,\tl: 1009,\tfdp: 0.4205810913731706\n",
      "ktest: 962,\tv: 403,\tm: 1009,\tl: 1009,\tfdp: 0.41954261954261957\n",
      "ktest: 962,\tv: 402,\tm: 1009,\tl: 1009,\tfdp: 0.41850414771206856\n",
      "ktest: 962,\tv: 401,\tm: 1009,\tl: 1009,\tfdp: 0.4174656758815175\n",
      "ktest: 962,\tv: 400,\tm: 1009,\tl: 1009,\tfdp: 0.41642720405096645\n",
      "ktest: 962,\tv: 399,\tm: 1009,\tl: 1009,\tfdp: 0.41538873222041545\n",
      "ktest: 962,\tv: 398,\tm: 1009,\tl: 1009,\tfdp: 0.4143502603898644\n",
      "ktest: 962,\tv: 397,\tm: 1009,\tl: 1009,\tfdp: 0.41331178855931333\n",
      "ktest: 962,\tv: 396,\tm: 1009,\tl: 1009,\tfdp: 0.41227331672876233\n",
      "ktest: 962,\tv: 395,\tm: 1009,\tl: 1009,\tfdp: 0.41123484489821127\n",
      "ktest: 962,\tv: 394,\tm: 1009,\tl: 1009,\tfdp: 0.4101963730676602\n",
      "ktest: 962,\tv: 393,\tm: 1009,\tl: 1009,\tfdp: 0.40915790123710916\n",
      "ktest: 962,\tv: 392,\tm: 1009,\tl: 1009,\tfdp: 0.40811942940655815\n",
      "ktest: 962,\tv: 391,\tm: 1009,\tl: 1009,\tfdp: 0.4070809575760071\n",
      "ktest: 962,\tv: 390,\tm: 1009,\tl: 1009,\tfdp: 0.40604248574545604\n",
      "ktest: 962,\tv: 389,\tm: 1009,\tl: 1009,\tfdp: 0.40500401391490504\n",
      "ktest: 962,\tv: 388,\tm: 1009,\tl: 1009,\tfdp: 0.403965542084354\n",
      "ktest: 962,\tv: 387,\tm: 1009,\tl: 1009,\tfdp: 0.4029270702538029\n",
      "ktest: 962,\tv: 386,\tm: 1009,\tl: 1009,\tfdp: 0.4018885984232519\n",
      "ktest: 962,\tv: 385,\tm: 1009,\tl: 1009,\tfdp: 0.40085012659270086\n",
      "ktest: 962,\tv: 384,\tm: 1009,\tl: 1009,\tfdp: 0.3998116547621498\n",
      "ktest: 962,\tv: 383,\tm: 1009,\tl: 1009,\tfdp: 0.3987731829315988\n",
      "ktest: 962,\tv: 382,\tm: 1009,\tl: 1009,\tfdp: 0.39773471110104774\n",
      "ktest: 962,\tv: 381,\tm: 1009,\tl: 1009,\tfdp: 0.3966962392704967\n",
      "ktest: 962,\tv: 380,\tm: 1009,\tl: 1009,\tfdp: 0.3956577674399457\n",
      "ktest: 962,\tv: 379,\tm: 1009,\tl: 1009,\tfdp: 0.3946192956093946\n",
      "ktest: 962,\tv: 378,\tm: 1009,\tl: 1009,\tfdp: 0.39358082377884357\n",
      "ktest: 962,\tv: 377,\tm: 1009,\tl: 1009,\tfdp: 0.39254235194829257\n",
      "ktest: 962,\tv: 376,\tm: 1009,\tl: 1009,\tfdp: 0.3915038801177415\n",
      "ktest: 962,\tv: 375,\tm: 1009,\tl: 1009,\tfdp: 0.39046540828719045\n",
      "ktest: 962,\tv: 374,\tm: 1009,\tl: 1009,\tfdp: 0.38942693645663945\n",
      "ktest: 962,\tv: 373,\tm: 1009,\tl: 1009,\tfdp: 0.3883884646260884\n",
      "ktest: 962,\tv: 372,\tm: 1009,\tl: 1009,\tfdp: 0.38734999279553733\n",
      "ktest: 962,\tv: 371,\tm: 1009,\tl: 1009,\tfdp: 0.38631152096498633\n",
      "ktest: 962,\tv: 370,\tm: 1009,\tl: 1009,\tfdp: 0.3852730491344353\n",
      "ktest: 962,\tv: 369,\tm: 1009,\tl: 1009,\tfdp: 0.3842345773038842\n",
      "ktest: 962,\tv: 368,\tm: 1009,\tl: 1009,\tfdp: 0.3831961054733332\n",
      "ktest: 962,\tv: 367,\tm: 1009,\tl: 1009,\tfdp: 0.38215763364278216\n",
      "ktest: 962,\tv: 366,\tm: 1009,\tl: 1009,\tfdp: 0.3811191618122311\n",
      "ktest: 962,\tv: 365,\tm: 1009,\tl: 1009,\tfdp: 0.3800806899816801\n",
      "ktest: 962,\tv: 364,\tm: 1009,\tl: 1009,\tfdp: 0.37904221815112904\n",
      "ktest: 962,\tv: 363,\tm: 1009,\tl: 1009,\tfdp: 0.378003746320578\n",
      "ktest: 961,\tv: 363,\tm: 1009,\tl: 1009,\tfdp: 0.37839709048948594\n",
      "ktest: 961,\tv: 362,\tm: 1009,\tl: 1009,\tfdp: 0.3773575380430863\n",
      "ktest: 961,\tv: 361,\tm: 1009,\tl: 1009,\tfdp: 0.3763179855966866\n",
      "ktest: 961,\tv: 360,\tm: 1009,\tl: 1009,\tfdp: 0.3752784331502869\n",
      "ktest: 961,\tv: 359,\tm: 1009,\tl: 1009,\tfdp: 0.3742388807038872\n",
      "ktest: 961,\tv: 358,\tm: 1009,\tl: 1009,\tfdp: 0.37319932825748753\n",
      "ktest: 961,\tv: 357,\tm: 1009,\tl: 1009,\tfdp: 0.37215977581108783\n",
      "ktest: 961,\tv: 356,\tm: 1009,\tl: 1009,\tfdp: 0.37112022336468814\n",
      "ktest: 961,\tv: 355,\tm: 1009,\tl: 1009,\tfdp: 0.37008067091828845\n",
      "ktest: 961,\tv: 354,\tm: 1009,\tl: 1009,\tfdp: 0.3690411184718888\n",
      "ktest: 960,\tv: 354,\tm: 1009,\tl: 1009,\tfdp: 0.36942553630363034\n",
      "ktest: 959,\tv: 354,\tm: 1009,\tl: 1009,\tfdp: 0.3698107558409647\n",
      "ktest: 959,\tv: 353,\tm: 1009,\tl: 1009,\tfdp: 0.36876903540197603\n",
      "ktest: 959,\tv: 352,\tm: 1009,\tl: 1009,\tfdp: 0.3677273149629874\n",
      "ktest: 959,\tv: 351,\tm: 1009,\tl: 1009,\tfdp: 0.36668559452399874\n",
      "ktest: 958,\tv: 351,\tm: 1009,\tl: 1009,\tfdp: 0.36706835610492156\n",
      "ktest: 958,\tv: 350,\tm: 1009,\tl: 1009,\tfdp: 0.366025548275078\n",
      "ktest: 958,\tv: 349,\tm: 1009,\tl: 1009,\tfdp: 0.3649827404452345\n",
      "ktest: 958,\tv: 348,\tm: 1009,\tl: 1009,\tfdp: 0.363939932615391\n",
      "ktest: 958,\tv: 347,\tm: 1009,\tl: 1009,\tfdp: 0.3628971247855474\n",
      "ktest: 957,\tv: 347,\tm: 1009,\tl: 1009,\tfdp: 0.36327632763276324\n",
      "ktest: 956,\tv: 347,\tm: 1009,\tl: 1009,\tfdp: 0.36365632379137497\n",
      "ktest: 956,\tv: 346,\tm: 1009,\tl: 1009,\tfdp: 0.3626113343551929\n",
      "ktest: 956,\tv: 345,\tm: 1009,\tl: 1009,\tfdp: 0.3615663449190108\n",
      "ktest: 956,\tv: 344,\tm: 1009,\tl: 1009,\tfdp: 0.36052135548282865\n",
      "ktest: 956,\tv: 343,\tm: 1009,\tl: 1009,\tfdp: 0.35947636604664657\n",
      "ktest: 956,\tv: 342,\tm: 1009,\tl: 1009,\tfdp: 0.3584313766104644\n",
      "ktest: 956,\tv: 341,\tm: 1009,\tl: 1009,\tfdp: 0.35738638717428234\n",
      "ktest: 956,\tv: 340,\tm: 1009,\tl: 1009,\tfdp: 0.3563413977381002\n",
      "ktest: 956,\tv: 339,\tm: 1009,\tl: 1009,\tfdp: 0.3552964083019181\n",
      "ktest: 956,\tv: 338,\tm: 1009,\tl: 1009,\tfdp: 0.35425141886573597\n",
      "ktest: 956,\tv: 337,\tm: 1009,\tl: 1009,\tfdp: 0.3532064294295539\n",
      "ktest: 956,\tv: 336,\tm: 1009,\tl: 1009,\tfdp: 0.3521614399933718\n",
      "ktest: 955,\tv: 336,\tm: 1009,\tl: 1009,\tfdp: 0.3525301954279198\n",
      "ktest: 955,\tv: 335,\tm: 1009,\tl: 1009,\tfdp: 0.3514841117619616\n",
      "ktest: 955,\tv: 334,\tm: 1009,\tl: 1009,\tfdp: 0.35043802809600333\n",
      "ktest: 955,\tv: 333,\tm: 1009,\tl: 1009,\tfdp: 0.3493919444300451\n",
      "ktest: 955,\tv: 332,\tm: 1009,\tl: 1009,\tfdp: 0.3483458607640869\n",
      "ktest: 955,\tv: 331,\tm: 1009,\tl: 1009,\tfdp: 0.3472997770981287\n",
      "ktest: 955,\tv: 330,\tm: 1009,\tl: 1009,\tfdp: 0.3462536934321705\n",
      "ktest: 955,\tv: 329,\tm: 1009,\tl: 1009,\tfdp: 0.34520760976621223\n",
      "ktest: 955,\tv: 328,\tm: 1009,\tl: 1009,\tfdp: 0.344161526100254\n",
      "ktest: 955,\tv: 327,\tm: 1009,\tl: 1009,\tfdp: 0.3431154424342958\n",
      "ktest: 955,\tv: 326,\tm: 1009,\tl: 1009,\tfdp: 0.3420693587683376\n",
      "ktest: 955,\tv: 325,\tm: 1009,\tl: 1009,\tfdp: 0.3410232751023794\n",
      "ktest: 955,\tv: 324,\tm: 1009,\tl: 1009,\tfdp: 0.33997719143642113\n",
      "ktest: 955,\tv: 323,\tm: 1009,\tl: 1009,\tfdp: 0.3389311077704629\n",
      "ktest: 955,\tv: 322,\tm: 1009,\tl: 1009,\tfdp: 0.3378850241045047\n",
      "ktest: 955,\tv: 321,\tm: 1009,\tl: 1009,\tfdp: 0.3368389404385465\n",
      "ktest: 955,\tv: 320,\tm: 1009,\tl: 1009,\tfdp: 0.33579285677258824\n",
      "ktest: 955,\tv: 319,\tm: 1009,\tl: 1009,\tfdp: 0.33474677310663004\n",
      "ktest: 954,\tv: 319,\tm: 1009,\tl: 1009,\tfdp: 0.33509766070946717\n",
      "ktest: 954,\tv: 318,\tm: 1009,\tl: 1009,\tfdp: 0.33405048051975006\n",
      "ktest: 954,\tv: 317,\tm: 1009,\tl: 1009,\tfdp: 0.333003300330033\n",
      "ktest: 954,\tv: 316,\tm: 1009,\tl: 1009,\tfdp: 0.3319561201403159\n",
      "ktest: 954,\tv: 315,\tm: 1009,\tl: 1009,\tfdp: 0.33090893995059883\n",
      "ktest: 954,\tv: 314,\tm: 1009,\tl: 1009,\tfdp: 0.3298617597608817\n",
      "ktest: 954,\tv: 313,\tm: 1009,\tl: 1009,\tfdp: 0.32881457957116467\n",
      "ktest: 954,\tv: 312,\tm: 1009,\tl: 1009,\tfdp: 0.32776739938144756\n",
      "ktest: 954,\tv: 311,\tm: 1009,\tl: 1009,\tfdp: 0.3267202191917305\n",
      "ktest: 954,\tv: 310,\tm: 1009,\tl: 1009,\tfdp: 0.3256730390020134\n",
      "ktest: 953,\tv: 310,\tm: 1009,\tl: 1009,\tfdp: 0.32601477356549924\n",
      "ktest: 953,\tv: 309,\tm: 1009,\tl: 1009,\tfdp: 0.3249664945508192\n",
      "ktest: 953,\tv: 308,\tm: 1009,\tl: 1009,\tfdp: 0.32391821553613914\n",
      "ktest: 952,\tv: 308,\tm: 1009,\tl: 1009,\tfdp: 0.32425846576254264\n",
      "ktest: 951,\tv: 308,\tm: 1009,\tl: 1009,\tfdp: 0.324599431551988\n",
      "ktest: 951,\tv: 307,\tm: 1009,\tl: 1009,\tfdp: 0.3235489479547324\n",
      "ktest: 951,\tv: 306,\tm: 1009,\tl: 1009,\tfdp: 0.32249846435747676\n",
      "ktest: 951,\tv: 305,\tm: 1009,\tl: 1009,\tfdp: 0.32144798076022113\n",
      "ktest: 951,\tv: 304,\tm: 1009,\tl: 1009,\tfdp: 0.3203974971629655\n",
      "ktest: 951,\tv: 303,\tm: 1009,\tl: 1009,\tfdp: 0.3193470135657099\n",
      "ktest: 951,\tv: 302,\tm: 1009,\tl: 1009,\tfdp: 0.31829652996845426\n",
      "ktest: 951,\tv: 301,\tm: 1009,\tl: 1009,\tfdp: 0.31724604637119863\n",
      "ktest: 951,\tv: 300,\tm: 1009,\tl: 1009,\tfdp: 0.316195562773943\n",
      "ktest: 951,\tv: 299,\tm: 1009,\tl: 1009,\tfdp: 0.3151450791766874\n",
      "ktest: 951,\tv: 298,\tm: 1009,\tl: 1009,\tfdp: 0.31409459557943176\n",
      "ktest: 951,\tv: 297,\tm: 1009,\tl: 1009,\tfdp: 0.31304411198217613\n",
      "ktest: 951,\tv: 296,\tm: 1009,\tl: 1009,\tfdp: 0.3119936283849205\n",
      "ktest: 950,\tv: 296,\tm: 1009,\tl: 1009,\tfdp: 0.31232204273058883\n",
      "ktest: 950,\tv: 295,\tm: 1009,\tl: 1009,\tfdp: 0.3112704533611255\n",
      "ktest: 950,\tv: 294,\tm: 1009,\tl: 1009,\tfdp: 0.31021886399166226\n",
      "ktest: 950,\tv: 293,\tm: 1009,\tl: 1009,\tfdp: 0.309167274622199\n",
      "ktest: 950,\tv: 292,\tm: 1009,\tl: 1009,\tfdp: 0.30811568525273575\n",
      "ktest: 950,\tv: 291,\tm: 1009,\tl: 1009,\tfdp: 0.3070640958832725\n",
      "ktest: 950,\tv: 290,\tm: 1009,\tl: 1009,\tfdp: 0.30601250651380923\n",
      "ktest: 950,\tv: 289,\tm: 1009,\tl: 1009,\tfdp: 0.304960917144346\n",
      "ktest: 950,\tv: 288,\tm: 1009,\tl: 1009,\tfdp: 0.3039093277748827\n",
      "ktest: 949,\tv: 288,\tm: 1009,\tl: 1009,\tfdp: 0.30422956942691104\n",
      "ktest: 949,\tv: 287,\tm: 1009,\tl: 1009,\tfdp: 0.3031768719548456\n",
      "ktest: 949,\tv: 286,\tm: 1009,\tl: 1009,\tfdp: 0.3021241744827802\n",
      "ktest: 949,\tv: 285,\tm: 1009,\tl: 1009,\tfdp: 0.30107147701071474\n",
      "ktest: 949,\tv: 284,\tm: 1009,\tl: 1009,\tfdp: 0.30001877953864925\n",
      "ktest: 949,\tv: 283,\tm: 1009,\tl: 1009,\tfdp: 0.29896608206658387\n",
      "ktest: 948,\tv: 283,\tm: 1009,\tl: 1009,\tfdp: 0.299281447132055\n",
      "ktest: 948,\tv: 282,\tm: 1009,\tl: 1009,\tfdp: 0.2982276392196182\n",
      "ktest: 947,\tv: 282,\tm: 1009,\tl: 1009,\tfdp: 0.2985425575292482\n",
      "ktest: 947,\tv: 281,\tm: 1009,\tl: 1009,\tfdp: 0.297487636831265\n",
      "ktest: 946,\tv: 281,\tm: 1009,\tl: 1009,\tfdp: 0.2978021057919746\n",
      "ktest: 946,\tv: 280,\tm: 1009,\tl: 1009,\tfdp: 0.2967460699558328\n",
      "ktest: 946,\tv: 279,\tm: 1009,\tl: 1009,\tfdp: 0.2956900341196911\n",
      "ktest: 946,\tv: 278,\tm: 1009,\tl: 1009,\tfdp: 0.2946339982835493\n",
      "ktest: 946,\tv: 277,\tm: 1009,\tl: 1009,\tfdp: 0.2935779624474075\n",
      "ktest: 946,\tv: 276,\tm: 1009,\tl: 1009,\tfdp: 0.2925219266112658\n",
      "ktest: 946,\tv: 275,\tm: 1009,\tl: 1009,\tfdp: 0.291465890775124\n",
      "ktest: 945,\tv: 275,\tm: 1009,\tl: 1009,\tfdp: 0.2917743202891718\n",
      "ktest: 945,\tv: 274,\tm: 1009,\tl: 1009,\tfdp: 0.2907171669547907\n",
      "ktest: 944,\tv: 274,\tm: 1009,\tl: 1009,\tfdp: 0.29102513005537844\n",
      "ktest: 944,\tv: 273,\tm: 1009,\tl: 1009,\tfdp: 0.2899668568551771\n",
      "ktest: 944,\tv: 272,\tm: 1009,\tl: 1009,\tfdp: 0.28890858365497574\n",
      "ktest: 944,\tv: 271,\tm: 1009,\tl: 1009,\tfdp: 0.2878503104547743\n",
      "ktest: 944,\tv: 270,\tm: 1009,\tl: 1009,\tfdp: 0.286792037254573\n",
      "ktest: 944,\tv: 269,\tm: 1009,\tl: 1009,\tfdp: 0.28573376405437156\n",
      "ktest: 944,\tv: 268,\tm: 1009,\tl: 1009,\tfdp: 0.2846754908541702\n",
      "ktest: 944,\tv: 267,\tm: 1009,\tl: 1009,\tfdp: 0.2836172176539688\n",
      "ktest: 944,\tv: 266,\tm: 1009,\tl: 1009,\tfdp: 0.28255894445376745\n",
      "ktest: 944,\tv: 265,\tm: 1009,\tl: 1009,\tfdp: 0.2815006712535661\n",
      "ktest: 944,\tv: 264,\tm: 1009,\tl: 1009,\tfdp: 0.2804423980533647\n",
      "ktest: 943,\tv: 264,\tm: 1009,\tl: 1009,\tfdp: 0.28073979190071713\n",
      "ktest: 943,\tv: 263,\tm: 1009,\tl: 1009,\tfdp: 0.27968039645958237\n",
      "ktest: 943,\tv: 262,\tm: 1009,\tl: 1009,\tfdp: 0.2786210010184476\n",
      "ktest: 942,\tv: 262,\tm: 1009,\tl: 1009,\tfdp: 0.2789167770280213\n",
      "ktest: 942,\tv: 261,\tm: 1009,\tl: 1009,\tfdp: 0.277856256963276\n",
      "ktest: 941,\tv: 261,\tm: 1009,\tl: 1009,\tfdp: 0.2781515346008565\n",
      "ktest: 941,\tv: 260,\tm: 1009,\tl: 1009,\tfdp: 0.2770898875222273\n",
      "ktest: 940,\tv: 260,\tm: 1009,\tl: 1009,\tfdp: 0.27738466399831474\n",
      "ktest: 939,\tv: 260,\tm: 1009,\tl: 1009,\tfdp: 0.27768006832632147\n",
      "ktest: 939,\tv: 259,\tm: 1009,\tl: 1009,\tfdp: 0.27661616001855777\n",
      "ktest: 939,\tv: 258,\tm: 1009,\tl: 1009,\tfdp: 0.2755522517107941\n",
      "ktest: 939,\tv: 257,\tm: 1009,\tl: 1009,\tfdp: 0.2744883434030304\n",
      "ktest: 939,\tv: 256,\tm: 1009,\tl: 1009,\tfdp: 0.2734244350952667\n",
      "ktest: 939,\tv: 255,\tm: 1009,\tl: 1009,\tfdp: 0.27236052678750305\n",
      "ktest: 939,\tv: 254,\tm: 1009,\tl: 1009,\tfdp: 0.27129661847973935\n",
      "ktest: 939,\tv: 253,\tm: 1009,\tl: 1009,\tfdp: 0.27023271017197564\n",
      "ktest: 939,\tv: 252,\tm: 1009,\tl: 1009,\tfdp: 0.269168801864212\n",
      "ktest: 938,\tv: 252,\tm: 1009,\tl: 1009,\tfdp: 0.2694557622073508\n",
      "ktest: 937,\tv: 252,\tm: 1009,\tl: 1009,\tfdp: 0.2697433350592263\n",
      "ktest: 937,\tv: 251,\tm: 1009,\tl: 1009,\tfdp: 0.2686771558692689\n",
      "ktest: 937,\tv: 250,\tm: 1009,\tl: 1009,\tfdp: 0.2676109766793115\n",
      "ktest: 937,\tv: 249,\tm: 1009,\tl: 1009,\tfdp: 0.26654479748935406\n",
      "ktest: 937,\tv: 248,\tm: 1009,\tl: 1009,\tfdp: 0.2654786182993966\n",
      "ktest: 937,\tv: 247,\tm: 1009,\tl: 1009,\tfdp: 0.26441243910943923\n",
      "ktest: 936,\tv: 247,\tm: 1009,\tl: 1009,\tfdp: 0.26469493103156466\n",
      "ktest: 936,\tv: 246,\tm: 1009,\tl: 1009,\tfdp: 0.2636276127612761\n",
      "ktest: 936,\tv: 245,\tm: 1009,\tl: 1009,\tfdp: 0.26256029449098756\n",
      "ktest: 936,\tv: 244,\tm: 1009,\tl: 1009,\tfdp: 0.26149297622069895\n",
      "ktest: 936,\tv: 243,\tm: 1009,\tl: 1009,\tfdp: 0.2604256579504104\n",
      "ktest: 936,\tv: 242,\tm: 1009,\tl: 1009,\tfdp: 0.25935833968012184\n",
      "ktest: 936,\tv: 241,\tm: 1009,\tl: 1009,\tfdp: 0.2582910214098333\n",
      "ktest: 936,\tv: 240,\tm: 1009,\tl: 1009,\tfdp: 0.2572237031395447\n",
      "ktest: 935,\tv: 240,\tm: 1009,\tl: 1009,\tfdp: 0.25749880870439984\n",
      "ktest: 935,\tv: 239,\tm: 1009,\tl: 1009,\tfdp: 0.25643034891724464\n",
      "ktest: 935,\tv: 238,\tm: 1009,\tl: 1009,\tfdp: 0.25536188913008945\n",
      "ktest: 934,\tv: 238,\tm: 1009,\tl: 1009,\tfdp: 0.2556352958636334\n",
      "ktest: 934,\tv: 237,\tm: 1009,\tl: 1009,\tfdp: 0.25456569211525004\n",
      "ktest: 934,\tv: 236,\tm: 1009,\tl: 1009,\tfdp: 0.25349608836686666\n",
      "ktest: 934,\tv: 235,\tm: 1009,\tl: 1009,\tfdp: 0.25242648461848327\n",
      "ktest: 934,\tv: 234,\tm: 1009,\tl: 1009,\tfdp: 0.25135688087009983\n",
      "ktest: 933,\tv: 234,\tm: 1009,\tl: 1009,\tfdp: 0.25162628803073234\n",
      "ktest: 933,\tv: 233,\tm: 1009,\tl: 1009,\tfdp: 0.25055553786889945\n",
      "ktest: 933,\tv: 232,\tm: 1009,\tl: 1009,\tfdp: 0.24948478770706653\n",
      "ktest: 933,\tv: 231,\tm: 1009,\tl: 1009,\tfdp: 0.2484140375452336\n",
      "ktest: 933,\tv: 230,\tm: 1009,\tl: 1009,\tfdp: 0.24734328738340072\n",
      "ktest: 932,\tv: 230,\tm: 1009,\tl: 1009,\tfdp: 0.24760867717673055\n",
      "ktest: 931,\tv: 230,\tm: 1009,\tl: 1009,\tfdp: 0.24787463708776894\n",
      "ktest: 931,\tv: 229,\tm: 1009,\tl: 1009,\tfdp: 0.2468015867107656\n",
      "ktest: 930,\tv: 229,\tm: 1009,\tl: 1009,\tfdp: 0.24706696476099224\n",
      "ktest: 929,\tv: 229,\tm: 1009,\tl: 1009,\tfdp: 0.2473329141310256\n",
      "ktest: 929,\tv: 228,\tm: 1009,\tl: 1009,\tfdp: 0.24625755363480376\n",
      "ktest: 929,\tv: 227,\tm: 1009,\tl: 1009,\tfdp: 0.24518219313858192\n",
      "ktest: 929,\tv: 226,\tm: 1009,\tl: 1009,\tfdp: 0.24410683264236005\n",
      "ktest: 928,\tv: 226,\tm: 1009,\tl: 1009,\tfdp: 0.24436987879822467\n",
      "ktest: 927,\tv: 226,\tm: 1009,\tl: 1009,\tfdp: 0.24463349247546115\n",
      "ktest: 927,\tv: 225,\tm: 1009,\tl: 1009,\tfdp: 0.2435558118918688\n",
      "ktest: 927,\tv: 224,\tm: 1009,\tl: 1009,\tfdp: 0.24247813130827645\n",
      "ktest: 927,\tv: 223,\tm: 1009,\tl: 1009,\tfdp: 0.2414004507246841\n",
      "ktest: 926,\tv: 223,\tm: 1009,\tl: 1009,\tfdp: 0.24166114235613628\n",
      "ktest: 925,\tv: 223,\tm: 1009,\tl: 1009,\tfdp: 0.24192239764516993\n",
      "ktest: 925,\tv: 222,\tm: 1009,\tl: 1009,\tfdp: 0.24084238694139684\n",
      "ktest: 925,\tv: 221,\tm: 1009,\tl: 1009,\tfdp: 0.23976237623762375\n",
      "ktest: 925,\tv: 220,\tm: 1009,\tl: 1009,\tfdp: 0.23868236553385067\n",
      "ktest: 925,\tv: 219,\tm: 1009,\tl: 1009,\tfdp: 0.2376023548300776\n",
      "ktest: 925,\tv: 218,\tm: 1009,\tl: 1009,\tfdp: 0.23652234412630452\n",
      "ktest: 925,\tv: 217,\tm: 1009,\tl: 1009,\tfdp: 0.23544233342253143\n",
      "ktest: 925,\tv: 216,\tm: 1009,\tl: 1009,\tfdp: 0.23436232271875834\n",
      "ktest: 924,\tv: 216,\tm: 1009,\tl: 1009,\tfdp: 0.23461596159615963\n",
      "ktest: 924,\tv: 215,\tm: 1009,\tl: 1009,\tfdp: 0.23353478204963354\n",
      "ktest: 924,\tv: 214,\tm: 1009,\tl: 1009,\tfdp: 0.23245360250310745\n",
      "ktest: 924,\tv: 213,\tm: 1009,\tl: 1009,\tfdp: 0.2313724229565814\n",
      "ktest: 924,\tv: 212,\tm: 1009,\tl: 1009,\tfdp: 0.2302912434100553\n",
      "ktest: 924,\tv: 211,\tm: 1009,\tl: 1009,\tfdp: 0.2292100638635292\n",
      "ktest: 924,\tv: 210,\tm: 1009,\tl: 1009,\tfdp: 0.22812888431700312\n",
      "ktest: 924,\tv: 209,\tm: 1009,\tl: 1009,\tfdp: 0.22704770477047706\n",
      "ktest: 924,\tv: 208,\tm: 1009,\tl: 1009,\tfdp: 0.22596652522395097\n",
      "ktest: 923,\tv: 208,\tm: 1009,\tl: 1009,\tfdp: 0.22621134269439944\n",
      "ktest: 923,\tv: 207,\tm: 1009,\tl: 1009,\tfdp: 0.22512899177241666\n",
      "ktest: 923,\tv: 206,\tm: 1009,\tl: 1009,\tfdp: 0.22404664085043388\n",
      "ktest: 922,\tv: 206,\tm: 1009,\tl: 1009,\tfdp: 0.22428964154549946\n",
      "ktest: 922,\tv: 205,\tm: 1009,\tl: 1009,\tfdp: 0.2232061167071154\n",
      "ktest: 922,\tv: 204,\tm: 1009,\tl: 1009,\tfdp: 0.22212259186873137\n",
      "ktest: 921,\tv: 204,\tm: 1009,\tl: 1009,\tfdp: 0.22236376732135757\n",
      "ktest: 920,\tv: 204,\tm: 1009,\tl: 1009,\tfdp: 0.222605467068446\n",
      "ktest: 920,\tv: 203,\tm: 1009,\tl: 1009,\tfdp: 0.22151958674128286\n",
      "ktest: 919,\tv: 203,\tm: 1009,\tl: 1009,\tfdp: 0.22176063090531034\n",
      "ktest: 919,\tv: 202,\tm: 1009,\tl: 1009,\tfdp: 0.22067356898910784\n",
      "ktest: 919,\tv: 201,\tm: 1009,\tl: 1009,\tfdp: 0.21958650707290533\n",
      "ktest: 918,\tv: 201,\tm: 1009,\tl: 1009,\tfdp: 0.21982570806100218\n",
      "ktest: 918,\tv: 200,\tm: 1009,\tl: 1009,\tfdp: 0.21873746198149227\n",
      "ktest: 917,\tv: 200,\tm: 1009,\tl: 1009,\tfdp: 0.21897599792694647\n",
      "ktest: 917,\tv: 199,\tm: 1009,\tl: 1009,\tfdp: 0.21788656510143928\n",
      "ktest: 917,\tv: 198,\tm: 1009,\tl: 1009,\tfdp: 0.2167971322759321\n",
      "ktest: 916,\tv: 198,\tm: 1009,\tl: 1009,\tfdp: 0.2170338103679364\n",
      "ktest: 916,\tv: 197,\tm: 1009,\tl: 1009,\tfdp: 0.21594318820528344\n",
      "ktest: 916,\tv: 196,\tm: 1009,\tl: 1009,\tfdp: 0.21485256604263048\n",
      "ktest: 915,\tv: 196,\tm: 1009,\tl: 1009,\tfdp: 0.21508737759021804\n",
      "ktest: 915,\tv: 195,\tm: 1009,\tl: 1009,\tfdp: 0.2139955634907753\n",
      "ktest: 914,\tv: 195,\tm: 1009,\tl: 1009,\tfdp: 0.21422969430422256\n",
      "ktest: 914,\tv: 194,\tm: 1009,\tl: 1009,\tfdp: 0.21313668565981325\n",
      "ktest: 914,\tv: 193,\tm: 1009,\tl: 1009,\tfdp: 0.21204367701540394\n",
      "ktest: 913,\tv: 193,\tm: 1009,\tl: 1009,\tfdp: 0.2122759263878195\n",
      "ktest: 913,\tv: 192,\tm: 1009,\tl: 1009,\tfdp: 0.2111817205816967\n",
      "ktest: 913,\tv: 191,\tm: 1009,\tl: 1009,\tfdp: 0.21008751477557394\n",
      "ktest: 913,\tv: 190,\tm: 1009,\tl: 1009,\tfdp: 0.20899330896945115\n",
      "ktest: 912,\tv: 190,\tm: 1009,\tl: 1009,\tfdp: 0.2092224682994615\n",
      "ktest: 912,\tv: 189,\tm: 1009,\tl: 1009,\tfdp: 0.2081270627062706\n",
      "ktest: 911,\tv: 189,\tm: 1009,\tl: 1009,\tfdp: 0.20835552270924126\n",
      "ktest: 911,\tv: 188,\tm: 1009,\tl: 1009,\tfdp: 0.20725891469498212\n",
      "ktest: 910,\tv: 188,\tm: 1009,\tl: 1009,\tfdp: 0.2074866717440975\n",
      "ktest: 910,\tv: 187,\tm: 1009,\tl: 1009,\tfdp: 0.2063888586660864\n",
      "ktest: 910,\tv: 186,\tm: 1009,\tl: 1009,\tfdp: 0.2052910455880753\n",
      "ktest: 909,\tv: 186,\tm: 1009,\tl: 1009,\tfdp: 0.20551688832249562\n",
      "ktest: 909,\tv: 185,\tm: 1009,\tl: 1009,\tfdp: 0.2044178675293272\n",
      "ktest: 909,\tv: 184,\tm: 1009,\tl: 1009,\tfdp: 0.20331884673615877\n",
      "ktest: 908,\tv: 184,\tm: 1009,\tl: 1009,\tfdp: 0.2035427661708902\n",
      "ktest: 908,\tv: 183,\tm: 1009,\tl: 1009,\tfdp: 0.2024425350023989\n",
      "ktest: 908,\tv: 182,\tm: 1009,\tl: 1009,\tfdp: 0.2013423038339076\n",
      "ktest: 908,\tv: 181,\tm: 1009,\tl: 1009,\tfdp: 0.2002420726654163\n",
      "ktest: 908,\tv: 180,\tm: 1009,\tl: 1009,\tfdp: 0.199141841496925\n",
      "ktest: 908,\tv: 179,\tm: 1009,\tl: 1009,\tfdp: 0.1980416103284337\n",
      "ktest: 907,\tv: 179,\tm: 1009,\tl: 1009,\tfdp: 0.1982599583001299\n",
      "ktest: 906,\tv: 179,\tm: 1009,\tl: 1009,\tfdp: 0.1984787882761786\n",
      "ktest: 906,\tv: 178,\tm: 1009,\tl: 1009,\tfdp: 0.19737612834131094\n",
      "ktest: 906,\tv: 177,\tm: 1009,\tl: 1009,\tfdp: 0.19627346840644327\n",
      "ktest: 906,\tv: 176,\tm: 1009,\tl: 1009,\tfdp: 0.1951708084715756\n",
      "ktest: 905,\tv: 176,\tm: 1009,\tl: 1009,\tfdp: 0.1953864668234779\n",
      "ktest: 905,\tv: 175,\tm: 1009,\tl: 1009,\tfdp: 0.19428258847984245\n",
      "ktest: 904,\tv: 175,\tm: 1009,\tl: 1009,\tfdp: 0.19449750284762987\n",
      "ktest: 904,\tv: 174,\tm: 1009,\tl: 1009,\tfdp: 0.19339240339963198\n",
      "ktest: 904,\tv: 173,\tm: 1009,\tl: 1009,\tfdp: 0.1922873039516341\n",
      "ktest: 904,\tv: 172,\tm: 1009,\tl: 1009,\tfdp: 0.1911822045036362\n",
      "ktest: 904,\tv: 171,\tm: 1009,\tl: 1009,\tfdp: 0.19007710505563832\n",
      "ktest: 904,\tv: 170,\tm: 1009,\tl: 1009,\tfdp: 0.1889720056076404\n",
      "ktest: 904,\tv: 169,\tm: 1009,\tl: 1009,\tfdp: 0.18786690615964252\n",
      "ktest: 904,\tv: 168,\tm: 1009,\tl: 1009,\tfdp: 0.18676180671164463\n",
      "ktest: 904,\tv: 167,\tm: 1009,\tl: 1009,\tfdp: 0.18565670726364672\n",
      "ktest: 904,\tv: 166,\tm: 1009,\tl: 1009,\tfdp: 0.18455160781564883\n",
      "ktest: 904,\tv: 165,\tm: 1009,\tl: 1009,\tfdp: 0.18344650836765092\n",
      "ktest: 904,\tv: 164,\tm: 1009,\tl: 1009,\tfdp: 0.18234140891965303\n",
      "ktest: 903,\tv: 164,\tm: 1009,\tl: 1009,\tfdp: 0.18254333739021741\n",
      "ktest: 903,\tv: 163,\tm: 1009,\tl: 1009,\tfdp: 0.181437014133307\n",
      "ktest: 903,\tv: 162,\tm: 1009,\tl: 1009,\tfdp: 0.1803306908763966\n",
      "ktest: 902,\tv: 162,\tm: 1009,\tl: 1009,\tfdp: 0.18053061403701345\n",
      "ktest: 902,\tv: 161,\tm: 1009,\tl: 1009,\tfdp: 0.1794230642576453\n",
      "ktest: 902,\tv: 160,\tm: 1009,\tl: 1009,\tfdp: 0.1783155144782771\n",
      "ktest: 901,\tv: 160,\tm: 1009,\tl: 1009,\tfdp: 0.17851342292941838\n",
      "ktest: 901,\tv: 159,\tm: 1009,\tl: 1009,\tfdp: 0.17740464390501204\n",
      "ktest: 901,\tv: 158,\tm: 1009,\tl: 1009,\tfdp: 0.17629586488060572\n",
      "ktest: 901,\tv: 157,\tm: 1009,\tl: 1009,\tfdp: 0.17518708585619938\n",
      "ktest: 900,\tv: 157,\tm: 1009,\tl: 1009,\tfdp: 0.1753817381738174\n",
      "ktest: 900,\tv: 156,\tm: 1009,\tl: 1009,\tfdp: 0.17427172717271727\n",
      "ktest: 899,\tv: 156,\tm: 1009,\tl: 1009,\tfdp: 0.17446557781473365\n",
      "ktest: 898,\tv: 156,\tm: 1009,\tl: 1009,\tfdp: 0.17465986019537366\n",
      "ktest: 897,\tv: 156,\tm: 1009,\tl: 1009,\tfdp: 0.1748545757585792\n",
      "ktest: 897,\tv: 155,\tm: 1009,\tl: 1009,\tfdp: 0.17374085234610417\n",
      "ktest: 897,\tv: 154,\tm: 1009,\tl: 1009,\tfdp: 0.17262712893362914\n",
      "ktest: 897,\tv: 153,\tm: 1009,\tl: 1009,\tfdp: 0.17151340552115413\n",
      "ktest: 896,\tv: 153,\tm: 1009,\tl: 1009,\tfdp: 0.17170482673267326\n",
      "ktest: 896,\tv: 152,\tm: 1009,\tl: 1009,\tfdp: 0.17058986032531823\n",
      "ktest: 896,\tv: 151,\tm: 1009,\tl: 1009,\tfdp: 0.16947489391796322\n",
      "ktest: 896,\tv: 150,\tm: 1009,\tl: 1009,\tfdp: 0.1683599275106082\n",
      "ktest: 896,\tv: 149,\tm: 1009,\tl: 1009,\tfdp: 0.16724496110325318\n",
      "ktest: 896,\tv: 148,\tm: 1009,\tl: 1009,\tfdp: 0.16612999469589815\n",
      "ktest: 895,\tv: 148,\tm: 1009,\tl: 1009,\tfdp: 0.16631561480170362\n",
      "ktest: 895,\tv: 147,\tm: 1009,\tl: 1009,\tfdp: 0.16519940262182642\n",
      "ktest: 894,\tv: 147,\tm: 1009,\tl: 1009,\tfdp: 0.16538418942565394\n",
      "ktest: 894,\tv: 146,\tm: 1009,\tl: 1009,\tfdp: 0.16426672868629144\n",
      "ktest: 893,\tv: 146,\tm: 1009,\tl: 1009,\tfdp: 0.16445067799053142\n",
      "ktest: 893,\tv: 145,\tm: 1009,\tl: 1009,\tfdp: 0.16333196589535773\n",
      "ktest: 893,\tv: 144,\tm: 1009,\tl: 1009,\tfdp: 0.16221325380018403\n",
      "ktest: 893,\tv: 143,\tm: 1009,\tl: 1009,\tfdp: 0.16109454170501036\n",
      "ktest: 892,\tv: 143,\tm: 1009,\tl: 1009,\tfdp: 0.16127514096701148\n",
      "ktest: 892,\tv: 142,\tm: 1009,\tl: 1009,\tfdp: 0.16015517471029614\n",
      "ktest: 892,\tv: 141,\tm: 1009,\tl: 1009,\tfdp: 0.1590352084535808\n",
      "ktest: 891,\tv: 141,\tm: 1009,\tl: 1009,\tfdp: 0.15921369914769257\n",
      "ktest: 890,\tv: 141,\tm: 1009,\tl: 1009,\tfdp: 0.1593925909444877\n",
      "ktest: 889,\tv: 141,\tm: 1009,\tl: 1009,\tfdp: 0.15957188519751864\n",
      "ktest: 888,\tv: 141,\tm: 1009,\tl: 1009,\tfdp: 0.15975158326643477\n",
      "ktest: 887,\tv: 141,\tm: 1009,\tl: 1009,\tfdp: 0.159931686517017\n",
      "ktest: 886,\tv: 141,\tm: 1009,\tl: 1009,\tfdp: 0.1601121963212123\n",
      "ktest: 886,\tv: 140,\tm: 1009,\tl: 1009,\tfdp: 0.15898464564289388\n",
      "ktest: 886,\tv: 139,\tm: 1009,\tl: 1009,\tfdp: 0.15785709496457548\n",
      "ktest: 885,\tv: 139,\tm: 1009,\tl: 1009,\tfdp: 0.15803546456340553\n",
      "ktest: 885,\tv: 138,\tm: 1009,\tl: 1009,\tfdp: 0.15690663981652406\n",
      "ktest: 884,\tv: 138,\tm: 1009,\tl: 1009,\tfdp: 0.1570841360154115\n",
      "ktest: 884,\tv: 137,\tm: 1009,\tl: 1009,\tfdp: 0.1559540343174589\n",
      "ktest: 883,\tv: 137,\tm: 1009,\tl: 1009,\tfdp: 0.1561306527028694\n",
      "ktest: 883,\tv: 136,\tm: 1009,\tl: 1009,\tfdp: 0.15499927116154427\n",
      "ktest: 882,\tv: 136,\tm: 1009,\tl: 1009,\tfdp: 0.15517500729664804\n",
      "ktest: 881,\tv: 136,\tm: 1009,\tl: 1009,\tfdp: 0.15535114237871006\n",
      "ktest: 880,\tv: 136,\tm: 1009,\tl: 1009,\tfdp: 0.15552767776777676\n",
      "ktest: 879,\tv: 136,\tm: 1009,\tl: 1009,\tfdp: 0.1557046148300837\n",
      "ktest: 879,\tv: 135,\tm: 1009,\tl: 1009,\tfdp: 0.15456808479482761\n",
      "ktest: 878,\tv: 135,\tm: 1009,\tl: 1009,\tfdp: 0.15474413044949142\n",
      "ktest: 877,\tv: 135,\tm: 1009,\tl: 1009,\tfdp: 0.15492057757657182\n",
      "ktest: 876,\tv: 135,\tm: 1009,\tl: 1009,\tfdp: 0.15509742755097428\n",
      "ktest: 876,\tv: 134,\tm: 1009,\tl: 1009,\tfdp: 0.15395700528957007\n",
      "ktest: 876,\tv: 133,\tm: 1009,\tl: 1009,\tfdp: 0.15281658302816584\n",
      "ktest: 875,\tv: 133,\tm: 1009,\tl: 1009,\tfdp: 0.1529912305516266\n",
      "ktest: 874,\tv: 133,\tm: 1009,\tl: 1009,\tfdp: 0.15316627772617078\n",
      "ktest: 874,\tv: 132,\tm: 1009,\tl: 1009,\tfdp: 0.15202324580284116\n",
      "ktest: 874,\tv: 131,\tm: 1009,\tl: 1009,\tfdp: 0.1508802138795115\n",
      "ktest: 874,\tv: 130,\tm: 1009,\tl: 1009,\tfdp: 0.14973718195618188\n",
      "ktest: 873,\tv: 130,\tm: 1009,\tl: 1009,\tfdp: 0.1499087022104272\n",
      "ktest: 872,\tv: 130,\tm: 1009,\tl: 1009,\tfdp: 0.1500806158597511\n",
      "ktest: 871,\tv: 130,\tm: 1009,\tl: 1009,\tfdp: 0.15025292425913087\n",
      "ktest: 870,\tv: 130,\tm: 1009,\tl: 1009,\tfdp: 0.15042562876977353\n",
      "ktest: 870,\tv: 129,\tm: 1009,\tl: 1009,\tfdp: 0.1492773415272562\n",
      "ktest: 870,\tv: 128,\tm: 1009,\tl: 1009,\tfdp: 0.14812905428473883\n",
      "ktest: 870,\tv: 127,\tm: 1009,\tl: 1009,\tfdp: 0.14698076704222146\n",
      "ktest: 870,\tv: 126,\tm: 1009,\tl: 1009,\tfdp: 0.14583247979970412\n",
      "ktest: 870,\tv: 125,\tm: 1009,\tl: 1009,\tfdp: 0.14468419255718676\n",
      "ktest: 870,\tv: 124,\tm: 1009,\tl: 1009,\tfdp: 0.1435359053146694\n",
      "ktest: 869,\tv: 124,\tm: 1009,\tl: 1009,\tfdp: 0.14370107896865636\n",
      "ktest: 868,\tv: 124,\tm: 1009,\tl: 1009,\tfdp: 0.14386663320709953\n",
      "ktest: 868,\tv: 123,\tm: 1009,\tl: 1009,\tfdp: 0.14271570014144272\n",
      "ktest: 868,\tv: 122,\tm: 1009,\tl: 1009,\tfdp: 0.1415647670757859\n",
      "ktest: 867,\tv: 122,\tm: 1009,\tl: 1009,\tfdp: 0.1417280482373497\n",
      "ktest: 866,\tv: 122,\tm: 1009,\tl: 1009,\tfdp: 0.14189170649166533\n",
      "ktest: 866,\tv: 121,\tm: 1009,\tl: 1009,\tfdp: 0.14073811538197697\n",
      "ktest: 866,\tv: 120,\tm: 1009,\tl: 1009,\tfdp: 0.13958452427228865\n",
      "ktest: 865,\tv: 120,\tm: 1009,\tl: 1009,\tfdp: 0.13974589366451096\n",
      "ktest: 865,\tv: 119,\tm: 1009,\tl: 1009,\tfdp: 0.13859096892348194\n",
      "ktest: 865,\tv: 118,\tm: 1009,\tl: 1009,\tfdp: 0.13743604418245292\n",
      "ktest: 864,\tv: 118,\tm: 1009,\tl: 1009,\tfdp: 0.13759511367803448\n",
      "ktest: 863,\tv: 118,\tm: 1009,\tl: 1009,\tfdp: 0.1377545518167112\n",
      "ktest: 862,\tv: 118,\tm: 1009,\tl: 1009,\tfdp: 0.13791435988146378\n",
      "ktest: 861,\tv: 118,\tm: 1009,\tl: 1009,\tfdp: 0.1380745391612332\n",
      "ktest: 860,\tv: 118,\tm: 1009,\tl: 1009,\tfdp: 0.13823509095095554\n",
      "ktest: 859,\tv: 118,\tm: 1009,\tl: 1009,\tfdp: 0.13839601655159695\n",
      "ktest: 859,\tv: 117,\tm: 1009,\tl: 1009,\tfdp: 0.13723302481586924\n",
      "ktest: 858,\tv: 117,\tm: 1009,\tl: 1009,\tfdp: 0.1373929700662374\n",
      "ktest: 858,\tv: 116,\tm: 1009,\tl: 1009,\tfdp: 0.13622862286228624\n",
      "ktest: 858,\tv: 115,\tm: 1009,\tl: 1009,\tfdp: 0.13506427565833506\n",
      "ktest: 858,\tv: 114,\tm: 1009,\tl: 1009,\tfdp: 0.1338999284543839\n",
      "ktest: 857,\tv: 114,\tm: 1009,\tl: 1009,\tfdp: 0.13405617107801795\n",
      "ktest: 857,\tv: 113,\tm: 1009,\tl: 1009,\tfdp: 0.13289046524255693\n",
      "ktest: 856,\tv: 113,\tm: 1009,\tl: 1009,\tfdp: 0.1330457111131674\n",
      "ktest: 856,\tv: 112,\tm: 1009,\tl: 1009,\tfdp: 0.13187864347182382\n",
      "ktest: 856,\tv: 111,\tm: 1009,\tl: 1009,\tfdp: 0.13071157583048026\n",
      "ktest: 856,\tv: 110,\tm: 1009,\tl: 1009,\tfdp: 0.12954450818913668\n",
      "ktest: 856,\tv: 109,\tm: 1009,\tl: 1009,\tfdp: 0.1283774405477931\n",
      "ktest: 855,\tv: 109,\tm: 1009,\tl: 1009,\tfdp: 0.12852758960106536\n",
      "ktest: 854,\tv: 109,\tm: 1009,\tl: 1009,\tfdp: 0.12867809029146476\n",
      "ktest: 853,\tv: 109,\tm: 1009,\tl: 1009,\tfdp: 0.12882894385569857\n",
      "ktest: 852,\tv: 109,\tm: 1009,\tl: 1009,\tfdp: 0.12898015153628037\n",
      "ktest: 852,\tv: 108,\tm: 1009,\tl: 1009,\tfdp: 0.12780760470413238\n",
      "ktest: 851,\tv: 108,\tm: 1009,\tl: 1009,\tfdp: 0.1279577899035497\n",
      "ktest: 851,\tv: 107,\tm: 1009,\tl: 1009,\tfdp: 0.12678386522553547\n",
      "ktest: 850,\tv: 107,\tm: 1009,\tl: 1009,\tfdp: 0.12693302271403611\n",
      "ktest: 849,\tv: 107,\tm: 1009,\tl: 1009,\tfdp: 0.12708253157471225\n",
      "ktest: 849,\tv: 106,\tm: 1009,\tl: 1009,\tfdp: 0.12590584146753897\n",
      "ktest: 848,\tv: 106,\tm: 1009,\tl: 1009,\tfdp: 0.12605431533719408\n",
      "ktest: 847,\tv: 106,\tm: 1009,\tl: 1009,\tfdp: 0.1262031397944989\n",
      "ktest: 847,\tv: 105,\tm: 1009,\tl: 1009,\tfdp: 0.12502367119828864\n",
      "ktest: 846,\tv: 105,\tm: 1009,\tl: 1009,\tfdp: 0.12517145331554433\n",
      "ktest: 846,\tv: 104,\tm: 1009,\tl: 1009,\tfdp: 0.12399059054841653\n",
      "ktest: 845,\tv: 104,\tm: 1009,\tl: 1009,\tfdp: 0.12413732497510105\n",
      "ktest: 845,\tv: 103,\tm: 1009,\tl: 1009,\tfdp: 0.12295506473724294\n",
      "ktest: 844,\tv: 103,\tm: 1009,\tl: 1009,\tfdp: 0.1231007460935667\n",
      "ktest: 843,\tv: 103,\tm: 1009,\tl: 1009,\tfdp: 0.1232467730758841\n",
      "ktest: 842,\tv: 103,\tm: 1009,\tl: 1009,\tfdp: 0.12339314691564168\n",
      "ktest: 841,\tv: 103,\tm: 1009,\tl: 1009,\tfdp: 0.12353986885014302\n",
      "ktest: 840,\tv: 103,\tm: 1009,\tl: 1009,\tfdp: 0.12368694012258367\n",
      "ktest: 839,\tv: 103,\tm: 1009,\tl: 1009,\tfdp: 0.12383436198208617\n",
      "ktest: 839,\tv: 102,\tm: 1009,\tl: 1009,\tfdp: 0.12264364696302765\n",
      "ktest: 838,\tv: 102,\tm: 1009,\tl: 1009,\tfdp: 0.12278999976369952\n",
      "ktest: 837,\tv: 102,\tm: 1009,\tl: 1009,\tfdp: 0.12293670227237778\n",
      "ktest: 837,\tv: 101,\tm: 1009,\tl: 1009,\tfdp: 0.12174314205614112\n",
      "ktest: 837,\tv: 100,\tm: 1009,\tl: 1009,\tfdp: 0.12054958183990444\n",
      "ktest: 837,\tv: 99,\tm: 1009,\tl: 1009,\tfdp: 0.11935602162366776\n",
      "ktest: 837,\tv: 98,\tm: 1009,\tl: 1009,\tfdp: 0.11816246140743109\n",
      "ktest: 836,\tv: 98,\tm: 1009,\tl: 1009,\tfdp: 0.118303804064617\n",
      "ktest: 835,\tv: 98,\tm: 1009,\tl: 1009,\tfdp: 0.11844548526708959\n",
      "ktest: 834,\tv: 98,\tm: 1009,\tl: 1009,\tfdp: 0.11858750623263765\n",
      "ktest: 834,\tv: 97,\tm: 1009,\tl: 1009,\tfdp: 0.11738965263432818\n",
      "ktest: 834,\tv: 96,\tm: 1009,\tl: 1009,\tfdp: 0.11619179903601871\n",
      "ktest: 834,\tv: 95,\tm: 1009,\tl: 1009,\tfdp: 0.11499394543770924\n",
      "ktest: 834,\tv: 94,\tm: 1009,\tl: 1009,\tfdp: 0.11379609183939977\n",
      "ktest: 834,\tv: 93,\tm: 1009,\tl: 1009,\tfdp: 0.1125982382410903\n",
      "ktest: 833,\tv: 93,\tm: 1009,\tl: 1009,\tfdp: 0.11273341019576147\n",
      "ktest: 832,\tv: 93,\tm: 1009,\tl: 1009,\tfdp: 0.11286890708301599\n",
      "ktest: 832,\tv: 92,\tm: 1009,\tl: 1009,\tfdp: 0.11166817402894134\n",
      "ktest: 832,\tv: 91,\tm: 1009,\tl: 1009,\tfdp: 0.11046744097486672\n",
      "ktest: 831,\tv: 91,\tm: 1009,\tl: 1009,\tfdp: 0.11060037411683406\n",
      "ktest: 830,\tv: 91,\tm: 1009,\tl: 1009,\tfdp: 0.11073362757962545\n",
      "ktest: 829,\tv: 91,\tm: 1009,\tl: 1009,\tfdp: 0.11086720252242353\n",
      "ktest: 828,\tv: 91,\tm: 1009,\tl: 1009,\tfdp: 0.111001100110011\n",
      "ktest: 827,\tv: 91,\tm: 1009,\tl: 1009,\tfdp: 0.11113532151280424\n",
      "ktest: 827,\tv: 90,\tm: 1009,\tl: 1009,\tfdp: 0.10992732888766507\n",
      "ktest: 826,\tv: 90,\tm: 1009,\tl: 1009,\tfdp: 0.1100604128209431\n",
      "ktest: 825,\tv: 90,\tm: 1009,\tl: 1009,\tfdp: 0.1101938193819382\n",
      "ktest: 825,\tv: 89,\tm: 1009,\tl: 1009,\tfdp: 0.10898289828982899\n",
      "ktest: 824,\tv: 89,\tm: 1009,\tl: 1009,\tfdp: 0.1091151590887244\n",
      "ktest: 823,\tv: 89,\tm: 1009,\tl: 1009,\tfdp: 0.10924774129903878\n",
      "ktest: 823,\tv: 88,\tm: 1009,\tl: 1009,\tfdp: 0.10803387750682723\n",
      "ktest: 823,\tv: 87,\tm: 1009,\tl: 1009,\tfdp: 0.10682001371461569\n",
      "ktest: 822,\tv: 87,\tm: 1009,\tl: 1009,\tfdp: 0.10694996506949965\n",
      "ktest: 821,\tv: 87,\tm: 1009,\tl: 1009,\tfdp: 0.1070802329928486\n",
      "ktest: 821,\tv: 86,\tm: 1009,\tl: 1009,\tfdp: 0.10586341216338441\n",
      "ktest: 820,\tv: 86,\tm: 1009,\tl: 1009,\tfdp: 0.10599251388553489\n",
      "ktest: 819,\tv: 86,\tm: 1009,\tl: 1009,\tfdp: 0.10612193087440612\n",
      "ktest: 819,\tv: 85,\tm: 1009,\tl: 1009,\tfdp: 0.10490213856550491\n",
      "ktest: 818,\tv: 85,\tm: 1009,\tl: 1009,\tfdp: 0.10503038078869013\n",
      "ktest: 817,\tv: 85,\tm: 1009,\tl: 1009,\tfdp: 0.10515893694632622\n",
      "ktest: 816,\tv: 85,\tm: 1009,\tl: 1009,\tfdp: 0.10528780819258397\n",
      "ktest: 815,\tv: 85,\tm: 1009,\tl: 1009,\tfdp: 0.1054169956872988\n",
      "ktest: 814,\tv: 85,\tm: 1009,\tl: 1009,\tfdp: 0.10554650059600555\n",
      "ktest: 813,\tv: 85,\tm: 1009,\tl: 1009,\tfdp: 0.10567632408997359\n",
      "ktest: 812,\tv: 85,\tm: 1009,\tl: 1009,\tfdp: 0.10580646734624202\n",
      "ktest: 811,\tv: 85,\tm: 1009,\tl: 1009,\tfdp: 0.10593693154765539\n",
      "ktest: 811,\tv: 84,\tm: 1009,\tl: 1009,\tfdp: 0.10470510676221755\n",
      "ktest: 810,\tv: 84,\tm: 1009,\tl: 1009,\tfdp: 0.1048343723261215\n",
      "ktest: 809,\tv: 84,\tm: 1009,\tl: 1009,\tfdp: 0.10496395745878669\n",
      "ktest: 808,\tv: 84,\tm: 1009,\tl: 1009,\tfdp: 0.10509386334673072\n",
      "ktest: 808,\tv: 83,\tm: 1009,\tl: 1009,\tfdp: 0.10385746495441625\n",
      "ktest: 807,\tv: 83,\tm: 1009,\tl: 1009,\tfdp: 0.10398616069785419\n",
      "ktest: 806,\tv: 83,\tm: 1009,\tl: 1009,\tfdp: 0.10411517578556864\n",
      "ktest: 805,\tv: 83,\tm: 1009,\tl: 1009,\tfdp: 0.1042445114076625\n",
      "ktest: 804,\tv: 83,\tm: 1009,\tl: 1009,\tfdp: 0.1043741687601596\n",
      "ktest: 803,\tv: 83,\tm: 1009,\tl: 1009,\tfdp: 0.10450414904504149\n",
      "ktest: 802,\tv: 83,\tm: 1009,\tl: 1009,\tfdp: 0.1046344534702847\n",
      "ktest: 801,\tv: 83,\tm: 1009,\tl: 1009,\tfdp: 0.10476508324989803\n",
      "ktest: 801,\tv: 82,\tm: 1009,\tl: 1009,\tfdp: 0.10351787987787543\n",
      "ktest: 800,\tv: 82,\tm: 1009,\tl: 1009,\tfdp: 0.10364727722772278\n",
      "ktest: 799,\tv: 82,\tm: 1009,\tl: 1009,\tfdp: 0.10377699847581755\n",
      "ktest: 798,\tv: 82,\tm: 1009,\tl: 1009,\tfdp: 0.10390704483982233\n",
      "ktest: 798,\tv: 81,\tm: 1009,\tl: 1009,\tfdp: 0.10265515273331843\n",
      "ktest: 797,\tv: 81,\tm: 1009,\tl: 1009,\tfdp: 0.10278395468154092\n",
      "ktest: 796,\tv: 81,\tm: 1009,\tl: 1009,\tfdp: 0.1029130802527489\n",
      "ktest: 795,\tv: 81,\tm: 1009,\tl: 1009,\tfdp: 0.10304253066816116\n",
      "ktest: 794,\tv: 81,\tm: 1009,\tl: 1009,\tfdp: 0.10317230715514876\n",
      "ktest: 794,\tv: 80,\tm: 1009,\tl: 1009,\tfdp: 0.10191410828740305\n",
      "ktest: 793,\tv: 80,\tm: 1009,\tl: 1009,\tfdp: 0.10204262544791678\n",
      "ktest: 792,\tv: 80,\tm: 1009,\tl: 1009,\tfdp: 0.10217146714671467\n",
      "ktest: 791,\tv: 80,\tm: 1009,\tl: 1009,\tfdp: 0.10230063461466248\n",
      "ktest: 790,\tv: 80,\tm: 1009,\tl: 1009,\tfdp: 0.10243012908885825\n",
      "ktest: 789,\tv: 80,\tm: 1009,\tl: 1009,\tfdp: 0.10255995181267177\n",
      "ktest: 789,\tv: 79,\tm: 1009,\tl: 1009,\tfdp: 0.10129377956807088\n",
      "ktest: 788,\tv: 79,\tm: 1009,\tl: 1009,\tfdp: 0.10142232497361413\n",
      "ktest: 788,\tv: 78,\tm: 1009,\tl: 1009,\tfdp: 0.10015454591144395\n",
      "ktest: 787,\tv: 78,\tm: 1009,\tl: 1009,\tfdp: 0.10028180708795148\n",
      "ktest: 786,\tv: 78,\tm: 1009,\tl: 1009,\tfdp: 0.10040939208424658\n",
      "ktest: 785,\tv: 78,\tm: 1009,\tl: 1009,\tfdp: 0.1005373021378571\n",
      "ktest: 784,\tv: 78,\tm: 1009,\tl: 1009,\tfdp: 0.10066553849262477\n",
      "ktest: 783,\tv: 78,\tm: 1009,\tl: 1009,\tfdp: 0.10079410239874562\n",
      "ktest: 782,\tv: 78,\tm: 1009,\tl: 1009,\tfdp: 0.10092299511281051\n",
      "ktest: 782,\tv: 77,\tm: 1009,\tl: 1009,\tfdp: 0.09964548884555974\n",
      "Got FDP of 0.09964548884555974 <= alpha(0.1) , for lower bound: 1159\n",
      "Total elements in window: 859\n",
      "Total discoveries in window: 782\n",
      "False discoveries: 0\n"
     ]
    }
   ],
   "source": [
    "DISCOVERY_EPOCHS = 1\n",
    "N_CLASSES = 2\n",
    "# DEVICE = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "DEVICE = torch.device(\"cpu\") # No point in using MPS for now :( See https://github.com/pytorch/pytorch/issues/77799\n",
    "\n",
    "clean_training_set, clean_test_set = get_datasets_for_discovery()\n",
    "\n",
    "# model = nn.DataParallel(LeNet5(N_CLASSES)).to(DEVICE)\n",
    "\n",
    "clean_discovery_results = []\n",
    "for i in range(DISCOVERY_EPOCHS):\n",
    "    clean_discovery_results.append(run_discovery(clean_training_set, clean_test_set, model))\n",
    "\n",
    "# print(clean_discovery_results)\n",
    "# noisy_discovery_results = []\n",
    "# for i in range(DISCOVERY_EPOCHS):\n",
    "#     noisy_discovery_results.append(run_discovery(clean_training_dataset, noisy_test_dataset, LeNet5(N_CLASSES)))\n",
    "\n",
    "# ae_powered_noisy_discovery_results = []\n",
    "# for i in range(DISCOVERY_EPOCHS):\n",
    "#     ae_powered_noisy_discovery_results.append(run_discovery(clean_training_dataset, noisy_test_dataset, LeNet5(N_CLASSES), ae=LeNet5AutoEncoder(latent_size=20))\n",
    "    \n",
    "# compare_discovery_results([clean_discovery_results, noisy_discovery_results, ae_powered_noisy_discovery_results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33168c6-c818-49b9-b88f-c6163fc9997b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
