{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "ce214c74-c41b-4cbc-9d0c-1e107bfa5aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "from torch.utils.data import Dataset as Dataset\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal\n",
    "from matplotlib import pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from datetime import datetime\n",
    "from typing import Optional, TextIO\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "7977481a-dcd8-4ce9-932c-2558cca2b59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cpu\") # No point in using MPS for now :( See https://github.com/pytorch/pytorch/issues/77799"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95be1ac1-bb89-49c3-ae3f-32ec426172dd",
   "metadata": {},
   "source": [
    "## NN Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "06298ae5-d3f4-4865-8d24-7546ba410958",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses_over_epochs(train_losses: list[float], valid_losses: list[float]):\n",
    "    '''\n",
    "    Graphically show the training and validation loss for each epoch.\n",
    "    '''\n",
    "    \n",
    "    # temporarily change the style of the plots to seaborn \n",
    "    plt.style.use('seaborn')\n",
    "\n",
    "    train_losses = np.array(train_losses) \n",
    "    valid_losses = np.array(valid_losses)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize = (8, 4.5))\n",
    "\n",
    "    ax.plot(train_losses, color='blue', label='Training loss') \n",
    "    ax.plot(valid_losses, color='red', label='Validation loss')\n",
    "    ax.set(title=\"Loss over epochs\", \n",
    "            xlabel='Epoch',\n",
    "            ylabel='Loss') \n",
    "    ax.legend()\n",
    "    fig.show()\n",
    "    \n",
    "    # change the plot style to default\n",
    "    plt.style.use('default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "b68323c6-3567-4d0f-a193-aa326d43f069",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_single_epoch(loader, criterion, model, optimizer, normalize_input_fn, normalize_labels_fn, positive_class = 1, train=True):\n",
    "    '''\n",
    "    Implementation a single epoch for the training/validation loop.\n",
    "    '''        \n",
    "    \n",
    "    model.train() if train else model.eval() \n",
    "    \n",
    "    running_loss = 0\n",
    "    \n",
    "    # Each iteration gets a batch from the train loader\n",
    "    for X, Y_true in loader:\n",
    "        X = normalize_input_fn(X) # Normalizing the input if necessary\n",
    "        X = X.to(DEVICE)\n",
    "        Y_true = Y_true.to(DEVICE)\n",
    "        # Y_true = normalize_labels_fn(Y_true)\n",
    "        # Y_true[Y_true == positive_class]  = 1 # We \"normalize\" the label of the positive class to be \"1\". Makes our lives easier (see comment below)\n",
    "        \n",
    "        optimizer.zero_grad() if train else None\n",
    "        \n",
    "        # Forward pass\n",
    "        Y_logits, Y_prob = model(X)\n",
    "        _, predicted_labels = torch.max(Y_prob, 1)  # The \"1\" is acutally misleading - it's the dimension to search the max in.\n",
    "                                                        # This actually returns the indices of the highest prediction for each row, \n",
    "                                                        # but since the index is one-to-one with the predicted digit (i.e., 0 or 1), \n",
    "                                                        # we use the index of the max probability as the label that's being predicted\n",
    "        batch_loss = criterion(Y_logits, Y_true) # we use the logits as the parameter since \"CELoss already pefroms softmax internally.\n",
    "        running_loss += batch_loss.item() * X.size(0) # X.size(0) is the size of the BATCH, not the image. \n",
    "                                                # The multiplication is required later for calculating the avg loss of the epoch step.\n",
    "        \n",
    "        # Backward pass, only required in training the model\n",
    "        if train:\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    avg_batch_loss_for_epoch = running_loss / len(loader.dataset)\n",
    "    return model, optimizer, avg_batch_loss_for_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "7e981840-3d2d-4cf4-99bb-82347b160df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_loop(train_loader, validation_loader, criterion, model, optimizer, positive_class=1, num_epochs=10, normalize_input_fn=lambda x: x, \n",
    "             normalize_labels_fn=lambda y: y, print_every=1):\n",
    "    \n",
    "    # Objects for storing metrics\n",
    "    best_loss = 1e10\n",
    "    train_losses = []\n",
    "    validation_losses = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # print(f'Epoch: {epoch}\\t')\n",
    "        \n",
    "        # Training the model\n",
    "        _, _, train_loss = run_single_epoch(train_loader, criterion, model, optimizer, normalize_input_fn, normalize_labels_fn, positive_class)\n",
    "        train_losses.append(train_loss)\n",
    "        \n",
    "        # No need for validation when working with a score model\n",
    "        validation_losses.append(0)\n",
    "        # # Validation\n",
    "        # with torch.no_grad():\n",
    "        #     _, _, validation_loss = run_single_epoch(validation_loader, criterion, model, None, normalize_input_fn, normalize_labels_fn, positive_class, False)\n",
    "        #     validation_losses.append(validation_loss)\n",
    "        \n",
    "        # if epoch % print_every == (print_every - 1):\n",
    "        #     print(f'{datetime.now().time().replace(microsecond=0)} --- '\n",
    "        #           f'Epoch: {epoch}\\t'\n",
    "        #           f'Train loss: {train_loss:.4f}\\t'\n",
    "        #           # f'Vaildation loss: {validation_loss:.4f}\\t')\n",
    "        #           f'Vaildation loss: 0\\t')\n",
    "    \n",
    "    plot_losses_over_epochs(train_losses, validation_losses)\n",
    "        \n",
    "    return model, optimizer, num_epochs, (train_losses, validation_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d4ae6f-9b94-4f17-8a2d-0625afb7dfe4",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "558223a6-75d2-48f9-8fd1-6165d46c57f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet5(nn.Module):\n",
    "\n",
    "    def __init__(self, n_classes):\n",
    "        \n",
    "        super(LeNet5, self).__init__()\n",
    "        \n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1),\n",
    "            nn.Tanh(),\n",
    "            nn.AvgPool2d(kernel_size=2),\n",
    "            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1),\n",
    "            nn.Tanh(),\n",
    "            nn.AvgPool2d(kernel_size=2),\n",
    "            nn.Conv2d(in_channels=16, out_channels=120, kernel_size=5, stride=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(in_features=120, out_features=84),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(in_features=84, out_features=n_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        logits = self.classifier(x)\n",
    "        probabilities = F.softmax(logits, dim=1)\n",
    "        return logits, probabilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "fc3d7d05-586c-4e42-af9c-d3e93d6f5c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleDataSet(Dataset):\n",
    "    def __init__(self, data, targets):\n",
    "        super(SimpleDataSet, self).__init__()\n",
    "        assert data.shape[0] == targets.shape[0] # assuming shape[0] = dataset size\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.targets.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index], self.targets[index].item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43c239e-e344-4637-9237-8399aa06771b",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "63413eaa-252b-4e06-8ec9-dd56edf12f68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000, 10.5841],\n",
       "        [ 0.0000,  5.8487]])"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# s = torch.stack((positive_mv.sample(), positive_mv.sample()))\n",
    "# s2 = positive_mv.log_prob(s) - null_mv.log_prob(s)\n",
    "\n",
    "s3 = torch.stack((torch.zeros(s2.view(-1,1).shape[0]).view(-1,1),s2.view(-1,1)), dim=1)\n",
    "s3.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "823dd6c8-4934-46a6-ae3b-9ac6e9aa6eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LikelihoodRatioModel():\n",
    "    def __init__(self, vae, null_mv, positive_mv):\n",
    "        self.vae = vae\n",
    "        self.null_mv = null_mv\n",
    "        self.positive_mv = positive_mv\n",
    "    \n",
    "    def __call__(self, value):\n",
    "        mu_logvar = self.vae.encoder(value.view(-1, 784)).view(-1, 2, LATENT_DIM)\n",
    "        mu = mu_logvar[:, 0, :]\n",
    "        llr = self.positive_mv.log_prob(mu) - self.null_mv.log_prob(mu)\n",
    "        # We need a 0s \"column as the first col to represent the probability of the \"null\" class (same as LeNet result)\n",
    "        llr_0_padded_right = torch.stack((torch.zeros(llr.view(-1,1).shape[0]).view(-1,1),llr.view(-1,1)), dim=1).squeeze()\n",
    "        return None, llr_0_padded_right\n",
    "    \n",
    "    def eval(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86b6c0a-f40b-48fb-a9cf-723d020a1a38",
   "metadata": {},
   "source": [
    "## Samples Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "04d0731f-1cff-4681-84c4-203d8ef7cf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "LATENT_DIM = 5\n",
    "\n",
    "class VAEFC(nn.Module):\n",
    "    '''\n",
    "    A fully-connectec variational autoencoder (as opposed to convolution-based) used as generative model for MNIST.\n",
    "    '''\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(784, 400),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(400, 400),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(400, LATENT_DIM * 2)\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(LATENT_DIM, 400),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(400, 400),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(400, 784),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def reparameterise(self, mu, logvar):\n",
    "        if self.training:\n",
    "            std = logvar.mul(0.5).exp_()\n",
    "            eps = std.new_empty(std.size()).normal_()\n",
    "            return eps.mul_(std).add_(mu)\n",
    "        else:\n",
    "            return mu\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu_logvar = self.encoder(x.view(-1, 784)).view(-1, 2, LATENT_DIM)\n",
    "        mu = mu_logvar[:, 0, :]\n",
    "        logvar = mu_logvar[:, 1, :]\n",
    "        z = self.reparameterise(mu, logvar)\n",
    "        return self.decoder(z), mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "24be2c54-bcf3-47b0-aced-f08bf43e5df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_loss_for_single_element_batch(x_hat, x, mu, logvar, y=None, β=3):\n",
    "    '''\n",
    "    'Dynamic' loss: changes based on the type of MNIST digit. This forces the VAE to place each digit near the mean we want, effectively\n",
    "    creating a mixture model of normals.\n",
    "\n",
    "    IMPORTANT: THIS WILL ONLY WORK WITH BATCH_SIZE=1 because otherwise the loss will not be calculated correctly.\n",
    "    '''\n",
    "    base_loss = nn.functional.binary_cross_entropy(\n",
    "        x_hat, x.view(-1, 784), reduction='sum'\n",
    "    )\n",
    "    # KLD = 0.5 * torch.sum(logvar.exp() - logvar - 1 + mu.pow(2)) # Orig KLD\n",
    "    \n",
    "    # KLD(p,q) = KL(N(m1,s1), N(m2,s2)) = log(std2/std1) + (s1 + ((m1-m2)^2))/(2*s2) - 1/2    , where s is VARIANCE (not STD), std1=sqrt(s1)\n",
    "    KLD = 0\n",
    "    if y[0]==4:\n",
    "        KLD = 0.5 * torch.sum(logvar.exp() - logvar + (mu-1).pow(2) -1)\n",
    "    else:\n",
    "        KLD = 0.5 * torch.sum(logvar.exp() - logvar + (mu+1).pow(2) -1)\n",
    "    return base_loss + β * KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "6fd0552d-1b97-416a-ba3f-5f52d234ea0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data loading step\n",
    "\n",
    "class_map = {\"null\": 4, \"positive\": 9}\n",
    "labels_map = {4:0, 9:1} \n",
    "\n",
    "def get_loader_for_vae(dataset, class_to_load=None, batch_size=1, num_samples=None):\n",
    "    if class_to_load is None:\n",
    "        samples_index = torch.logical_or(dataset.targets == class_map[\"null\"] ,dataset.targets == class_map[\"positive\"]).nonzero().reshape(-1)\n",
    "    else:\n",
    "        samples_index = (dataset.targets == class_map[class_to_load]).nonzero().reshape(-1)\n",
    "    if num_samples is not None:\n",
    "        samples_index = samples_index[:num_samples]\n",
    "    print(F\"sample index: {samples_index.shape}\")\n",
    "    return DataLoader(dataset,batch_size=batch_size, shuffle=False, sampler=SubsetRandomSampler(samples_index), drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "a1b0f7c8-eb16-42f8-9ab6-38b1e99e27e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_VAE(vae, train_loader, vae_criterion, epochs=2):\n",
    "    \n",
    "    learning_rate = 1e-3\n",
    "    \n",
    "    vae_optimizer = torch.optim.Adam(\n",
    "        vae.parameters(),\n",
    "        lr=learning_rate,\n",
    "    )\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        vae.train()\n",
    "        train_loss = 0\n",
    "        print(f'====> VAE Epoch: {epoch}')\n",
    "        for x, label in train_loader:\n",
    "            x = x.to(DEVICE)\n",
    "            # ===================forward=====================\n",
    "            x_hat, mu, logvar = vae(x)\n",
    "            loss = vae_criterion(x_hat, x, mu, logvar, label)\n",
    "            train_loss += loss.item()\n",
    "            # ===================backward====================\n",
    "            vae_optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            vae_optimizer.step()\n",
    "        # ===================log========================\n",
    "        print(f'VAE Average loss: {train_loss / len(train_loader.dataset):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "1fda199d-5447-446c-885d-ae0403ba8a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict\n",
    "\n",
    "VAECodes = TypedDict('VAECodes', {'mu': torch.Tensor, 'logvar': torch.Tensor, 'label': torch.Tensor})\n",
    "\n",
    "def get_VAE_codes_for_samples(vae: torch.nn.Module, loader: torch.utils.data.DataLoader) -> VAEResult: \n",
    "    codes = dict(mu=list(), logvar=list(), label=list())\n",
    "    means, logvars, labels = list(), list(), list()\n",
    "    with torch.no_grad():\n",
    "        vae.eval()\n",
    "        for x, y in loader:\n",
    "            x = x.to(DEVICE)\n",
    "            # ===================forward=====================\n",
    "            x_hat, mu, logvar = vae(x)\n",
    "            # =====================log=======================\n",
    "            means.append(mu.detach())\n",
    "            logvars.append(logvar.detach())\n",
    "            labels.append(y.detach())\n",
    "    # ===================log========================\n",
    "    codes['mu'] = torch.cat(means)\n",
    "    codes['logvar']= torch.cat(logvars)\n",
    "    codes['label'] = torch.cat(labels)\n",
    "    return codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "7233c658-11cb-455b-8ef5-6a2f875f7a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_and_vcov_for_vae_codes(codes: VAECodes):\n",
    "        mean_tensor = codes['mu'].mean(0)\n",
    "        centered_mus = codes['mu'] - mean_tensor\n",
    "        vcov = centered_mus.T.cov()\n",
    "        return dict(mean=mean_tensor, vcov=vcov, centered_mus=centered_mus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "792edc8b-4753-49d1-99e8-9422cc9506e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "VAEResult = TypedDict('VAEResult', {'vae': torch.nn.Module, 'null_mean': torch.Tensor, 'positive_mean':torch.Tensor, 'common_vcov': torch.Tensor})\n",
    "                      \n",
    "def get_trained_vae() -> torch.nn.Module:\n",
    "    '''\n",
    "    Returns: an MNIST-trained VAE.\n",
    "    '''\n",
    "    # Loading relevant data\n",
    "    train_all_loader = get_loader_for_vae(MNIST('./data', train=True, download=True, transform=transforms.ToTensor()))\n",
    "\n",
    "    # Create and train the VAE\n",
    "    vae = VAEFC().to(DEVICE)\n",
    "    train_VAE(vae, train_all_loader, vae_loss_for_single_element_batch)\n",
    "    \n",
    "    return vae\n",
    "\n",
    "\n",
    "def get_vae_stats(vae: torch.nn.Module):\n",
    "    '''\n",
    "    Parameters:\n",
    "        vae: The MNIST-trained VAE to get the stats from.\n",
    "    \n",
    "    Returns:\n",
    "        a Dictionary of the form: {null_mean: torch.Tensor, positive_mean: torch.Tensor, common_vcov: torch.Tensor} \n",
    "    '''\n",
    "    # Loading relevant data\n",
    "    train_null_only = get_loader_for_vae(MNIST('./data', train=True, download=True, transform=transforms.ToTensor()), class_to_load=\"null\")\n",
    "    train_positive_only = get_loader_for_vae(MNIST('./data', train=True, download=True, transform=transforms.ToTensor()), class_to_load=\"positive\")\n",
    "    \n",
    "    # get codes for null and positive classes\n",
    "    null_codes = get_VAE_codes_for_samples(vae, train_null_only)\n",
    "    positive_codes = get_VAE_codes_for_samples(vae, train_positive_only)\n",
    "    \n",
    "    # get the interesting stats to be used for the generation later\n",
    "    null_stats = get_mean_and_vcov_for_vae_codes(null_codes)\n",
    "    positive_stats = get_mean_and_vcov_for_vae_codes(positive_codes)\n",
    "    \n",
    "    # calculate common vcov matrix (we want this so that the likelihood ratio will translate to LDA).\n",
    "    all_centered_means = torch.cat((null_stats['centered_mus'], positive_stats['centered_mus']))\n",
    "    common_vcov= all_centered_means.T.cov()\n",
    "    \n",
    "    return dict(null_mean=null_stats['mean'], positive_mean=positive_stats['mean'], common_vcov=common_vcov)\n",
    "    \n",
    "    \n",
    "def get_trained_vae_and_stats() -> VAEResult:\n",
    "    vae = get_trained_vae()\n",
    "    stats = get_vae_stats(vae)\n",
    "    return dict(vae=vae, null_mean=stats['null_mean'], positive_mean=stats['positive_mean'], common_vcov=stats['common_vcov'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "dae9f1b8-4dc2-459b-98e3-ec017203476d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_generated_datasets_from_vae(vae: torch.nn.Module, null_mv: torch.distributions.MultivariateNormal, positive_mv: torch.distributions.MultivariateNormal):\n",
    "    \n",
    "    TRAINING_SIZE = 4000\n",
    "    TEST_NULL_SIZE = 1000\n",
    "    TEST_POSITIVE_SIZE = 2000\n",
    "    BENCHMARK_NULL_SIZE = 2000\n",
    "    BENCHMARK_POSITIVE_SIZE = 2000\n",
    "    with torch.no_grad():\n",
    "        vae.eval()\n",
    "        \n",
    "        # Training set (only 4s)\n",
    "        training_codes = null_mv.sample(torch.Size([TRAINING_SIZE]))\n",
    "        training_data = vae.decoder(training_codes)\n",
    "        training_targets = torch.repeat_interleave(torch.tensor([0]), TRAINING_SIZE)\n",
    "        training_set = SimpleDataSet(training_data, training_targets)\n",
    "\n",
    "        # Benchmark set (4 and 9s)\n",
    "        benchmark_null_codes = null_mv.sample(torch.Size([BENCHMARK_NULL_SIZE]))\n",
    "        benchmark_positive_codes = positive_mv.sample(torch.Size([BENCHMARK_POSITIVE_SIZE]))\n",
    "        benchmark_codes = torch.cat((benchmark_null_codes, benchmark_positive_codes)) \n",
    "        benchmark_null_targets = torch.repeat_interleave(torch.tensor([0]), BENCHMARK_NULL_SIZE)\n",
    "        benchmark_positive_targets = torch.repeat_interleave(torch.tensor([1]), BENCHMARK_POSITIVE_SIZE)\n",
    "        benchmark_targets = torch.cat((benchmark_null_targets, benchmark_positive_targets)) \n",
    "        shuffle = torch.randperm(BENCHMARK_NULL_SIZE + BENCHMARK_POSITIVE_SIZE) # we want mixed, random-ordered samples\n",
    "        benchmark_codes = benchmark_codes[shuffle]\n",
    "        benchmark_targets = benchmark_targets[shuffle]\n",
    "        benchmark_data = vae.decoder(benchmark_codes)\n",
    "        benchmark_set = SimpleDataSet(benchmark_data, benchmark_targets)\n",
    "\n",
    "\n",
    "        # Test set (4 and 9s)\n",
    "        test_null_codes = null_mv.sample(torch.Size([TEST_NULL_SIZE]))\n",
    "        test_positive_codes = positive_mv.sample(torch.Size([TEST_POSITIVE_SIZE]))\n",
    "        test_codes = torch.cat((test_null_codes, test_positive_codes)) \n",
    "        test_null_targets = torch.repeat_interleave(torch.tensor([0]), TEST_NULL_SIZE)\n",
    "        test_positive_targets = torch.repeat_interleave(torch.tensor([1]), TEST_POSITIVE_SIZE)\n",
    "        test_targets = torch.cat((test_null_targets, test_positive_targets)) \n",
    "        shuffle = torch.randperm(TEST_NULL_SIZE + TEST_POSITIVE_SIZE) # we want mixed, random-ordered samples\n",
    "        test_codes = test_codes[shuffle]\n",
    "        test_targets = test_targets[shuffle]\n",
    "        test_data = vae.decoder(test_codes)\n",
    "        test_set = SimpleDataSet(test_data, test_targets)\n",
    "\n",
    "        return training_set, test_set, benchmark_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc3169d-bb28-4a84-b604-40abc522e731",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "9c8f9c0d-79aa-49ad-94d0-8cd3088668b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trained_model(train_loader, test_loader, num_epochs=20):\n",
    "    LEARNING_RATE = 1e-3\n",
    "    N_CLASSES = 2\n",
    "    \n",
    "    model = nn.DataParallel(LeNet5(N_CLASSES)) # We create the model from scratch for each experiment\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    return run_loop(train_loader, test_loader, criterion, model, optimizer, normalize_input_fn=lambda x: x / 255.0, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "47ae51f0-5daa-445a-bfdb-62fc6324098e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConcatDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, datasetA, datasetB):\n",
    "        super(ConcatDataset, self).__init__()\n",
    "        self.datasetA = datasetA\n",
    "        self.datasetB = datasetB\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        if i<len(self.datasetA):\n",
    "            return self.datasetA[i]\n",
    "        else:\n",
    "            return self.datasetB[i-len(self.datasetA)]\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.datasetA) + len(self.datasetB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "9c86dc35-165a-4a32-a553-f7d20d4e48a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def clone_and_new_computation_graph(t: torch.Tensor, requires_grad=True) -> torch.Tensor:\n",
    "    '''\n",
    "        Returns: \n",
    "            A Tensor with the same data (copied) as `t`, on a new computation graph\n",
    "    '''\n",
    "    t2 = torch.detach(t).clone()\n",
    "    if requires_grad:\n",
    "        t2.requires_grad_()\n",
    "    return t2\n",
    "\n",
    "\n",
    "def get_synthetic_h0_h1(training_set: SimpleDataSet, test_set: SimpleDataSet) -> tuple[SimpleDataSet, SimpleDataSet, SimpleDataSet, int]:\n",
    "    '''\n",
    "    Parameters:\n",
    "        Training and Test datasets. Each of the following form:\n",
    "            Dataset.data: 4-D tensor (batch size, channels, width, height). This is because nn.Conv2d expects input of this shape.\n",
    "            Dataset.targets: 1-D tensor (target class)\n",
    "    Returns:\n",
    "        H0, H1, H1 with true target values (used for validation), K\n",
    "    '''\n",
    "    \n",
    "    # k = math.floor(len(training_set) / 2) # TODO sample random k instead?\n",
    "    k = len(training_set)- len(test_set) # TODO sample random k instead?\n",
    "    # k = len(training_set) - 50\n",
    "    original_training_data = training_set.data\n",
    "    original_training_targets = training_set.targets\n",
    "\n",
    "    # Create H0 set by *copying* the training set, and have it use a separate computation graph.\n",
    "    h0_data = clone_and_new_computation_graph(original_training_data[:k])\n",
    "    h0_targets = clone_and_new_computation_graph(original_training_targets[:k], requires_grad=False)\n",
    "    h0_targets[:] = 0\n",
    "\n",
    "    h0_set = SimpleDataSet(h0_data, h0_targets)\n",
    "    \n",
    "    # Create H1 and H1_true_targets sets by *copying* the data and have it use a separate computation graph\n",
    "    h1_0_data = clone_and_new_computation_graph(original_training_data[k:])\n",
    "    h1_0_targets = clone_and_new_computation_graph(original_training_targets[k:], requires_grad=False)\n",
    "    h1_0_targets[:] = 1\n",
    "        \n",
    "    h1_0_data_for_true_targets = clone_and_new_computation_graph(original_training_data[k:])\n",
    "    h1_0_true_targets = clone_and_new_computation_graph(original_training_targets[k:], requires_grad=False)\n",
    "    \n",
    "    original_test_data = test_set.data\n",
    "    original_test_targets = test_set.targets\n",
    "    h1_1_data = clone_and_new_computation_graph(original_test_data)\n",
    "    h1_1_targets = clone_and_new_computation_graph(original_test_targets, requires_grad=False)\n",
    "    h1_1_targets[:] = 1\n",
    "    \n",
    "    h1_1_data_for_true_targets = clone_and_new_computation_graph(original_test_data)\n",
    "    h1_1_true_targets = clone_and_new_computation_graph(original_test_targets, requires_grad=False)\n",
    "    \n",
    "    h1_data = torch.cat((h1_0_data, h1_1_data), 0)\n",
    "    h1_targets = torch.cat((h1_0_targets, h1_1_targets), 0)\n",
    "    \n",
    "    h1_set = SimpleDataSet(h1_data, h1_targets)\n",
    "    \n",
    "    h1_data_true = torch.cat((h1_0_data_for_true_targets, h1_1_data_for_true_targets), 0)\n",
    "    h1_targets_true = torch.cat((h1_0_true_targets, h1_1_true_targets), 0)\n",
    "    \n",
    "    h1_set_with_true_targets = SimpleDataSet(h1_data_true, h1_targets_true)\n",
    "    \n",
    "\n",
    "    return h0_set, h1_set, h1_set_with_true_targets, k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "d6e556c7-9a5d-4d26-bba3-64222e4a204d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datasets_for_discovery(experiment_type: int, add_noise=False) -> tuple[SimpleDataSet, SimpleDataSet]:\n",
    "    '''\n",
    "    Parameters:\n",
    "        experiment_type:\n",
    "            1 - test data is only H1, no noise\n",
    "            2 - test data is a mix of H0 and H1, no noise\n",
    "            \n",
    "    Returns:\n",
    "        A Tuple of (training_set, test_set, benchmark_set)\n",
    "            Dataset.data: 4-D tensor (batch size, channels, width, height). This is because nn.Conv2d expects input of this shape.\n",
    "            Dataset.targets: 1-D tensor (target class)\n",
    "    '''\n",
    "    \n",
    "    BENCHMARK_TRAINING_SIZE = 1000 # data used for training a *standard* classifier for benchmark purposes\n",
    "    \n",
    "    image_padding_to_32 = transforms.Compose([transforms.Resize((32,32)), transforms.ToTensor()])\n",
    "    \n",
    "    if add_noise:\n",
    "        raise NotImplementedError(\"Adding noise was not yet implemented\")\n",
    "        \n",
    "    ## Training data\n",
    "    training_set_full = datasets.MNIST(root='./data', download=True, transform=image_padding_to_32, train=True)\n",
    "    training_subset_index = (training_set_full.targets == 4).nonzero().reshape(-1)\n",
    "    training_subset_loader = torch.utils.data.DataLoader(dataset=training_set_full, batch_size=len(training_subset_index), shuffle=False, sampler=Data.SubsetRandomSampler(training_subset_index))\n",
    "    training_subset_data, training_subset_targets = next(iter(training_subset_loader)) # We only need one iteration, as the loader has the size of the entire relevant sample\n",
    "\n",
    "    assert len(training_subset_targets[(training_subset_targets!=4).nonzero().reshape(-1)])==0 # Avoid bugs in data loading. You're welcome hahaha\n",
    "    \n",
    "    training_subset_targets[(training_subset_targets==4).nonzero().reshape(-1)] = 0  # Set the targets' value to 0 (as this is our \"null\" class).\n",
    "\n",
    "    # Separating training for Adadetect and benchmark\n",
    "    benchmark_four_subset_data = training_subset_data[-BENCHMARK_TRAINING_SIZE:]\n",
    "    benchmark_four_subset_targets = training_subset_targets[-BENCHMARK_TRAINING_SIZE:]\n",
    "    \n",
    "    # Notice that since we update training_subset_data itself, this MUST happen AFTER we already got the benchmark data.\n",
    "    training_subset_data = training_subset_data[:-BENCHMARK_TRAINING_SIZE]\n",
    "    training_subset_targets = training_subset_targets[:-BENCHMARK_TRAINING_SIZE]\n",
    "    \n",
    "    benchmark_nine_subset_index = (training_set_full.targets == 9).nonzero().reshape(-1)\n",
    "    benchmark_nine_subset_loader = torch.utils.data.DataLoader(dataset=training_set_full, batch_size=len(benchmark_nine_subset_index), shuffle=False, sampler=Data.SubsetRandomSampler(benchmark_nine_subset_index))\n",
    "    benchmark_nine_subset_data, benchmark_nine_subset_targets = next(iter(benchmark_nine_subset_loader)) \n",
    "    \n",
    "    assert len(benchmark_nine_subset_targets[(benchmark_nine_subset_targets!=9).nonzero().reshape(-1)])==0 # Avoid bugs in data loading. You're welcome hahaha\n",
    "    \n",
    "    benchmark_nine_subset_targets[(benchmark_nine_subset_targets==9).nonzero().reshape(-1)] = 1  # Set the targets' value to 1 (as this is our \"positive\" class).\n",
    "    \n",
    "    benchmark_data = torch.cat([benchmark_four_subset_data, benchmark_nine_subset_data], dim=0)\n",
    "    benchmark_targets = torch.cat([benchmark_four_subset_targets,benchmark_nine_subset_targets], dim=0)\n",
    "    benchmark_set = SimpleDataSet(benchmark_data, benchmark_targets)\n",
    "    \n",
    "    training_set = SimpleDataSet(training_subset_data, training_subset_targets)\n",
    "    \n",
    "    ## Test data\n",
    "    test_set_full = datasets.MNIST(root='./data', download=True, transform=image_padding_to_32, train=False)\n",
    "    test_subset_index = []\n",
    "    if experiment_type==1:\n",
    "        test_subset_index = (test_set_full.targets == 9).nonzero().reshape(-1)\n",
    "    elif experiment_type==2:\n",
    "        test_subset_index = torch.logical_or(test_set_full.targets == 4, test_set_full.targets == 9).nonzero().reshape(-1)\n",
    "    else:\n",
    "        raise NotImplementedError(\"Only 1,2 experiment types are supported\")\n",
    "    \n",
    "    test_subset_loader = torch.utils.data.DataLoader(dataset=test_set_full, batch_size=len(test_subset_index), shuffle=False, sampler=Data.SubsetRandomSampler(test_subset_index))\n",
    "    test_subset_data, test_subset_targets = next(iter(test_subset_loader))\n",
    "    test_subset_targets[(test_subset_targets==4).nonzero().reshape(-1)] = 0\n",
    "    test_subset_targets[(test_subset_targets==9).nonzero().reshape(-1)] = 1\n",
    "    test_set = SimpleDataSet(test_subset_data, test_subset_targets)\n",
    "    \n",
    "    return training_set, test_set, benchmark_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "d3ddb536-ce1a-4bdb-a39a-94a725c9a66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_knockoffs(score_model, h1_set, h1_set_with_true_targets, l, m, alpha):\n",
    "    with torch.no_grad():\n",
    "        score_model.eval()\n",
    "        _, probability_scores = score_model(h1_set.data.to(DEVICE)) # probability scores is a tensor of pairs (p(0), p(1)).\n",
    "    probability_of_discovery = probability_scores[:,1].numpy() # We only care about the probability of a discovery (p(1))\n",
    "\n",
    "    print(F\"probability scores: {probability_scores}\")\n",
    "    print(F\"probability of discovery: {probability_of_discovery}\")\n",
    "    scores_df = pd.DataFrame({'score': probability_of_discovery, 'is_test': np.concatenate((np.repeat(0, l),np.repeat(1,m))),'truth':h1_set_with_true_targets.targets.numpy()})\n",
    "    scores_df.sort_values(by=['score'], inplace=True, ascending=True)\n",
    "    \n",
    "    fdp = 10 # a value which is definitely bigger than alpha\n",
    "    \n",
    "    for lower_bound in range(len(h1_set)):\n",
    "        scores_window_df = scores_df[lower_bound:] # get the subset of the samples we want to test with.\n",
    "        ktest = len(scores_window_df[scores_window_df['is_test']==1]) # This is the \"moving\" k, which changes as we move the lower score bound.\n",
    "        v = len(scores_window_df[scores_window_df['is_test']==0]) # The count of false discoveries that we know of (i.e., training samples)\n",
    "        try: \n",
    "            fdp = ((v+1) / (l+1)) * (m / ktest)\n",
    "        except ZeroDivisionError:\n",
    "            fdp = 99999\n",
    "            break\n",
    "        # print(F\"ktest: {ktest},\\t\"\n",
    "        #       F\"v: {v},\\t\"\n",
    "        #       F\"m: {m},\\t\"\n",
    "        #       F\"l: {l},\\t\"\n",
    "        #       F\"fdp: {fdp}\")\n",
    "\n",
    "        if fdp<=alpha:\n",
    "            # print(F\"Got FDP of {fdp} <= alpha({alpha}) , for lower bound: {lower_bound}\")\n",
    "            break\n",
    "    \n",
    "    total_elements = len(scores_window_df)\n",
    "    total_discoveries = ktest\n",
    "    false_discoveries = len(scores_window_df[(scores_window_df['is_test']==1) & (scores_window_df['truth']==0)])\n",
    "    \n",
    "    return dict(total_elements=total_elements, total_discoveries=total_discoveries,false_discoveries=false_discoveries,v=v,fdp=fdp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "bbf0a781-c9cd-4d00-a8b3-05641b8e7a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_discovery(seed, batch_size, experiment_type, alpha=0.1, use_generative=True):\n",
    "    \n",
    "    # Reproducability :-)\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    \n",
    "    null_mv = None\n",
    "    positive_mv = None\n",
    "    if use_generative:\n",
    "        vae_result = get_trained_vae_and_stats()\n",
    "        vae = vae_result['vae']\n",
    "        null_mean = vae_result['null_mean']\n",
    "        positive_mean = vae_result['positive_mean']\n",
    "        vcov = vae_result['common_vcov']\n",
    "        null_mv = MultivariateNormal(null_mean, vcov)\n",
    "        positive_mv = MultivariateNormal(positive_mean, vcov)\n",
    "    \n",
    "    \n",
    "    # Get the data (notice this loads in a different random order each time, given the seed)\n",
    "    training_set, test_set, benchmark_set = get_generated_datasets_from_vae(vae, null_mv, positive_mv) if use_generative else get_datasets_for_discovery(experiment_type)\n",
    "        \n",
    "    # Re-divide train and test data for AdaDetect\n",
    "    h0_set, h1_set, h1_set_with_true_targets, k = get_synthetic_h0_h1(training_set, test_set)\n",
    "    # print(F\"Training set size: {len(training_set)}, Test set size: {len(test_set)}\")\n",
    "    # print(F\"Selected K: {k}, h0 size: {len(h0_set)} , h1 size: {len(h1_set)}\")\n",
    "    h0h1_set = ConcatDataset(h0_set,h1_set)\n",
    "    h0h1_loader = DataLoader(h0h1_set, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    # Benchmark data loader\n",
    "    benchmark_loader = DataLoader(benchmark_set, shuffle=True)\n",
    "\n",
    "    ## Use BoNuS and Knockoff counting for stating discoveries while keeping FDR\n",
    "    l = len(training_set)-k # This is the length of the \"2nd part\" of the null samples, which will be concatenated to the test sample\n",
    "    m = len(test_set)\n",
    "    \n",
    "    # Training\n",
    "    # real_model, optimizer, num_epochs, (train_losses, validation_losses) = get_trained_model(h0h1_loader, None, num_epochs=5)\n",
    "    # benchmark_model, bm_optimizer, bm_num_epochs, (bm_train_losses, bm_validation_losses) = get_trained_model(benchmark_loader, None, num_epochs=5)\n",
    "\n",
    "    # Knockoff Process\n",
    "    # real_knockoff_results = perform_knockoffs(real_model, h1_set, h1_set_with_true_targets, l, m, alpha)\n",
    "    # benchmark_knockoff_results = perform_knockoffs(benchmark_model, h1_set, h1_set_with_true_targets, l, m, alpha)\n",
    "    \n",
    "    lr_model = LikelihoodRatioModel(vae, null_mv, positive_mv) if use_generative else None\n",
    "    lr_knockoff_results = perform_knockoffs(lr_model, h1_set, h1_set_with_true_targets, l, m, alpha) if use_generative else dict(total_elements=-1, total_discoveries=-1, false_discoveries=-1,v=-1,fdp=-1)\n",
    "    \n",
    "    # return dict(model=dict(real=real_model, benchmark=benchmark_model, likelihood_ratio=lr_model),\n",
    "    #             optimizer=dict(real=optimizer,benchmark=bm_optimizer),\n",
    "    #             alpha=alpha,\n",
    "    #             training_set_size=len(training_set),\n",
    "    #             test_set_size=len(test_set),\n",
    "    #             m=m,\n",
    "    #             l=l,\n",
    "    #             num_epochs=dict(real=num_epochs, benchmark=bm_num_epochs),\n",
    "    #             final_CELoss=dict(real=train_losses[-1], benchmark=bm_train_losses[-1]),\n",
    "    #             total_elements=dict(real=real_knockoff_results[\"total_elements\"], benchmark=benchmark_knockoff_results[\"total_elements\"], lr=lr_knockoff_results[\"total_elements\"]),\n",
    "    #             total_discoveries=dict(real=real_knockoff_results[\"total_discoveries\"], benchmark=benchmark_knockoff_results[\"total_discoveries\"], lr=lr_knockoff_results[\"total_discoveries\"]), \n",
    "    #             false_discoveries=dict(real=real_knockoff_results[\"false_discoveries\"], benchmark=benchmark_knockoff_results[\"false_discoveries\"], lr=lr_knockoff_results[\"false_discoveries\"]),\n",
    "    #             v=dict(real=real_knockoff_results[\"v\"], benchmark=benchmark_knockoff_results[\"v\"], lr=lr_knockoff_results[\"v\"]),\n",
    "    #             fdp=dict(real=real_knockoff_results[\"fdp\"], benchmark=benchmark_knockoff_results[\"fdp\"], lr=lr_knockoff_results[\"fdp\"]))\n",
    "    \n",
    "    return dict(model=dict(real=None, benchmark=None, likelihood_ratio=lr_model),\n",
    "                optimizer=dict(real=None,benchmark=None),\n",
    "                alpha=alpha,\n",
    "                training_set_size=len(training_set),\n",
    "                test_set_size=len(test_set),\n",
    "                m=m,\n",
    "                l=l,\n",
    "                num_epochs=dict(real=0, benchmark=0),\n",
    "                final_CELoss=dict(real=-1, benchmark=-1),\n",
    "                total_elements=dict(real=-1, benchmark=-1, lr=lr_knockoff_results[\"total_elements\"]),\n",
    "                total_discoveries=dict(real=-1, benchmark=-1, lr=lr_knockoff_results[\"total_discoveries\"]), \n",
    "                false_discoveries=dict(real=-1, benchmark=-1, lr=lr_knockoff_results[\"false_discoveries\"]),\n",
    "                v=dict(real=-1, benchmark=-1, lr=lr_knockoff_results[\"v\"]),\n",
    "                fdp=dict(real=-1, benchmark=-1, lr=lr_knockoff_results[\"fdp\"]))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "295b1d85-5d39-4fe1-8801-d2cbad527a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiment_id,\texperiment_type,\tseed,\tbatch_size,\talpha,\ttraining set size,\ttest set size,\tm,\tl,\tnum epochs,\tfinal CELoss,\ttotal elements,\ttotal discoveries (ktest),\tv,\tfalse discoveries,\tfdp,\tBenchmark num epochs,\tBenchmark final CELoss,\tBenchmark total elements,\tBenchmark total discoveries (ktest),\tBenchmark v,\tBenchmark false discoveries,\tBenchmark fdp\n",
      "2-0-2023-07-23-19-18-13,\t2,\t0,\t32,sample index: torch.Size([11791])\n",
      "====> VAE Epoch: 0\n",
      "VAE Average loss: 29.0346\n",
      "====> VAE Epoch: 1\n",
      "VAE Average loss: 26.8313\n",
      "sample index: torch.Size([5842])\n",
      "sample index: torch.Size([5949])\n",
      "probability scores: tensor([[  0.0000,  -9.9181],\n",
      "        [  0.0000, -10.0269],\n",
      "        [  0.0000, -16.1851],\n",
      "        ...,\n",
      "        [  0.0000,  18.6084],\n",
      "        [  0.0000,  17.5195],\n",
      "        [  0.0000, -10.2532]])\n",
      "probability of discovery: [ -9.918143 -10.026894 -16.185059 ...  18.60837   17.519466 -10.253203]\n",
      "\t0.1,\t4000,\t4000,\t4000,\t4000,\t0,\t-1,\t-1,\t-1,\t-1,\t-1,\t-1,\t2296,\t2089,\t207,\t105,\t0.09954428578111577,\t0,\t-1,\t-1,\t-1,\t-1,\t-1,\t-1\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'state_dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [233], line 66\u001b[0m\n\u001b[1;32m     39\u001b[0m             print_to_stdout_and_stream(\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mdiscovery_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124malpha\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     40\u001b[0m                                        \u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mdiscovery_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraining_set_size\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     41\u001b[0m                                        \u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mdiscovery_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_set_size\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     61\u001b[0m                                        \u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mdiscovery_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfalse_discoveries\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbenchmark\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     62\u001b[0m                                        \u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mdiscovery_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfdp\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbenchmark\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, results_stream)\n\u001b[1;32m     64\u001b[0m             \u001b[38;5;66;03m# Reproduceability - save the model used for this discovery process\u001b[39;00m\n\u001b[1;32m     65\u001b[0m             torch\u001b[38;5;241m.\u001b[39msave({ \n\u001b[0;32m---> 66\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_state_dict\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43mdiscovery_results\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreal\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m(),\n\u001b[1;32m     67\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moptimizer_state_dict\u001b[39m\u001b[38;5;124m'\u001b[39m: discovery_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimizer\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreal\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mstate_dict(),\n\u001b[1;32m     68\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m: discovery_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfinal_CELoss\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreal\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     69\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbenchmark_model_state_dict\u001b[39m\u001b[38;5;124m'\u001b[39m: discovery_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbenchmark\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mstate_dict(),\n\u001b[1;32m     70\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbenchmark_optimizer_state_dict\u001b[39m\u001b[38;5;124m'\u001b[39m: discovery_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimizer\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbenchmark\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mstate_dict(),\n\u001b[1;32m     71\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbenchmark_loss\u001b[39m\u001b[38;5;124m'\u001b[39m: discovery_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfinal_CELoss\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbenchmark\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     72\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr_null_mv\u001b[39m\u001b[38;5;124m'\u001b[39m: discovery_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mnull_mv,\n\u001b[1;32m     73\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr_positive_mv\u001b[39m\u001b[38;5;124m'\u001b[39m: discovery_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mpositive_mv,\n\u001b[1;32m     74\u001b[0m             }, \u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexp_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*** All done! ***\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'state_dict'"
     ]
    }
   ],
   "source": [
    "class NullStream:\n",
    "        @staticmethod\n",
    "        def write(*_): pass\n",
    "        @staticmethod\n",
    "        def flush(*_): pass\n",
    "\n",
    "def print_to_stdout_and_stream(text, stream:TextIO = NullStream):\n",
    "        sys.stdout.write(text)\n",
    "        sys.stdout.flush()\n",
    "        stream.write(text)\n",
    "        stream.flush()\n",
    "\n",
    "# DEVICE = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "NUM_EXPERIMENT_TYPES = 2 # 1 - only 9, 2 - 4+9\n",
    "NUM_EXPERIMENTS_PER_TYPE = 1\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "\n",
    "with open('experiments-results.csv', mode='at', encoding=\"utf-8\") as results_stream:\n",
    "    print_to_stdout_and_stream(\"experiment_id,\\texperiment_type,\\tseed,\\tbatch_size,\\talpha,\\ttraining set size,\\ttest set size,\\tm,\\tl,\"\n",
    "                               \"\\tnum epochs,\\tfinal CELoss,\\ttotal elements,\\ttotal discoveries (ktest),\\tv,\\tfalse discoveries,\\tfdp,\"\n",
    "                               \"\\tBenchmark num epochs,\\tBenchmark final CELoss,\\tBenchmark total elements,\\tBenchmark total discoveries (ktest),\\tBenchmark v,\\tBenchmark false discoveries,\\tBenchmark fdp\\n\",\n",
    "                              results_stream) \n",
    "    \n",
    "    for exp_type in range(2,NUM_EXPERIMENT_TYPES+1):\n",
    "        \n",
    "        for i in range(NUM_EXPERIMENTS_PER_TYPE):\n",
    "            \n",
    "            # Print to know we started another discovery process\n",
    "            exp_id = F\"{exp_type}-{i}-{datetime.utcnow().strftime('%Y-%m-%d-%H-%M-%S')}\"\n",
    "            print_to_stdout_and_stream(F\"{exp_id},\"\n",
    "                                       F\"\\t{exp_type},\"\n",
    "                                       F\"\\t{i},\"\n",
    "                                       F\"\\t{BATCH_SIZE},\", results_stream)\n",
    "            \n",
    "            discovery_results = run_discovery(i, BATCH_SIZE, exp_type)\n",
    "            \n",
    "            print_to_stdout_and_stream(F\"\\t{discovery_results['alpha']},\"\n",
    "                                       F\"\\t{discovery_results['training_set_size']},\"\n",
    "                                       F\"\\t{discovery_results['test_set_size']},\"\n",
    "                                       F\"\\t{discovery_results['m']},\"\n",
    "                                       F\"\\t{discovery_results['l']},\"\n",
    "                                       F\"\\t{discovery_results['num_epochs']['real']},\"\n",
    "                                       F\"\\t{discovery_results['final_CELoss']['real']},\"\n",
    "                                       F\"\\t{discovery_results['total_elements']['real']},\"\n",
    "                                       F\"\\t{discovery_results['total_discoveries']['real']},\"\n",
    "                                       F\"\\t{discovery_results['v']['real']},\"\n",
    "                                       F\"\\t{discovery_results['false_discoveries']['real']},\"\n",
    "                                       F\"\\t{discovery_results['fdp']['real']},\"\n",
    "                                       F\"\\t{discovery_results['total_elements']['lr']},\"\n",
    "                                       F\"\\t{discovery_results['total_discoveries']['lr']},\"\n",
    "                                       F\"\\t{discovery_results['v']['lr']},\"\n",
    "                                       F\"\\t{discovery_results['false_discoveries']['lr']},\"\n",
    "                                       F\"\\t{discovery_results['fdp']['lr']},\"\n",
    "                                       F\"\\t{discovery_results['num_epochs']['benchmark']},\"\n",
    "                                       F\"\\t{discovery_results['final_CELoss']['benchmark']},\"\n",
    "                                       F\"\\t{discovery_results['total_elements']['benchmark']},\"\n",
    "                                       F\"\\t{discovery_results['total_discoveries']['benchmark']},\"\n",
    "                                       F\"\\t{discovery_results['v']['benchmark']},\"\n",
    "                                       F\"\\t{discovery_results['false_discoveries']['benchmark']},\"\n",
    "                                       F\"\\t{discovery_results['fdp']['benchmark']}\\n\", results_stream)\n",
    "            \n",
    "            # Reproduceability - save the model used for this discovery process\n",
    "            torch.save({ \n",
    "                'model_state_dict': discovery_results[\"model\"][\"real\"].state_dict(),\n",
    "                'optimizer_state_dict': discovery_results[\"optimizer\"][\"real\"].state_dict(),\n",
    "                'loss': discovery_results[\"final_CELoss\"][\"real\"],\n",
    "                'benchmark_model_state_dict': discovery_results[\"model\"][\"benchmark\"].state_dict(),\n",
    "                'benchmark_optimizer_state_dict': discovery_results[\"optimizer\"][\"benchmark\"].state_dict(),\n",
    "                'benchmark_loss': discovery_results[\"final_CELoss\"][\"benchmark\"],\n",
    "                'lr_null_mv': discovery_results[\"model\"][\"lr\"].null_mv,\n",
    "                'lr_positive_mv': discovery_results[\"model\"][\"lr\"].positive_mv,\n",
    "            }, F\"{exp_id}.pt\")\n",
    "\n",
    "print(\"*** All done! ***\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd8fc2a-2545-42c2-9b1c-b9abbfb423d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
