{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "ce214c74-c41b-4cbc-9d0c-1e107bfa5aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "from torch.utils.data import Dataset as Dataset\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal\n",
    "from matplotlib import pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from datetime import datetime\n",
    "from typing import Optional, TextIO\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "7977481a-dcd8-4ce9-932c-2558cca2b59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cpu\") # No point in using MPS for now :( See https://github.com/pytorch/pytorch/issues/77799"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95be1ac1-bb89-49c3-ae3f-32ec426172dd",
   "metadata": {},
   "source": [
    "## NN Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "06298ae5-d3f4-4865-8d24-7546ba410958",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses_over_epochs(train_losses: list[float], valid_losses: list[float]):\n",
    "    '''\n",
    "    Graphically show the training and validation loss for each epoch.\n",
    "    '''\n",
    "    \n",
    "    # temporarily change the style of the plots to seaborn \n",
    "    plt.style.use('seaborn')\n",
    "\n",
    "    train_losses = np.array(train_losses) \n",
    "    valid_losses = np.array(valid_losses)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize = (8, 4.5))\n",
    "\n",
    "    ax.plot(train_losses, color='blue', label='Training loss') \n",
    "    ax.plot(valid_losses, color='red', label='Validation loss')\n",
    "    ax.set(title=\"Loss over epochs\", \n",
    "            xlabel='Epoch',\n",
    "            ylabel='Loss') \n",
    "    ax.legend()\n",
    "    fig.show()\n",
    "    \n",
    "    # change the plot style to default\n",
    "    plt.style.use('default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "b68323c6-3567-4d0f-a193-aa326d43f069",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_single_epoch(loader, criterion, model, optimizer, normalize_input_fn, normalize_labels_fn, positive_class = 1, train=True):\n",
    "    '''\n",
    "    Implementation a single epoch for the training/validation loop.\n",
    "    '''        \n",
    "    \n",
    "    model.train() if train else model.eval() \n",
    "    \n",
    "    running_loss = 0\n",
    "    \n",
    "    # Each iteration gets a batch from the train loader\n",
    "    for X, Y_true in loader:\n",
    "        X = normalize_input_fn(X) # Normalizing the input if necessary\n",
    "        X = X.to(DEVICE)\n",
    "        Y_true = Y_true.to(DEVICE)\n",
    "        # Y_true = normalize_labels_fn(Y_true)\n",
    "        # Y_true[Y_true == positive_class]  = 1 # We \"normalize\" the label of the positive class to be \"1\". Makes our lives easier (see comment below)\n",
    "        \n",
    "        optimizer.zero_grad() if train else None\n",
    "        \n",
    "        # Forward pass\n",
    "        Y_logits, Y_prob = model(X)\n",
    "        _, predicted_labels = torch.max(Y_prob, 1)  # The \"1\" is acutally misleading - it's the dimension to search the max in.\n",
    "                                                        # This actually returns the indices of the highest prediction for each row, \n",
    "                                                        # but since the index is one-to-one with the predicted digit (i.e., 0 or 1), \n",
    "                                                        # we use the index of the max probability as the label that's being predicted\n",
    "        batch_loss = criterion(Y_logits, Y_true) # we use the logits as the parameter since \"CELoss already pefroms softmax internally.\n",
    "        running_loss += batch_loss.item() * X.size(0) # X.size(0) is the size of the BATCH, not the image. \n",
    "                                                # The multiplication is required later for calculating the avg loss of the epoch step.\n",
    "        \n",
    "        # Backward pass, only required in training the model\n",
    "        if train:\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    avg_batch_loss_for_epoch = running_loss / len(loader.dataset)\n",
    "    return model, optimizer, avg_batch_loss_for_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "7e981840-3d2d-4cf4-99bb-82347b160df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_loop(train_loader, validation_loader, criterion, model, optimizer, positive_class=1, num_epochs=10, normalize_input_fn=lambda x: x, \n",
    "             normalize_labels_fn=lambda y: y, print_every=1):\n",
    "    \n",
    "    # Objects for storing metrics\n",
    "    best_loss = 1e10\n",
    "    train_losses = []\n",
    "    validation_losses = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # print(f'Epoch: {epoch}\\t')\n",
    "        \n",
    "        # Training the model\n",
    "        _, _, train_loss = run_single_epoch(train_loader, criterion, model, optimizer, normalize_input_fn, normalize_labels_fn, positive_class)\n",
    "        train_losses.append(train_loss)\n",
    "        \n",
    "        # No need for validation when working with a score model\n",
    "        validation_losses.append(0)\n",
    "        # # Validation\n",
    "        # with torch.no_grad():\n",
    "        #     _, _, validation_loss = run_single_epoch(validation_loader, criterion, model, None, normalize_input_fn, normalize_labels_fn, positive_class, False)\n",
    "        #     validation_losses.append(validation_loss)\n",
    "        \n",
    "        # if epoch % print_every == (print_every - 1):\n",
    "        #     print(f'{datetime.now().time().replace(microsecond=0)} --- '\n",
    "        #           f'Epoch: {epoch}\\t'\n",
    "        #           f'Train loss: {train_loss:.4f}\\t'\n",
    "        #           # f'Vaildation loss: {validation_loss:.4f}\\t')\n",
    "        #           f'Vaildation loss: 0\\t')\n",
    "    \n",
    "    plot_losses_over_epochs(train_losses, validation_losses)\n",
    "        \n",
    "    return model, optimizer, num_epochs, (train_losses, validation_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d4ae6f-9b94-4f17-8a2d-0625afb7dfe4",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "558223a6-75d2-48f9-8fd1-6165d46c57f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet5(nn.Module):\n",
    "\n",
    "    def __init__(self, n_classes):\n",
    "        \n",
    "        super(LeNet5, self).__init__()\n",
    "        \n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1),\n",
    "            nn.Tanh(),\n",
    "            nn.AvgPool2d(kernel_size=2),\n",
    "            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1),\n",
    "            nn.Tanh(),\n",
    "            nn.AvgPool2d(kernel_size=2),\n",
    "            nn.Conv2d(in_channels=16, out_channels=120, kernel_size=5, stride=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(in_features=120, out_features=84),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(in_features=84, out_features=n_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        logits = self.classifier(x)\n",
    "        probabilities = F.softmax(logits, dim=1)\n",
    "        return logits, probabilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "fc3d7d05-586c-4e42-af9c-d3e93d6f5c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleDataSet(Dataset):\n",
    "    def __init__(self, data, targets):\n",
    "        super(SimpleDataSet, self).__init__()\n",
    "        assert data.shape[0] == targets.shape[0] # assuming shape[0] = dataset size\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.targets.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index], self.targets[index].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "823dd6c8-4934-46a6-ae3b-9ac6e9aa6eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LikelihoodRatioModel():\n",
    "    def __init__(self, vae, null_mv, positive_mv):\n",
    "        self.vae = vae\n",
    "        self.null_mv = null_mv\n",
    "        self.positive_mv = positive_mv\n",
    "    \n",
    "    def __call__(self, value):\n",
    "        mu_logvar = self.vae.encoder(value.view(-1, 1024)).view(-1, 2, LATENT_DIM)\n",
    "        mu = mu_logvar[:, 0, :]\n",
    "        llr = self.positive_mv.log_prob(mu) - self.null_mv.log_prob(mu)\n",
    "        # We need a 0s \"column as the first col to represent the probability of the \"null\" class (same as LeNet result)\n",
    "        llr_0_padded_right = torch.stack((torch.zeros(llr.view(-1,1).shape[0]).view(-1,1),llr.view(-1,1)), dim=1).squeeze()\n",
    "        return None, llr_0_padded_right\n",
    "    \n",
    "    def eval(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86b6c0a-f40b-48fb-a9cf-723d020a1a38",
   "metadata": {},
   "source": [
    "## Samples Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "04d0731f-1cff-4681-84c4-203d8ef7cf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "LATENT_DIM = 5\n",
    "\n",
    "class VAEFC(nn.Module):\n",
    "    '''\n",
    "    A fully-connectec variational autoencoder (as opposed to convolution-based) used as generative model for MNIST.\n",
    "    '''\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(1024, 400),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(400, 400),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(400, LATENT_DIM * 2)\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(LATENT_DIM, 400),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(400, 400),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(400, 1024),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def reparameterise(self, mu, logvar):\n",
    "        if self.training:\n",
    "            std = logvar.mul(0.5).exp_()\n",
    "            eps = std.new_empty(std.size()).normal_()\n",
    "            return eps.mul_(std).add_(mu)\n",
    "        else:\n",
    "            return mu\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu_logvar = self.encoder(x.view(-1, 1024)).view(-1, 2, LATENT_DIM)\n",
    "        mu = mu_logvar[:, 0, :]\n",
    "        logvar = mu_logvar[:, 1, :]\n",
    "        z = self.reparameterise(mu, logvar)\n",
    "        return self.decoder(z), mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "24be2c54-bcf3-47b0-aced-f08bf43e5df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_loss_for_single_element_batch(x_hat, x, mu, logvar, y=None, β=3):\n",
    "    '''\n",
    "    'Dynamic' loss: changes based on the type of MNIST digit. This forces the VAE to place each digit near the mean we want, effectively\n",
    "    creating a mixture model of normals.\n",
    "\n",
    "    IMPORTANT: THIS WILL ONLY WORK WITH BATCH_SIZE=1 because otherwise the loss will not be calculated correctly.\n",
    "    '''\n",
    "    base_loss = nn.functional.binary_cross_entropy(\n",
    "        x_hat, x.view(-1, 1024), reduction='sum'\n",
    "    )\n",
    "    # KLD = 0.5 * torch.sum(logvar.exp() - logvar - 1 + mu.pow(2)) # Orig KLD\n",
    "    \n",
    "    # KLD(p,q) = KL(N(m1,s1), N(m2,s2)) = log(std2/std1) + (s1 + ((m1-m2)^2))/(2*s2) - 1/2    , where s is VARIANCE (not STD), std1=sqrt(s1)\n",
    "    KLD = 0\n",
    "    if y[0]==4:\n",
    "        KLD = 0.5 * torch.sum(logvar.exp() - logvar + (mu-1).pow(2) -1)\n",
    "    else:\n",
    "        KLD = 0.5 * torch.sum(logvar.exp() - logvar + (mu+1).pow(2) -1)\n",
    "    return base_loss + β * KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "6fd0552d-1b97-416a-ba3f-5f52d234ea0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data loading step\n",
    "\n",
    "class_map = {\"null\": 4, \"positive\": 9}\n",
    "labels_map = {4:0, 9:1} \n",
    "\n",
    "def get_loader_for_vae(dataset, class_to_load=None, batch_size=1, num_samples=None):\n",
    "    if class_to_load is None:\n",
    "        samples_index = torch.logical_or(dataset.targets == class_map[\"null\"] ,dataset.targets == class_map[\"positive\"]).nonzero().reshape(-1)\n",
    "    else:\n",
    "        samples_index = (dataset.targets == class_map[class_to_load]).nonzero().reshape(-1)\n",
    "    if num_samples is not None:\n",
    "        samples_index = samples_index[:num_samples]\n",
    "    print(F\"sample index: {samples_index.shape}\")\n",
    "    return DataLoader(dataset,batch_size=batch_size, shuffle=False, sampler=SubsetRandomSampler(samples_index), drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "a1b0f7c8-eb16-42f8-9ab6-38b1e99e27e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_VAE(vae, train_loader, vae_criterion, epochs=10):\n",
    "    \n",
    "    learning_rate = 1e-3\n",
    "    \n",
    "    vae_optimizer = torch.optim.Adam(\n",
    "        vae.parameters(),\n",
    "        lr=learning_rate,\n",
    "    )\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        vae.train()\n",
    "        train_loss = 0\n",
    "        print(f'====> VAE Epoch: {epoch}')\n",
    "        for x, label in train_loader:\n",
    "            x = x.to(DEVICE)\n",
    "            # ===================forward=====================\n",
    "            x_hat, mu, logvar = vae(x)\n",
    "            loss = vae_criterion(x_hat, x, mu, logvar, label)\n",
    "            train_loss += loss.item()\n",
    "            # ===================backward====================\n",
    "            vae_optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            vae_optimizer.step()\n",
    "        # ===================log========================\n",
    "        print(f'VAE Average loss: {train_loss / len(train_loader.dataset):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "1fda199d-5447-446c-885d-ae0403ba8a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict\n",
    "\n",
    "VAECodes = TypedDict('VAECodes', {'mu': torch.Tensor, 'logvar': torch.Tensor, 'label': torch.Tensor})\n",
    "\n",
    "def get_VAE_codes_for_samples(vae: torch.nn.Module, loader: torch.utils.data.DataLoader) -> VAEResult: \n",
    "    codes = dict(mu=list(), logvar=list(), label=list())\n",
    "    means, logvars, labels = list(), list(), list()\n",
    "    with torch.no_grad():\n",
    "        vae.eval()\n",
    "        for x, y in loader:\n",
    "            x = x.to(DEVICE)\n",
    "            # ===================forward=====================\n",
    "            x_hat, mu, logvar = vae(x)\n",
    "            # =====================log=======================\n",
    "            means.append(mu.detach())\n",
    "            logvars.append(logvar.detach())\n",
    "            labels.append(y.detach())\n",
    "    # ===================log========================\n",
    "    codes['mu'] = torch.cat(means)\n",
    "    codes['logvar']= torch.cat(logvars)\n",
    "    codes['label'] = torch.cat(labels)\n",
    "    return codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "7233c658-11cb-455b-8ef5-6a2f875f7a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_and_vcov_for_vae_codes(codes: VAECodes):\n",
    "        mean_tensor = codes['mu'].mean(0)\n",
    "        centered_mus = codes['mu'] - mean_tensor\n",
    "        vcov = centered_mus.T.cov()\n",
    "        return dict(mean=mean_tensor, vcov=vcov, centered_mus=centered_mus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "792edc8b-4753-49d1-99e8-9422cc9506e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "VAEResult = TypedDict('VAEResult', {'vae': torch.nn.Module, 'null_mean': torch.Tensor, 'positive_mean':torch.Tensor, 'common_vcov': torch.Tensor})\n",
    "\n",
    "image_padding_to_32 = transforms.Compose([transforms.Resize((32,32)), transforms.ToTensor()])\n",
    "\n",
    "def get_trained_vae() -> torch.nn.Module:\n",
    "    '''\n",
    "    Returns: an MNIST-trained VAE.\n",
    "    '''\n",
    "    # Loading relevant data\n",
    "    train_all_loader = get_loader_for_vae(MNIST('./data', train=True, download=True, transform=image_padding_to_32))\n",
    "\n",
    "    # Create and train the VAE\n",
    "    vae = VAEFC().to(DEVICE)\n",
    "    train_VAE(vae, train_all_loader, vae_loss_for_single_element_batch)\n",
    "    \n",
    "    return vae\n",
    "\n",
    "\n",
    "def get_vae_stats(vae: torch.nn.Module):\n",
    "    '''\n",
    "    Parameters:\n",
    "        vae: The MNIST-trained VAE to get the stats from.\n",
    "    \n",
    "    Returns:\n",
    "        a Dictionary of the form: {null_mean: torch.Tensor, positive_mean: torch.Tensor, common_vcov: torch.Tensor} \n",
    "    '''\n",
    "    # Loading relevant data\n",
    "    train_null_only = get_loader_for_vae(MNIST('./data', train=True, download=True, transform=image_padding_to_32), class_to_load=\"null\")\n",
    "    train_positive_only = get_loader_for_vae(MNIST('./data', train=True, download=True, transform=image_padding_to_32), class_to_load=\"positive\")\n",
    "    \n",
    "    # get codes for null and positive classes\n",
    "    null_codes = get_VAE_codes_for_samples(vae, train_null_only)\n",
    "    positive_codes = get_VAE_codes_for_samples(vae, train_positive_only)\n",
    "    \n",
    "    # get the interesting stats to be used for the generation later\n",
    "    null_stats = get_mean_and_vcov_for_vae_codes(null_codes)\n",
    "    positive_stats = get_mean_and_vcov_for_vae_codes(positive_codes)\n",
    "    \n",
    "    # calculate common vcov matrix (we want this so that the likelihood ratio will translate to LDA).\n",
    "    all_centered_means = torch.cat((null_stats['centered_mus'], positive_stats['centered_mus']))\n",
    "    common_vcov= all_centered_means.T.cov()\n",
    "    \n",
    "    return dict(null_mean=null_stats['mean'], positive_mean=positive_stats['mean'], common_vcov=common_vcov)\n",
    "    \n",
    "    \n",
    "def get_trained_vae_and_stats() -> VAEResult:\n",
    "    vae = get_trained_vae()\n",
    "    stats = get_vae_stats(vae)\n",
    "    return dict(vae=vae, null_mean=stats['null_mean'], positive_mean=stats['positive_mean'], common_vcov=stats['common_vcov'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "dae9f1b8-4dc2-459b-98e3-ec017203476d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_generated_datasets_from_vae(vae: torch.nn.Module, null_mv: torch.distributions.MultivariateNormal, positive_mv: torch.distributions.MultivariateNormal):\n",
    "    \n",
    "    TRAINING_SIZE = 4000\n",
    "    TEST_NULL_SIZE = 1000\n",
    "    TEST_POSITIVE_SIZE = 1000\n",
    "    BENCHMARK_NULL_SIZE = 2000\n",
    "    BENCHMARK_POSITIVE_SIZE = 2000\n",
    "    with torch.no_grad():\n",
    "        vae.eval()\n",
    "        \n",
    "        # Training set (only 4s)\n",
    "        training_codes = null_mv.sample(torch.Size([TRAINING_SIZE]))\n",
    "        training_data = vae.decoder(training_codes).unsqueeze(dim=1).view(-1,1,32,32)\n",
    "        training_targets = torch.repeat_interleave(torch.tensor([0]), TRAINING_SIZE)\n",
    "        training_set = SimpleDataSet(training_data, training_targets)\n",
    "\n",
    "        # Benchmark set (4 and 9s)\n",
    "        benchmark_null_codes = null_mv.sample(torch.Size([BENCHMARK_NULL_SIZE]))\n",
    "        benchmark_positive_codes = positive_mv.sample(torch.Size([BENCHMARK_POSITIVE_SIZE]))\n",
    "        benchmark_codes = torch.cat((benchmark_null_codes, benchmark_positive_codes)) \n",
    "        benchmark_null_targets = torch.repeat_interleave(torch.tensor([0]), BENCHMARK_NULL_SIZE)\n",
    "        benchmark_positive_targets = torch.repeat_interleave(torch.tensor([1]), BENCHMARK_POSITIVE_SIZE)\n",
    "        benchmark_targets = torch.cat((benchmark_null_targets, benchmark_positive_targets)) \n",
    "        shuffle = torch.randperm(BENCHMARK_NULL_SIZE + BENCHMARK_POSITIVE_SIZE) # we want mixed, random-ordered samples\n",
    "        benchmark_codes = benchmark_codes[shuffle]\n",
    "        benchmark_targets = benchmark_targets[shuffle]\n",
    "        benchmark_data = vae.decoder(benchmark_codes).unsqueeze(dim=1).view(-1,1,32,32)\n",
    "        benchmark_set = SimpleDataSet(benchmark_data, benchmark_targets)\n",
    "\n",
    "\n",
    "        # Test set (4 and 9s)\n",
    "        test_null_codes = null_mv.sample(torch.Size([TEST_NULL_SIZE]))\n",
    "        test_positive_codes = positive_mv.sample(torch.Size([TEST_POSITIVE_SIZE]))\n",
    "        test_codes = torch.cat((test_null_codes, test_positive_codes)) \n",
    "        test_null_targets = torch.repeat_interleave(torch.tensor([0]), TEST_NULL_SIZE)\n",
    "        test_positive_targets = torch.repeat_interleave(torch.tensor([1]), TEST_POSITIVE_SIZE)\n",
    "        test_targets = torch.cat((test_null_targets, test_positive_targets)) \n",
    "        shuffle = torch.randperm(TEST_NULL_SIZE + TEST_POSITIVE_SIZE) # we want mixed, random-ordered samples\n",
    "        test_codes = test_codes[shuffle]\n",
    "        test_targets = test_targets[shuffle]\n",
    "        test_data = vae.decoder(test_codes).unsqueeze(dim=1).view(-1,1,32,32)\n",
    "        test_set = SimpleDataSet(test_data, test_targets)\n",
    "\n",
    "        return training_set, test_set, benchmark_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc3169d-bb28-4a84-b604-40abc522e731",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "9c8f9c0d-79aa-49ad-94d0-8cd3088668b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trained_model(train_loader, test_loader, num_epochs=20):\n",
    "    LEARNING_RATE = 1e-3\n",
    "    N_CLASSES = 2\n",
    "    \n",
    "    model = nn.DataParallel(LeNet5(N_CLASSES)) # We create the model from scratch for each experiment\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    return run_loop(train_loader, test_loader, criterion, model, optimizer, normalize_input_fn=lambda x: x / 255.0, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "47ae51f0-5daa-445a-bfdb-62fc6324098e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConcatDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, datasetA, datasetB):\n",
    "        super(ConcatDataset, self).__init__()\n",
    "        self.datasetA = datasetA\n",
    "        self.datasetB = datasetB\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        if i<len(self.datasetA):\n",
    "            return self.datasetA[i]\n",
    "        else:\n",
    "            return self.datasetB[i-len(self.datasetA)]\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.datasetA) + len(self.datasetB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "9c86dc35-165a-4a32-a553-f7d20d4e48a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def clone_and_new_computation_graph(t: torch.Tensor, requires_grad=True) -> torch.Tensor:\n",
    "    '''\n",
    "        Returns: \n",
    "            A Tensor with the same data (copied) as `t`, on a new computation graph\n",
    "    '''\n",
    "    t2 = torch.detach(t).clone()\n",
    "    if requires_grad:\n",
    "        t2.requires_grad_()\n",
    "    return t2\n",
    "\n",
    "\n",
    "def get_synthetic_h0_h1(training_set: SimpleDataSet, test_set: SimpleDataSet) -> tuple[SimpleDataSet, SimpleDataSet, SimpleDataSet, int]:\n",
    "    '''\n",
    "    Parameters:\n",
    "        Training and Test datasets. Each of the following form:\n",
    "            Dataset.data: 4-D tensor (batch size, channels, width, height). This is because nn.Conv2d expects input of this shape.\n",
    "            Dataset.targets: 1-D tensor (target class)\n",
    "    Returns:\n",
    "        H0, H1, H1 with true target values (used for validation), K\n",
    "    '''\n",
    "    \n",
    "    # k = math.floor(len(training_set) / 2) # TODO sample random k instead?\n",
    "    k = len(training_set)- len(test_set) # TODO sample random k instead?\n",
    "    # k = len(training_set) - 50\n",
    "    original_training_data = training_set.data\n",
    "    original_training_targets = training_set.targets\n",
    "\n",
    "    # Create H0 set by *copying* the training set, and have it use a separate computation graph.\n",
    "    h0_data = clone_and_new_computation_graph(original_training_data[:k])\n",
    "    h0_targets = clone_and_new_computation_graph(original_training_targets[:k], requires_grad=False)\n",
    "    h0_targets[:] = 0\n",
    "\n",
    "    h0_set = SimpleDataSet(h0_data, h0_targets)\n",
    "    \n",
    "    # Create H1 and H1_true_targets sets by *copying* the data and have it use a separate computation graph\n",
    "    h1_0_data = clone_and_new_computation_graph(original_training_data[k:])\n",
    "    h1_0_targets = clone_and_new_computation_graph(original_training_targets[k:], requires_grad=False)\n",
    "    h1_0_targets[:] = 1\n",
    "        \n",
    "    h1_0_data_for_true_targets = clone_and_new_computation_graph(original_training_data[k:])\n",
    "    h1_0_true_targets = clone_and_new_computation_graph(original_training_targets[k:], requires_grad=False)\n",
    "    \n",
    "    original_test_data = test_set.data\n",
    "    original_test_targets = test_set.targets\n",
    "    h1_1_data = clone_and_new_computation_graph(original_test_data)\n",
    "    h1_1_targets = clone_and_new_computation_graph(original_test_targets, requires_grad=False)\n",
    "    h1_1_targets[:] = 1\n",
    "    \n",
    "    h1_1_data_for_true_targets = clone_and_new_computation_graph(original_test_data)\n",
    "    h1_1_true_targets = clone_and_new_computation_graph(original_test_targets, requires_grad=False)\n",
    "    \n",
    "    h1_data = torch.cat((h1_0_data, h1_1_data), 0)\n",
    "    h1_targets = torch.cat((h1_0_targets, h1_1_targets), 0)\n",
    "    \n",
    "    h1_set = SimpleDataSet(h1_data, h1_targets)\n",
    "    \n",
    "    h1_data_true = torch.cat((h1_0_data_for_true_targets, h1_1_data_for_true_targets), 0)\n",
    "    h1_targets_true = torch.cat((h1_0_true_targets, h1_1_true_targets), 0)\n",
    "    \n",
    "    h1_set_with_true_targets = SimpleDataSet(h1_data_true, h1_targets_true)\n",
    "    \n",
    "\n",
    "    return h0_set, h1_set, h1_set_with_true_targets, k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "d6e556c7-9a5d-4d26-bba3-64222e4a204d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datasets_for_discovery(experiment_type: int, add_noise=False) -> tuple[SimpleDataSet, SimpleDataSet]:\n",
    "    '''\n",
    "    Parameters:\n",
    "        experiment_type:\n",
    "            1 - test data is only H1, no noise\n",
    "            2 - test data is a mix of H0 and H1, no noise\n",
    "            \n",
    "    Returns:\n",
    "        A Tuple of (training_set, test_set, benchmark_set)\n",
    "            Dataset.data: 4-D tensor (batch size, channels, width, height). This is because nn.Conv2d expects input of this shape.\n",
    "            Dataset.targets: 1-D tensor (target class)\n",
    "    '''\n",
    "    \n",
    "    BENCHMARK_TRAINING_SIZE = 1000 # data used for training a *standard* classifier for benchmark purposes\n",
    "    \n",
    "    image_padding_to_32 = transforms.Compose([transforms.Resize((32,32)), transforms.ToTensor()])\n",
    "    \n",
    "    if add_noise:\n",
    "        raise NotImplementedError(\"Adding noise was not yet implemented\")\n",
    "        \n",
    "    ## Training data\n",
    "    training_set_full = datasets.MNIST(root='./data', download=True, transform=image_padding_to_32, train=True)\n",
    "    training_subset_index = (training_set_full.targets == 4).nonzero().reshape(-1)\n",
    "    training_subset_loader = torch.utils.data.DataLoader(dataset=training_set_full, batch_size=len(training_subset_index), shuffle=False, sampler=Data.SubsetRandomSampler(training_subset_index))\n",
    "    training_subset_data, training_subset_targets = next(iter(training_subset_loader)) # We only need one iteration, as the loader has the size of the entire relevant sample\n",
    "\n",
    "    assert len(training_subset_targets[(training_subset_targets!=4).nonzero().reshape(-1)])==0 # Avoid bugs in data loading. You're welcome hahaha\n",
    "    \n",
    "    training_subset_targets[(training_subset_targets==4).nonzero().reshape(-1)] = 0  # Set the targets' value to 0 (as this is our \"null\" class).\n",
    "\n",
    "    # Separating training for Adadetect and benchmark\n",
    "    benchmark_four_subset_data = training_subset_data[-BENCHMARK_TRAINING_SIZE:]\n",
    "    benchmark_four_subset_targets = training_subset_targets[-BENCHMARK_TRAINING_SIZE:]\n",
    "    \n",
    "    # Notice that since we update training_subset_data itself, this MUST happen AFTER we already got the benchmark data.\n",
    "    training_subset_data = training_subset_data[:-BENCHMARK_TRAINING_SIZE]\n",
    "    training_subset_targets = training_subset_targets[:-BENCHMARK_TRAINING_SIZE]\n",
    "    \n",
    "    benchmark_nine_subset_index = (training_set_full.targets == 9).nonzero().reshape(-1)\n",
    "    benchmark_nine_subset_loader = torch.utils.data.DataLoader(dataset=training_set_full, batch_size=len(benchmark_nine_subset_index), shuffle=False, sampler=Data.SubsetRandomSampler(benchmark_nine_subset_index))\n",
    "    benchmark_nine_subset_data, benchmark_nine_subset_targets = next(iter(benchmark_nine_subset_loader)) \n",
    "    \n",
    "    assert len(benchmark_nine_subset_targets[(benchmark_nine_subset_targets!=9).nonzero().reshape(-1)])==0 # Avoid bugs in data loading. You're welcome hahaha\n",
    "    \n",
    "    benchmark_nine_subset_targets[(benchmark_nine_subset_targets==9).nonzero().reshape(-1)] = 1  # Set the targets' value to 1 (as this is our \"positive\" class).\n",
    "    \n",
    "    benchmark_data = torch.cat([benchmark_four_subset_data, benchmark_nine_subset_data], dim=0)\n",
    "    benchmark_targets = torch.cat([benchmark_four_subset_targets,benchmark_nine_subset_targets], dim=0)\n",
    "    benchmark_set = SimpleDataSet(benchmark_data, benchmark_targets)\n",
    "    \n",
    "    training_set = SimpleDataSet(training_subset_data, training_subset_targets)\n",
    "    \n",
    "    ## Test data\n",
    "    test_set_full = datasets.MNIST(root='./data', download=True, transform=image_padding_to_32, train=False)\n",
    "    test_subset_index = []\n",
    "    if experiment_type==1:\n",
    "        test_subset_index = (test_set_full.targets == 9).nonzero().reshape(-1)\n",
    "    elif experiment_type==2:\n",
    "        test_subset_index = torch.logical_or(test_set_full.targets == 4, test_set_full.targets == 9).nonzero().reshape(-1)\n",
    "    else:\n",
    "        raise NotImplementedError(\"Only 1,2 experiment types are supported\")\n",
    "    \n",
    "    test_subset_loader = torch.utils.data.DataLoader(dataset=test_set_full, batch_size=len(test_subset_index), shuffle=False, sampler=Data.SubsetRandomSampler(test_subset_index))\n",
    "    test_subset_data, test_subset_targets = next(iter(test_subset_loader))\n",
    "    test_subset_targets[(test_subset_targets==4).nonzero().reshape(-1)] = 0\n",
    "    test_subset_targets[(test_subset_targets==9).nonzero().reshape(-1)] = 1\n",
    "    test_set = SimpleDataSet(test_subset_data, test_subset_targets)\n",
    "    \n",
    "    return training_set, test_set, benchmark_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "d3ddb536-ce1a-4bdb-a39a-94a725c9a66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_knockoffs(score_model, h1_set, h1_set_with_true_targets, l, m, alpha):\n",
    "    with torch.no_grad():\n",
    "        score_model.eval()\n",
    "        _, probability_scores = score_model(h1_set.data.to(DEVICE)) # probability scores is a tensor of pairs (p(0), p(1)).\n",
    "    probability_of_discovery = probability_scores[:,1].numpy() # We only care about the probability of a discovery (p(1))\n",
    "\n",
    "    print(F\"probability scores: {probability_scores}\")\n",
    "    print(F\"probability of discovery: {probability_of_discovery}\")\n",
    "    scores_df = pd.DataFrame({'score': probability_of_discovery, 'is_test': np.concatenate((np.repeat(0, l),np.repeat(1,m))),'truth':h1_set_with_true_targets.targets.numpy()})\n",
    "    scores_df.sort_values(by=['score'], inplace=True, ascending=True)\n",
    "    \n",
    "    fdp = 10 # a value which is definitely bigger than alpha\n",
    "    \n",
    "    for lower_bound in range(len(h1_set)):\n",
    "        scores_window_df = scores_df[lower_bound:] # get the subset of the samples we want to test with.\n",
    "        ktest = len(scores_window_df[scores_window_df['is_test']==1]) # This is the \"moving\" k, which changes as we move the lower score bound.\n",
    "        v = len(scores_window_df[scores_window_df['is_test']==0]) # The count of false discoveries that we know of (i.e., training samples)\n",
    "        try: \n",
    "            fdp = ((v+1) / (l+1)) * (m / ktest)\n",
    "        except ZeroDivisionError:\n",
    "            fdp = 99999\n",
    "            break\n",
    "        # print(F\"ktest: {ktest},\\t\"\n",
    "        #       F\"v: {v},\\t\"\n",
    "        #       F\"m: {m},\\t\"\n",
    "        #       F\"l: {l},\\t\"\n",
    "        #       F\"fdp: {fdp}\")\n",
    "\n",
    "        if fdp<=alpha:\n",
    "            # print(F\"Got FDP of {fdp} <= alpha({alpha}) , for lower bound: {lower_bound}\")\n",
    "            break\n",
    "    \n",
    "    total_elements = len(scores_window_df)\n",
    "    total_discoveries = ktest\n",
    "    false_discoveries = len(scores_window_df[(scores_window_df['is_test']==1) & (scores_window_df['truth']==0)])\n",
    "    \n",
    "    return dict(total_elements=total_elements, total_discoveries=total_discoveries,false_discoveries=false_discoveries,v=v,fdp=fdp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "bbf0a781-c9cd-4d00-a8b3-05641b8e7a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_discovery(seed, batch_size, experiment_type, alpha=0.1, use_generative=True):\n",
    "    \n",
    "    # Reproducability :-)\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    \n",
    "    null_mv = None\n",
    "    positive_mv = None\n",
    "    if use_generative:\n",
    "        vae_result = get_trained_vae_and_stats()\n",
    "        vae = vae_result['vae']\n",
    "        null_mean = vae_result['null_mean']\n",
    "        positive_mean = vae_result['positive_mean']\n",
    "        vcov = vae_result['common_vcov']\n",
    "        null_mv = MultivariateNormal(null_mean, vcov)\n",
    "        positive_mv = MultivariateNormal(positive_mean, vcov)\n",
    "    \n",
    "    \n",
    "    # Get the data (notice this loads in a different random order each time, given the seed)\n",
    "    training_set, test_set, benchmark_set = get_generated_datasets_from_vae(vae, null_mv, positive_mv) if use_generative else get_datasets_for_discovery(experiment_type)\n",
    "        \n",
    "    # Re-divide train and test data for AdaDetect\n",
    "    h0_set, h1_set, h1_set_with_true_targets, k = get_synthetic_h0_h1(training_set, test_set)\n",
    "    # print(F\"Training set size: {len(training_set)}, Test set size: {len(test_set)}\")\n",
    "    # print(F\"Selected K: {k}, h0 size: {len(h0_set)} , h1 size: {len(h1_set)}\")\n",
    "    h0h1_set = ConcatDataset(h0_set,h1_set)\n",
    "    h0h1_loader = DataLoader(h0h1_set, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    # Benchmark data loader\n",
    "    benchmark_loader = DataLoader(benchmark_set, shuffle=True)\n",
    "\n",
    "    ## Use BoNuS and Knockoff counting for stating discoveries while keeping FDR\n",
    "    l = len(training_set)-k # This is the length of the \"2nd part\" of the null samples, which will be concatenated to the test sample\n",
    "    m = len(test_set)\n",
    "    \n",
    "    # Training\n",
    "    real_model, optimizer, num_epochs, (train_losses, validation_losses) = get_trained_model(h0h1_loader, None, num_epochs=20)\n",
    "    benchmark_model, bm_optimizer, bm_num_epochs, (bm_train_losses, bm_validation_losses) = get_trained_model(benchmark_loader, None, num_epochs=20)\n",
    "\n",
    "    # Knockoff Process\n",
    "    real_knockoff_results = perform_knockoffs(real_model, h1_set, h1_set_with_true_targets, l, m, alpha)\n",
    "    benchmark_knockoff_results = perform_knockoffs(benchmark_model, h1_set, h1_set_with_true_targets, l, m, alpha)\n",
    "    \n",
    "    lr_model = LikelihoodRatioModel(vae, null_mv, positive_mv) if use_generative else None\n",
    "    lr_knockoff_results = perform_knockoffs(lr_model, h1_set, h1_set_with_true_targets, l, m, alpha) if use_generative else dict(total_elements=-1, total_discoveries=-1, false_discoveries=-1,v=-1,fdp=-1)\n",
    "    \n",
    "    return dict(model=dict(real=real_model, benchmark=benchmark_model, likelihood_ratio=lr_model),\n",
    "                optimizer=dict(real=optimizer,benchmark=bm_optimizer),\n",
    "                alpha=alpha,\n",
    "                training_set_size=len(training_set),\n",
    "                test_set_size=len(test_set),\n",
    "                m=m,\n",
    "                l=l,\n",
    "                num_epochs=dict(real=num_epochs, benchmark=bm_num_epochs),\n",
    "                final_CELoss=dict(real=train_losses[-1], benchmark=bm_train_losses[-1]),\n",
    "                total_elements=dict(real=real_knockoff_results[\"total_elements\"], benchmark=benchmark_knockoff_results[\"total_elements\"], lr=lr_knockoff_results[\"total_elements\"]),\n",
    "                total_discoveries=dict(real=real_knockoff_results[\"total_discoveries\"], benchmark=benchmark_knockoff_results[\"total_discoveries\"], lr=lr_knockoff_results[\"total_discoveries\"]), \n",
    "                false_discoveries=dict(real=real_knockoff_results[\"false_discoveries\"], benchmark=benchmark_knockoff_results[\"false_discoveries\"], lr=lr_knockoff_results[\"false_discoveries\"]),\n",
    "                v=dict(real=real_knockoff_results[\"v\"], benchmark=benchmark_knockoff_results[\"v\"], lr=lr_knockoff_results[\"v\"]),\n",
    "                fdp=dict(real=real_knockoff_results[\"fdp\"], benchmark=benchmark_knockoff_results[\"fdp\"], lr=lr_knockoff_results[\"fdp\"]))\n",
    "    \n",
    "    # return dict(model=dict(real=None, benchmark=None, likelihood_ratio=lr_model),\n",
    "    #             optimizer=dict(real=None,benchmark=None),\n",
    "    #             alpha=alpha,\n",
    "    #             training_set_size=len(training_set),\n",
    "    #             test_set_size=len(test_set),\n",
    "    #             m=m,\n",
    "    #             l=l,\n",
    "    #             num_epochs=dict(real=0, benchmark=0),\n",
    "    #             final_CELoss=dict(real=-1, benchmark=-1),\n",
    "    #             total_elements=dict(real=-1, benchmark=-1, lr=lr_knockoff_results[\"total_elements\"]),\n",
    "    #             total_discoveries=dict(real=-1, benchmark=-1, lr=lr_knockoff_results[\"total_discoveries\"]), \n",
    "    #             false_discoveries=dict(real=-1, benchmark=-1, lr=lr_knockoff_results[\"false_discoveries\"]),\n",
    "    #             v=dict(real=-1, benchmark=-1, lr=lr_knockoff_results[\"v\"]),\n",
    "    #             fdp=dict(real=-1, benchmark=-1, lr=lr_knockoff_results[\"fdp\"]))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "295b1d85-5d39-4fe1-8801-d2cbad527a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiment_id,\texperiment_type,\tseed,\tbatch_size,\talpha,\ttraining set size,\ttest set size,\tm,\tl,\tnum epochs,\tfinal CELoss,\ttotal elements,\ttotal discoveries (ktest),\tv,\tfalse discoveries,\tfdp,\tBenchmark num epochs,\tBenchmark final CELoss,\tBenchmark total elements,\tBenchmark total discoveries (ktest),\tBenchmark v,\tBenchmark false discoveries,\tBenchmark fdp\n",
      "2-0-2023-07-24-07-30-04,\t2,\t0,\t32,sample index: torch.Size([11791])\n",
      "====> VAE Epoch: 0\n",
      "VAE Average loss: 38.7850\n",
      "====> VAE Epoch: 1\n",
      "VAE Average loss: 36.0431\n",
      "====> VAE Epoch: 2\n",
      "VAE Average loss: 35.3091\n",
      "====> VAE Epoch: 3\n",
      "VAE Average loss: 34.9096\n",
      "====> VAE Epoch: 4\n",
      "VAE Average loss: 34.7179\n",
      "====> VAE Epoch: 5\n",
      "VAE Average loss: 34.6218\n",
      "====> VAE Epoch: 6\n",
      "VAE Average loss: 34.4925\n",
      "====> VAE Epoch: 7\n",
      "VAE Average loss: 34.3936\n",
      "====> VAE Epoch: 8\n",
      "VAE Average loss: 34.3738\n",
      "====> VAE Epoch: 9\n",
      "VAE Average loss: 34.3081\n",
      "sample index: torch.Size([5842])\n",
      "sample index: torch.Size([5949])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/x6/ctsmhfm56hj3xdv0z721s6lc0000gn/T/ipykernel_32630/1730830866.py:7: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.\n",
      "  plt.style.use('seaborn')\n",
      "/var/folders/x6/ctsmhfm56hj3xdv0z721s6lc0000gn/T/ipykernel_32630/1730830866.py:20: UserWarning: Matplotlib is currently using module://matplotlib_inline.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  fig.show()\n",
      "/var/folders/x6/ctsmhfm56hj3xdv0z721s6lc0000gn/T/ipykernel_32630/1730830866.py:7: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.\n",
      "  plt.style.use('seaborn')\n",
      "/var/folders/x6/ctsmhfm56hj3xdv0z721s6lc0000gn/T/ipykernel_32630/1730830866.py:20: UserWarning: Matplotlib is currently using module://matplotlib_inline.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probability scores: tensor([[0.0051, 0.9949],\n",
      "        [0.0017, 0.9983],\n",
      "        [0.0017, 0.9983],\n",
      "        ...,\n",
      "        [0.0036, 0.9964],\n",
      "        [0.0017, 0.9983],\n",
      "        [0.0017, 0.9983]])\n",
      "probability of discovery: [0.99491787 0.9983152  0.9982876  ... 0.99642533 0.998264   0.99834394]\n",
      "probability scores: tensor([[0.9925, 0.0075],\n",
      "        [0.9911, 0.0089],\n",
      "        [0.9969, 0.0031],\n",
      "        ...,\n",
      "        [0.9990, 0.0010],\n",
      "        [0.9966, 0.0034],\n",
      "        [0.0346, 0.9654]])\n",
      "probability of discovery: [0.00751544 0.00887967 0.00308309 ... 0.00101809 0.00339887 0.96541005]\n",
      "probability scores: tensor([[  0.0000, -12.5818],\n",
      "        [  0.0000, -24.1380],\n",
      "        [  0.0000, -17.0513],\n",
      "        ...,\n",
      "        [  0.0000,   1.2963],\n",
      "        [  0.0000, -17.1750],\n",
      "        [  0.0000,  11.4638]])\n",
      "probability of discovery: [-12.581795  -24.138027  -17.05135   ...   1.2962627 -17.175016\n",
      "  11.463795 ]\n",
      "\t0.1,\t4000,\t2000,\t2000,\t2000,\t20,\t0.5899337089856466,\t289,\t264,\t25,\t11,\t0.09843563066951373,\t1107,\t1008,\t99,\t49,\t0.09915677082093874,\t20,\t0.09447920903636259,\t924,\t841,\t83,\t47,\t0.09983117834661742\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'lr'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [422], line 72\u001b[0m\n\u001b[1;32m     39\u001b[0m             print_to_stdout_and_stream(\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mdiscovery_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124malpha\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     40\u001b[0m                                        \u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mdiscovery_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraining_set_size\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     41\u001b[0m                                        \u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mdiscovery_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_set_size\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     61\u001b[0m                                        \u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mdiscovery_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfalse_discoveries\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbenchmark\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     62\u001b[0m                                        \u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mdiscovery_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfdp\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbenchmark\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, results_stream)\n\u001b[1;32m     64\u001b[0m             \u001b[38;5;66;03m# Reproduceability - save the model used for this discovery process\u001b[39;00m\n\u001b[1;32m     65\u001b[0m             torch\u001b[38;5;241m.\u001b[39msave({ \n\u001b[1;32m     66\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_state_dict\u001b[39m\u001b[38;5;124m'\u001b[39m: discovery_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreal\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mstate_dict(),\n\u001b[1;32m     67\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moptimizer_state_dict\u001b[39m\u001b[38;5;124m'\u001b[39m: discovery_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimizer\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreal\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mstate_dict(),\n\u001b[1;32m     68\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m: discovery_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfinal_CELoss\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreal\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     69\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbenchmark_model_state_dict\u001b[39m\u001b[38;5;124m'\u001b[39m: discovery_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbenchmark\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mstate_dict(),\n\u001b[1;32m     70\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbenchmark_optimizer_state_dict\u001b[39m\u001b[38;5;124m'\u001b[39m: discovery_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimizer\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbenchmark\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mstate_dict(),\n\u001b[1;32m     71\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbenchmark_loss\u001b[39m\u001b[38;5;124m'\u001b[39m: discovery_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfinal_CELoss\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbenchmark\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m---> 72\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr_null_mv\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43mdiscovery_results\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mnull_mv,\n\u001b[1;32m     73\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr_positive_mv\u001b[39m\u001b[38;5;124m'\u001b[39m: discovery_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mpositive_mv,\n\u001b[1;32m     74\u001b[0m             }, \u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexp_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*** All done! ***\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'lr'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x450 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAArQAAAGxCAYAAACTGyX0AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAABdUklEQVR4nO3deVwU9f8H8NfMcp9yKZp4yyGg4JGKpHlfqYVHP1NTI/NrWpkWdid+VSytb1711VAjM83yyBLJMyvFPPNAv6ngLSICyqkrO/P7Y9vFlWtA2ANez8eDx+7Ofmbns28GePHZz8wIsizLICIiIiKyUKKpO0BERERE9CgYaImIiIjIojHQEhEREZFFY6AlIiIiIovGQEtEREREFo2BloiIiIgsGgMtEREREVk0BloiIiIismgMtERERERk0RhoiYjIrP3555/w8/NDQkKCqbtCRGaKgZaILM7GjRvh5+eHkydPmrorRERkBhhoiYiIiMiiMdASEdUC+fn5pu4CEVG1YaAlohrr9OnTePHFF9G2bVuEhoZi7Nix+Ouvvwza3L9/H0uWLEGfPn0QHByMjh07YuTIkdi3b5++TXp6Ot5++2107doVQUFBCA8Px6RJk3D16tVy+5CYmIjnnnsOISEhaN++PSZNmoTk5GT98wkJCfDz88PBgweLrbtu3Tr4+fnh7Nmz+mXJycl49dVX8fjjjyM4OBgRERHYtWuXwXq6KRkHDx7EzJkz0blzZ3Tr1q3MfqrVaixatAi9e/dGUFAQunXrho8//hhqtdqgnZ+fH2bNmoUtW7agb9+++j4cOnSo2GsqqT8AZGdnY+7cuejRoweCgoLQtWtXREVFITMz06CdJEn44osv0LVrVwQHB2Ps2LG4dOmSQZuLFy/ilVdeQZcuXRAcHIyuXbvi9ddfR05OTpnvn4gsm5WpO0BEVB3OnTuHUaNGwdHRES+++CKsrKzw3XffYcyYMfjmm2/Qpk0bAMCSJUuwbNkyDB8+HK1bt0Zubi5OnTqFpKQkdOnSBQDwyiuv4Pz58xg9ejQee+wxZGZmYt++fUhNTUXDhg1L7cP+/fsxYcIENGzYEFOmTMHdu3fxzTffYOTIkdi4cSMaNmyIJ598Eg4ODti2bRsef/xxg/Xj4+PRsmVL+Pr66t/TyJEjUa9ePUyYMEG/3uTJk7F48WL07t3bYP3o6Gi4u7tj8uTJZY7QSpKESZMm4ciRIxgxYgSaN2+Os2fPIi4uDhcvXsTnn39u0P7QoUOIj4/HmDFjYGNjg7Vr1+LFF1/E999/b9BXJfXPy8vDqFGjkJycjKFDh6JVq1bIysrC7t27kZaWBnd3d/12v/zySwiCgBdeeAG5ubmIjY3FG2+8ge+//x6ANpRHRkZCrVZj9OjR8PT0RFpaGn799VdkZ2fD2dm59B2GiCybTERkYTZs2CD7+vrKJ06cKLXNyy+/LAcGBsqXL1/WL0tLS5NDQ0PlUaNG6ZcNHjxYfumll0p9nTt37si+vr5ybGxshfs5ZMgQuXPnznJWVpZ+2ZkzZ2R/f385KipKv2zatGly586d5cLCQv2ymzdvyv7+/vKSJUv0y8aOHSs/9dRT8r179/TLJEmSn332WblPnz76Zbr6jBw50uA1S7N582bZ399fPnTokMHytWvXyr6+vvKRI0f0y3x9fWVfX1/55MmT+mXXrl2Tg4OD5cmTJ+uXKa3/woULZV9fX3n79u3F+iVJkizLsnzgwAHZ19dX7t+/v8F7j4uLk319feW///5blmVZPn36tOzr6ytv27at3PdMRDULpxwQUY2j0Wiwb98+9OrVCz4+PvrldevWxVNPPYUjR44gNzcXAODi4oJz587h4sWLJb6WnZ0drK2tcfDgQdy5c0dxH27evIkzZ87gmWeeQZ06dfTL/f39ERYWhr179+qX9e/fHxkZGQbTDn755RdIkoQBAwYAAG7fvo0DBw6gf//+yM3NRWZmJjIzM5GVlYXw8HBcvHgRaWlpBn0YMWIEVCpVuX1NSEhA8+bN0axZM/3rZmZmolOnTgC0p816UGhoKIKCgvSPGzRogJ49e+KPP/6ARqOpUP23b98Of3//YqPLACAIgsHjiIgI2NjY6B+3b98eAHDlyhUAgJOTEwDgjz/+QEFBQbnvm4hqDk45IKIaJzMzEwUFBWjatGmx55o3bw5JkpCamoqWLVvi1Vdfxcsvv4y+ffvC19cX4eHhGDJkCPz9/QEANjY2eOONN/DRRx+hS5cuaNOmDZ588kk8/fTT8PLyKrUP169fB4BS+/DHH38gPz8fDg4O6Nq1K5ydnREfH4/OnTsD0E43CAgI0K9/+fJlyLKMhQsXYuHChSVuMyMjA/Xq1dM/Lms6xIMuXbqE5ORk/bZLet0HNW7cuFibJk2aoKCgQD/vVWn9L1++jD59+ijqZ4MGDQweu7i4ANDOwQUAHx8fjB8/HqtWrcJPP/2E9u3bo0ePHhg8eDCnGxDVcAy0RFSrdejQATt27MCuXbuwb98+/PDDD4iLi0N0dDSGDx8OABg3bhx69OiBnTt34o8//sDChQuxfPlyxMXFoVWrVo/cBxsbG/Tq1Qs7duzAhx9+iIyMDBw9ehTTpk3Tt5EkCQDwwgsv4IknnijxdRo1amTw2NbWVtH2JUmCr68v3n777RKf9/b2VvQ61U0US/5QUZZl/f233noLzzzzjP77OXv2bCxbtgzr1683m/dBRFWPgZaIahx3d3fY29vjwoULxZ5LSUmBKIqoX7++flmdOnUwdOhQDB06FHl5eRg9ejQWL16sD7SANiy+8MILeOGFF3Dx4kU8/fTTWLlyJRYsWFBiH3SjiaX1wc3NDQ4ODvpl/fv3x6ZNm5CYmIjk5GTIsoz+/fvrn9d9dG9tbY2wsLAKVqRsjRo1wv/+9z907ty52Mf8JXn4zAKA9uwC9vb2+oO4lNa/UaNGOHfu3CO+A0N+fn7w8/PDyy+/jKNHj2LkyJFYu3YtXn/99SrdDhGZD86hJaIaR6VSoUuXLti1a5fBqbVu3bqFn3/+Ge3atdPPt8zKyjJY19HREY0aNdKfrqqgoAD37t0zaNOoUSM4OjoWO6XVg+rWrYuAgABs3rxZ/5E4AJw9exb79u0rdhqtsLAw1KlTB/Hx8di2bRtat25tMP/Uw8MDjz/+OL777jvcvHmz2PYePsVVRfTv3x9paWlYv359sefu3r1b7AwJx44dQ1JSkv5xamoqdu3ahS5dukClUlWo/n369MH//vc/7Nixo9i2Hxx5VSI3NxeFhYUGy3x9fSGKYpnfKyKyfByhJSKLtWHDBvz+++/Flj///POYOnUq9u/fj+eeew7PPfccVCoVvvvuO6jVarz55pv6tgMHDsTjjz+OwMBA1KlTBydPnsQvv/yC0aNHA9COPI4bNw79+vVDixYtoFKpsHPnTty6dQsDBw4ss39RUVGYMGECnn32WQwbNkx/2i5nZ2dMmTLFoK21tTV69+6NrVu3oqCgADNmzCj2eh9++CGee+45DBo0CCNGjICPjw9u3bqFv/76Czdu3MCWLVsqU0YMGTIE27Ztw4cffog///wTbdu2hUajQUpKChISEhAbG4vg4GB9e19fX0RGRhqctgvQnt5MR2n9IyMj8csvv+C1117D0KFDERgYiDt37mD37t2Ijo7Wz2VW4sCBA5g1axb69euHJk2aQKPR4Mcff4RKpULfvn0rVRsisgwMtERksXRB6mERERFo2bIl1qxZg08++QTLli2DLMto3bo15s+frz8HKgCMGTMGu3fvxr59+6BWq9GgQQNMnToVkZGRALTzRwcOHIjExERs2bIFKpUKzZo1w2effVZuSAoLC0NsbCwWLVqERYsWwcrKCh06dMCbb75pMPqqM2DAAHz//fcQBMFguoFOixYtsGHDBixZsgSbNm3C7du34e7ujlatWmHy5MkVKZ0BURSxdOlSfPXVV/jxxx+xY8cO2Nvbo2HDhhgzZkyxg7s6dOiAkJAQLF26FNevX0eLFi0QExNjED6V1t/R0RFr1qzB4sWLsWPHDmzatAkeHh7o3LmzwQFuSvj5+SE8PBx79uxBWloa7O3t4efnhy+//BIhISGVrg8RmT9BruhnOkREVGv5+flh1KhR+OCDD0zdFSIiPc6hJSIiIiKLxkBLRERERBaNgZaIiIiILBrn0BIRERGRReMILRERERFZNAZaIiIiIrJoDLREREREZNFq7YUV0tNzjLYtURTg7u6IzMw8SBKnLJeFtVKGdVKGdVKGdVKGdVKGdVKOtSqfl5ezonYcoTUCURQgCAJEUTB1V8wea6UM66QM66QM66QM66QM66Qca1V1GGiJiIiIyKIx0BIRERGRRWOgJSIiIiKLxkBLRERERBaNgZaIiIiILBoDLRERERFZNAZaIiIiIrJoDLREREREZNEYaImIiIjIojHQEhEREZFFY6AlIiIiIovGQEtERERUQcOGDcL69d8qbn/06GGEh7dHTk5ONfYKiI//Cf36PVmt2zBHVqbuAFUPtRq4eFFEdjbg5ibDzU1GnTqAyH9hiIioFgkPb1/m8+PHT0Bk5MQKv+6XX34Ne3t7xe2Dg9vgxx8T4OTkVOFtUfkYaC3cnTvAuXMizp8Xce6c7kuFixcFaDSCQVtBkP8Jt9qQ6+4u68Ou7n5Jy+zsTPTmiIiIHtGPPybo7+/atQMrVvwX3367Qb/M3t5Bf1+WZWg0GlhZlR+P3NzcKtQPa2treHh4VmgdUo6B1gJIEnDtmmAQXM+fF3H2rIj0dOVDrrIsIDNTQGZmxbbv4FAUcssLv25uMjw8ZLi6VvBNEhERVYMHQ6STkxMEQdAvO3r0MF599V+YP38hvvzyC6SknMenny5BvXreWLz4UyQlncLduwVo3LgpJk6cjA4dOupfa9iwQRgxYiRGjHgOgHYkeMaM97B//x84eDARXl51MWXKVISHdzPY1rZte+Ds7Iz4+J+waNEn+Oyzz/Dvf8/GzZtpCA4OwTvvfAhPT23/CgsLsWTJf5CQsBWiqMJTTw1BZmYG8vJyERPzieIabNr0A9auXY2bN9NQv34DjB0biX79BgLQhviVK5dj69YtyMrKhIuLK7p374mpU98EAGzc+D3Wr/8WN2+mwdHRCW3ahGD27I8f4TtSPRhozcjdu0BysmFoPXdORHKyiPx8odz169SR0bKlhJYtNWjRQkLLlhLc3WXcvq0NsllZ2q/S7hcUlLyN/HwB+fkCrl1T/l4GDbqPFSvuKl+BiIgsUna29pNCHZVKhIsLkJ0tQqOpnm22bCnBxaXqXu+//12CKVNeQ4MGDeHs7Iy0tDR06tQFL730MqytbZCQsBUzZkzDt99ugLe3d6mvs2rVl5g06RVMnvwafvjhO0RHv48NG36Ci0vJozx3797FypUrMXPmbEgS8O9/v4+lSz/Dhx/OBgCsWROH7dsT8PbbH6JJk6b4/vu1+P33X9G2bdnTKB60d+8eLFy4AK++Oh3t2z+O/ft/R0zMLNStWw9t27bHr7/uwvr132LmzLlo2rQ5MjNv4fz5cwCA//3vNBYuXID33otGcHAbZGffwfHjfynetjEx0JpARobwwPSAouB6+bIAWS47uAqCDB8fbXDVhVbdfU9PGUL5ubdUBQUoNfCWFoJv30aJff7pJ2ukp9+Dl5dc+Q4REZFZy84G2rVzwp07Jf3xUT6/tKJcXWUcOZJbZaH2xRcnokOHTvrHLi6uaNnSV/94woRJ+O23Pdi3by+GDn221Nfp3/8p9O7dDwAwceJk/PDDOpw+nYROncJKbF9YWIjo6Gg4O3ugsFBCRMQIfPVVrP75DRvWY/TocejWrTsA4PXXo5CYuK9C723dutXo338QIiKGAwAaNWqMpKRTWLt2Ndq2bY+0tBtwd/dAhw4dYWVlBW9vb7RqFQQASEu7ATs7O3Tp8gQcHBzh7V0fvr7+Fdq+sZhNoF2zZg1WrFiB9PR0+Pv74/3330fr1q1LbDtmzBgcPHiw2PJu3bph+fLl1d3VCrt4UcDbbwN//WWHc+cEZGaWP03Azk5G8+ZFgVUXWps1k+DgUO7qlWJvD9jby2jQQHkI1Wi083h1QffkSRXeeks76TYpScSTT1bTv+dERERVxN+/lcHj/Px8rFy5HImJfyAj4xY0Gg3u3buHtLQbZb5O8+Yt9fft7e3h6OiIrKzS5/nZ2dmhUaNGyMrKA6CdHqFrn5ubi8zMDLRqFahvr1Kp4OcXAFmWFL+3ixcvYvDgCINlwcFt8P336wAA3bv3wvr1azFixBB07NgZnTp1QZcuT8DKygodOnSEt3d9/XMdO4aha9fusDPDg2vMItDGx8cjJiYG0dHRaNOmDeLi4hAZGYmEhAR4eHgUa7948WLcv39f//j27dsYMmQI+vXrZ8xuKzZ7tg02bgQAVbHnPD0lg9FWX1/t/YYNZYs4I4FKBbi7A+7uMpo3lxEUJOGdd2whSQIDLRFRDefiAhw5klvClAN7ZGcXQKNRHrwqoqqnHNjZGY4mL136GQ4d+hOTJ09Fw4Y+sLW1xXvvzcD9+4Vlvs7DB5MJggBZLn2QqKLtq0O9et5Yu3YDDh06iMOH/8Snn87D2rWrsWTJcjg4OGLFim9w7NgRHDp0ALGx/8XKlcvx5Zdfw9nZ2aj9LI9ZBNpVq1ZhxIgRGDp0KAAgOjoav/76KzZs2ICXXnqpWPs6deoYPN66dSvs7OzMNtD+3/8VIjXVCq6uhf+MuhbNca3gQZJmz94eaNFCwtmzKiQlqQDcL3cdIiKyXC4uQLt2RcHVygpwcwOysiQUFlZPoK1uJ08ex4ABg/Qf9efn5+PGjesA2hmtD05OTnB398CZM6cREtIWAKDRaHD27P8MpkOUp0mTJjhx4jj6939Kv+zkyeNo2rSp/rGtrR3Cw7siPLwrIiKG47nnhiE5+Tz8/Pz1I7UdOnTE+PEvoV+/J3H06CF069aj6t5sFTB5oFWr1UhKSsLEiUXngBNFEWFhYTh27Jii19iwYQMGDhwIh+r6LP4R9eqlwfDhQFbWPYv94a6IwEBdoLWAIWYiIqKHNGzYCHv37kaXLk8AEBAb+wUkyfjHhAwdOgLffLMKDRs2ROPGTfDDD98hJycbgPIDZkaOfB4ffPAWfH390L7949i37zf89tse/Oc/SwFoL8QgSRq0ahUEW1s7/PLLNtja2sLb2xv79v2O69evISQkFM7OLkhM3AdZluHj07ia3nHlmTzQZmVlQaPRFJta4OHhgZSUlHLXP3HiBM6ePYs5c+ZUaLuiKEAUH+EIqgpQqUSD25qudWsZmzZpj3rVaETY2ipft7bVqrJYJ2VYJ2VYJ2VYJ2XMuU66v/tWVoZ9tLIS9csAYOrU6ZgzZyb+9a9I1KlTB2PGjEV+fj5EEQbtRFEweKxSGT5+sM3D23owgxTVzLB/Y8eOR1ZWJmbPngmVSsSQIRHo1CkMoigW205p77FHjx7IynoT3367GgsXLkCDBo/hvfc+xOOPPw4AcHV1wddfr8LixZ9BkjRo3rwFFiz4DB4e7nB1dcG6dd9g1arluHdPDR8fH8yaNRe+vi1L3LYpCbKxJ2s8JC0tDV27dsW6desQGhqqX/7xxx/j0KFD+P7778tc/4MPPsCxY8fw008/VWi7sixDeJRTAlCpEhKA/v21948eBR74thIREVElSZKE/v37o3///pg6daqpu2NWTD5C6+bmBpVKhYyMDIPlGRkZ+hMLlyY/Px9bt27Fq6++WuHtZmbmGXWEtronyJuTxo0FANrpH/v330OTJmVPon9QbatVZbFOyrBOyrBOyrBOyrBOypVXq9TU6/jzzwNo27Yd1Go1fvjhO1y9ehVdu/bUnxmhpnNzc1TUzuSB1sbGBoGBgUhMTESvXr0AaP8DSUxMxOjRo8tcNyEhAWq1GoMHD67wdiVJNvp8GI3GcifIV4SHh/bsDbduiThxQsCIERV/z7WlVo+KdVKGdVKGdVKGdVKGdVKutFpJErB16xYsXvwfyDLQrFlzfPbZ5/DxacLaPsTkgRYAxo8fjxkzZiAoKAitW7dGXFwcCgoKEBGhPW9aVFQU6tWrh+nTpxus98MPP6BXr14Vvp4yVS9B0B4YtnevyAPDiIiIKqlePW988cVKU3fDIphFoB0wYAAyMzOxaNEipKenIyAgALGxsfopB6mpqRAfOilrSkoKjhw5gpUr+Y02R9pACyQlqSDLeKQrmBERERGVxSwCLQCMHj261CkGq1evLrasWbNm+Pvvv6u7W1RJgYHaCyrcvi3g+nUBjz3GS+ASERFR9eDnwVQtAgOL5vZw2gERERFVJyYNqhYtW0qwsdGOyp46VfySv0RERERVhYGWqoW1NeDnpx2l5QgtERERVScmDao2umkHSUkcoSUiIqLqw0BL1UZ3YNiFCwJyc03cGSIiokcwZcpLWLjwE/3jYcMGYf36b8tcJzy8PX777ddH3nZVvU5ZVqxYhnHjnqvWbVQnBlqqNroRWlkWcOYMdzUiIjK+qKjXMW3aKyU+d/z4MYSHt8f58+cq/Lpffvk1Bg+OeNTuGSgtVP74YwI6dQqr0m3VNEwZVG10I7QApx0QEZFpPPXUEBw+/Cdu3kwr9tzWrVvg798KLVq0rPDrurm5wc7Oriq6WC4PD0/Y2NgYZVuWymzOQ0s1j5sb8NhjEq5d4xXDiIjINMLCwlGnjhvi43/CuHEv6pfn5+djz55dmDz5Vdy5cxuffvoxjh8/hpycbDz2WEOMGTMevXv3K/V1hw0bhBEjRmLECO2I6pUrlzFv3r9x5kwSGjR4DK+9Nr3YOp9/vgi//fYr0tPT4O7uiX79+mP69KkAgPj4n7Bq1ZcAtFMMAOCddz7EgAGDEB7eHnPnLkDXrk8CAJKTz2PhwgU4deok7Ozs0K1bD7zyyutwcHAAAMyZMxO5uTkIDg7Bd999g/v3C9GzZx+89tp0WFkpi36SJCEubgW2bNmE27ez0LhxU/zrX1P0I8X379/H4sWfYu/e3cjJyYGbmzuefnooxowZD1mWsXLlcmzdugVZWZlwcXFF9+49MXXqm4q2XRkMtFStAgN1gZYjtERENZGQfQeqc2f1j1UqEXCxhyq7ANBIZaxZeZqWvpBdXBW1tbKyQr9+A7Bt288YOzYSwj+XrtyzZyckSYNevfqhoCAffn4BGD16LBwcHJGY+Admz/4Qjz3WEK1aBZW7DUmS8O67b8LNzQPLln2FvLxcLFr0SbF2Dg4OePfdD+Hp6YXk5PP4+OM58PCog2HDnkPPnr2RkpKMP//cj88++xwA4OTkVOw1CgoKMG3aFAQFBSM2Ng5ZWVmYN282/vOfj/HuuzP17Y4ePQwPD08sWrQMV69ewYcfvo2WLX0xePAziur2/fdrsW7dN3jzzXfg6+uHn3/egrfemobVq9fDx6cRvv9+Hf744zfMmjUP9ep5Iy0tDTdv3gAA/PrrLqxf/y1mzpyLpk2bIzPzVqWmdVQEAy1Vq8BADbZvt8Lp0yIkCRA5UEtEVGMI2Xfg3i4Y4p3bxZ5zqcbtSq51kHnkpOJQO3DgEHz77WocO3YEbdtqRz/j43/Ck0/2gJOTE5ycnPDcc2P07YcN+z8cPHgAu3fvVBRoDx8+iEuXLuLTT5fA09MLAPDSS5PxxhuvGrR7cIS4fv0GuHbtMrZt24Zhw56Dra0d7O3toVJZwcPDs9Rt7diRALVajffemwV7e3sAwLRpb2LGjGmYNOkVuLt7AACcnV3w+utRUKlUaNy4CTp3DseRIwcVB9q1a7/BqFFj0atXXwDAyy+/imPHDmP9+rWYPn0Gbt68AR+fRmjdOgSCIMDbu75+3bS0G3B390CHDh1hZWUFb29vRXV8FAy0VK10B4bl5wu4eFFAs2a8BC4RERlX48ZNEBzcGlu3bkHbtu1x9eoVHD9+DJGR/wUAaDQarF69Crt370B6ejoKC+9DrVbD1lbZHNmLFy+gbl1vfZgFgKCg1sXa7dq1HT/8sA7Xrl1DQUE+NBpNiaOwZbl06QJatGipD7MAEBwcAkmScPnyJX2gbdq0GVSqok9HPTw8kZJyXtE28vJycetWOoKD2xgsDw5uox9p7d9/EF5/fTJGjhyKTp06IyzsCTz+eCcAQPfuvbB+/VqMGDEEHTt2RqdOXdClyxOKpztUBgMtVaugIMMDw5o1KzRhb4iIqCrJLq7IPHKy2JQDFxd7ZGcXQGMGUw50Bg4cgs8+m4/p02dg69YteOyxhggNbQcA+Pbb1fj++7V49dXpaNasBezt7bFo0ScoLLxfZX0+deoEZs16Hy+88BI6duwMR0cn7NmzA2vXflNl23jQw+FREARIUtV9P/z8/PH99z/iwIH9OHz4ID744C20b/84Zs/+GPXqeWPt2g04dOggDh/+E59+Og9r167GkiXLqy3UMtBStWrSRIaDg4z8fAFJSSIGDTJ1j4iIqCrJLq4obNehaIGVCLg5QpOVh8LC6gm0ldGjR28sXPgJtm9PwC+/xOPpp4fq59OePHkc4eHd0LfvAAD4Z7TzMpo2barotZs0aYqbN2/g1q1b8PTUThdISjpp0ObkyROoV88bY8dG6pelpqYatLG2toYkaVCWxo2bIj7+ZxQUFOhHaU+e/AuiKKJRo8aK+lseR0cneHp64eTJ4/rQr93OcQQEBBq069mzD3r27IMnn+yJ6dNfQXb2Hbi4uMLW1g7h4V0RHt4VERHD8dxzw5CcfB5+fv5V0seHcUYjVStRBAICeMUwIiIyLQcHB/Ts2RvLli1FRsYtDBhQNMLi4+ODQ4f+xMmTx3Hx4gXMnz8XWVkZil+7ffvH4ePTGHPmfIhz587i+PFjWL78c4M2Pj4+SEu7gZ07f8G1a1fx/ffrsHfvHoM23t4NkJp6HefO/Y3bt29DrVYX21afPv1hY2ODOXM+RErKeRw9ehj/+c989O07QD/doCo899wYrFkTh127tuPy5Yv44ovFOHfuLIYPHwkAWLfuG+zYkYBLly7i8uVL2LNnJzw8PODk5Iz4+J/w88+bkZJyHteuXcUvv2yDra0tvL29q6x/D+MILVW7wEANjhxR4dQp/v9ERESm89RTQ/Dzzz+ic+cuBvNdx46NxPXr1zBt2iuws7PD4MHP4IknnkRenrLLXIqiiLlz52PevH/jpZfGwtu7PqZOfRPTpxdd0CE8vBueffY5/Oc/H0Otvo+wsC544YUXsWLFcn2bJ5/sgd9+241XXvkXcnNz9KftepCdnR0+/XQJFi5cgBdfHGtw2q6qNGzY/yE3NxdLlnyGrKxMNGnSDPPmfQofn0YAAAcHR3z77de4evUKRFGEv38g5s9fCFEU4eTkjG+++QqLF/8HkiShWbMW+Oij/8DVtU6V9vFBgizLtfIonfT0HKNty8pKhJubI7LM7OMXY/nqK2tERWkn1v/9dw7c3EpvW9trpRTrpAzrpAzrpAzrpAzrpBxrVT4vL2dF7ThkRtXuwSuGnT7NaQdERERUtRhoqdoFBEgQBO0HAbxiGBEREVU1pguqdk5O2rMdADwwjIiIiKoeAy0ZhW7aAQ8MIyIioqrGdEFGERSknez+998i7lfdeaqJiIiIGGjJOHQjtGq1gPPnudsRERFR1WGyIKMIDCw6HQkPDCMiIqKqxGRBRvHYYzJcXbUHhp06xQPDiIiIqOow0JJRCAIQFKSddsARWiIiIqpKTBZkNLppBwy0REREVJWYLMhodAeG3bolIi1NMHFviIiIqKZgoCWj4YFhREREVB2YKshofH0lqFQ8MIyIiIiqFgMtGY2dnTbUAsDp09z1iIiIqGowVZBRtWrFA8OIiIioajFVkFHpDgw7f15EQYGJO0NEREQ1AgMtGZXuwDCNRsDff3P3IyIiokdnFolizZo16NGjB4KDgzF8+HCcOHGizPbZ2dmIjo5GeHg4goKC0LdvX+zdu9dIvaVHYXimAx4YRkRERI/OytQdiI+PR0xMDKKjo9GmTRvExcUhMjISCQkJ8PDwKNZerVZj/Pjx8PDwwMKFC1GvXj1cv34dLi4uJug9VVTdujLq1pVw86bIebRERERUJUweaFetWoURI0Zg6NChAIDo6Gj8+uuv2LBhA1566aVi7Tds2IA7d+5g3bp1sLa2BgA0bNjQqH2mRxMYyEBLREREVcekgVatViMpKQkTJ07ULxNFEWFhYTh27FiJ6+zevRshISGYNWsWdu3aBXd3dzz11FOYMGECVCrlH2GLogBRNM7VqlQq0eC2tgsOlrBnj3bKgUolQnjg28BaKcM6KcM6KcM6KcM6KcM6KcdaVR2TBtqsrCxoNJpiUws8PDyQkpJS4jpXrlzBgQMHMGjQICxfvhyXL19GdHQ0CgsLMWXKFMXbdnd3hCAY9/KrLi72Rt2euerYUXubnS0gO9sRTZoUb8NaKcM6KcM6KcM6KcM6KcM6KcdaPTqTTzmoKFmW4eHhgX//+99QqVQICgpCWloaVqxYUaFAm5mZZ9QRWhcXe2RnF0CjkcpfoYZr2lQA4AAA2LfvLlxdNfrnWCtlWCdlWCdlWCdlWCdlWCflWKvyubk5Kmpn0kDr5uYGlUqFjIwMg+UZGRnw9PQscR0vLy9YWVkZTC9o1qwZ0tPToVarYWNjo2jbkiRDkuTKd74SNBoJhYXcYZs0AWxtZdy7J+DECQF9+hSvCWulDOukDOukDOukDOukDOukHGv16Ew6acPGxgaBgYFITEzUL5MkCYmJiQgNDS1xnbZt2+Ly5cuQpKJv/MWLF+Hl5aU4zJJpWVkB/v68YhgRERFVDZOnifHjx2P9+vXYtGkTkpOTMXPmTBQUFCAiIgIAEBUVhU8++UTffuTIkbh9+zbmzJmDCxcu4Ndff8WyZcswatQoU70FqgTdFcNOneK5aImIiOjRmHwO7YABA5CZmYlFixYhPT0dAQEBiI2N1U85SE1NhSgW5e769etjxYoViImJweDBg1GvXj08//zzmDBhgqneAlWC7gILly6JyMkBnJ1N3CEiIiKyWCYPtAAwevRojB49usTnVq9eXWxZaGgo1q9fX93domoUFFQ0ZeT0aRU6dtSU0ZqIiIiodCafckC1U6tWRQGW82iJiIjoUTBJkEm4ugI+PjwwjIiIiB4dkwSZjO7AsKQkHhhGRERElcdASyajOzDszBkRGk6hJSIiokpioCWT0QXaggIBFy4Y9zLEREREVHMw0JLJ6KYcAJx2QERERJXHQEsm07ixDEdH7eWHT53irkhERESVwxRBJiOKQKtWujMdcISWiIiIKoeBlkwqKEh3pgPuikRERFQ5TBFkUroDw1JTRWRmmrgzREREZJEYaMmkeGAYERERPSoGWjIpf38JgsADw4iIiKjymCDIpBwdgebNeWAYERERVR4DLZmcbh4tDwwjIiKiymCCIJPTBdqzZ0Wo1SbuDBEREVkcBloyOd2BYffvCzh7lrskERERVQzTA5mcboQW4IFhREREVHFMD2Ry9evLcHfXhloGWiIiIqoopgcyOUHggWFERERUeUwPZBZatSoaoZVlE3eGiIiILAoDLZkF3YFhGRkCrl83cWeIiIjIojDQklkICio6MOz4cRN2hIiIiCwOAy2ZBV9fCdbW2rkGDLRERERUEQy0ZBZsbICWLbWjtAy0REREVBEMtGQ2dGc6+Osv0/aDiIiILAsDLZkN3YFh584B+fkm7gwRERFZDAZaMhu6A8MkCThzhrsmERERKcPUQGaDl8AlIiKiymBqILPh4SGjfn1eMYyIiIgqhqmBzIpulPbkSe6aREREpAxTA5mV4OCiEVpJKqcxERERERhoyczoRmhzcwVcviyYuDdERERkCRhoyaw8eAncpCSVCXtCRERElsJsAu2aNWvQo0cPBAcHY/jw4Thx4kSpbTdu3Ag/Pz+Dr+DgYCP2lqpL8+Yy7O2193mmAyIiIlLCytQdAID4+HjExMQgOjoabdq0QVxcHCIjI5GQkAAPD48S13FyckJCQoL+sSDw4+maQKUCgoKAQ4d4pgMiIiJSxiwSw6pVqzBixAgMHToULVq0QHR0NOzs7LBhw4ZS1xEEAV5eXvovT09PI/aYqlNIiPb29GlOOSAiIqLymXyEVq1WIykpCRMnTtQvE0URYWFhOHbsWKnr5efno3v37pAkCa1atcK0adPQsmVLxdsVRQGiaJxRXZVKNLil0qlUItq00d6/fFlEXp4IV1fT9skccZ9ShnVShnVShnVShnVSjrWqOiYPtFlZWdBoNMWmFnh4eCAlJaXEdZo2bYq5c+fCz88POTk5WLlyJf7v//4PW7duhbe3t6Lturs7Gn2agouLvVG3Z6l0gRYALl92RNeupuuLueM+pQzrpAzrpAzrpAzrpBxr9ehMHmgrIzQ0FKGhoQaPBwwYgHXr1mHq1KmKXiMzM8+oI7QuLvbIzi6ARsOTq5ZFpRLRunXRD3Zi4j0EBxeasEfmifuUMqyTMqyTMqyTMqyTcqxV+dzcHBW1M3mgdXNzg0qlQkZGhsHyjIwMxfNira2tERAQgMuXLyveriTJkCS5Qn19VBqNhMJC7rDlcXMDmjSRcPGiiJMnBdasDNynlGGdlGGdlGGdlGGdlGOtHp3JJ23Y2NggMDAQiYmJ+mWSJCExMdFgFLYsGo0GZ8+ehZeXV3V1k4xMdz5anouWiIiIymPyEVoAGD9+PGbMmIGgoCC0bt0acXFxKCgoQEREBAAgKioK9erVw/Tp0wEAS5YsQUhICBo3bozs7GysWLEC169fx/Dhw035NqgKBQZK+Pln4H//E1FYCFiZxZ5KRERE5sgsYsKAAQOQmZmJRYsWIT09HQEBAYiNjdVPOUhNTYUoFg0mZ2dn4/3330d6ejpcXV0RGBiIdevWoUWLFqZ6C1TFdCO0d+8KSE4W4efHj2KIiIioZIIsy8adSGom0tNzjLYtKysRbm6OyMrK4xyZcuhq9ddf+QgNdQAA/Pe/BYiI4IFhD+I+pQzrpAzrpAzrpAzrpBxrVT4vL2dF7Uw+h5aoJI0ayXB21v6vxSuGERERUVmYFMgsCQIQGKgBwAPDiIiIqGwMtGS2AgO1H7+cOsXdlIiIiErHpEBmSxdob94UkZ5u3Ku6ERERkeVgoCWzFRSk0d/nPFoiIiIqDVMCmS0/PwmiyAPDiIiIqGxMCWS27O2BFi14xTAiIiIqGwMtmTXdPFqO0BIREVFpmBLIrOkC7blzIu7dM3FniIiIyCwx0JJZ0x0YVlgo4OxZ7q5ERERUHBMCmTXdCC3AaQdERERUMiYEMmt168rw9NRdYIEHhhEREVFxDLRk1gQBaNWKB4YRERFR6ZgQyOwFBRWdukuWTdwZIiIiMjsMtGT2AgO1B4bdvi3g+nVeApeIiIgMMdCS2eOBYURERFQWpgMyey1bSrCx0c414IFhRERE9DAGWjJ71taAry8PDCMiIqKSMR2QRXjwwDAiIiKiBzHQkkXQHRh24YKA3FwTd4aIiIjMCgMtWQTdgWGyLODMGe62REREVITJgCyCboQW4LQDIiIiMsRASxbBzQ147DEeGEZERETFMRmQxdBNO+AILRERET2IgZYshm7awenTIiSpnMZERERUazDQksXQjdDm5wu4eJGXwCUiIiItBlqyGDwwjIiIiErCQEsWo0kTGQ4O2kvg8sAwIiIi0mEqIIuhUgEBATwwjIiIiAwx0JJF0U07OHWKuy4RERFpMRWQRdEdGHbtmoisLBN3hoiIiMwCAy1ZlKCgogPDTp/mtAMiIiJioCULExAgQRB4YBgREREVMZtEsGbNGvTo0QPBwcEYPnw4Tpw4oWi9rVu3ws/PDy+//HI195DMgZOT9mwHAA8MIyIiIi2zCLTx8fGIiYnB5MmTsWnTJvj7+yMyMhIZGRllrnf16lV89NFHaN++vZF6SuaAB4YRERHRg8wiEaxatQojRozA0KFD0aJFC0RHR8POzg4bNmwodR2NRoM33ngDr7zyCnx8fIzYWzI13YFhf/8t4v59E3eGiIiITM7K1B1Qq9VISkrCxIkT9ctEUURYWBiOHTtW6npLly6Fh4cHhg8fjiNHjlR4u6IoQBSNc/lUlUo0uKXSKalVmzbaKQdqtYALF1Ro1Uo2St/MCfcpZVgnZVgnZVgnZVgn5VirqmPyQJuVlQWNRgMPDw+D5R4eHkhJSSlxncOHD+OHH37A5s2bK71dd3dHCIJxAq2Oi4u9UbdnycqqVZcuRfcvXnQweFzbcJ9ShnVShnVShnVShnVSjrV6dCYPtBWVm5uLqKgo/Pvf/4a7u3ulXyczM8+oI7QuLvbIzi6ARiMZZZuWSkmtnJwAV1cH3Lkj4MABNQYMqH3zDrhPKcM6KcM6KcM6KcM6Kcdalc/NzVFRO5MHWjc3N6hUqmIHgGVkZMDT07NY+ytXruDatWuYNGmSfpkkaXeCVq1aISEhAY0aNSp3u5IkQ5KM+1G1RiOhsJA7rBLl1SowUIP9+61w8qRYq2vKfUoZ1kkZ1kkZ1kkZ1kk51urRmTzQ2tjYIDAwEImJiejVqxcAbUBNTEzE6NGji7Vv1qwZfvrpJ4Nln332GfLy8vDuu+/C29vbKP0m0woMlLB/P89FS0RERGYQaAFg/PjxmDFjBoKCgtC6dWvExcWhoKAAERERAICoqCjUq1cP06dPh62tLXx9fQ3Wd3FxAYBiy6nm0l0x7NYtEWlpAurVq30HhhEREZFWpQPtqVOnkJOTg86dOwMA7ty5g/nz5yM5ORlhYWGYPHkyRFHZ6NmAAQOQmZmJRYsWIT09HQEBAYiNjdVPOUhNTVX8WlQ76E7dBWhHaevV05TRmoiIiGqySgfamJgYdO7cWR9o586di507d6JLly5YuXIlRFHE5MmTFb/e6NGjS5xiAACrV68uc9158+Yp7zjVCL6+ElQqGRqNgFOnVOjRg4GWiIiotqr0sOf58+cRHBwMALh79y5++eUXvPPOO1i0aBHeeOMNbNmypco6SfQwOzugZUvtKO3p0xy9JyIiqs0qnQTu3r0Le3vtedOOHj0KtVqNnj17AgD8/Pxw48aNqukhUSl00w54YBgREVHtVukk4OPjg99++w0A8NNPPyEwMBB16tQBoD3llpOTU5V0kKg0gYHaaQbnz4soKDBxZ4iIiMhkKh1ox40bh9jYWHTq1AmbN2/G888/r3/u4MGD8PPzq5IOEpVGN0Kr0Qj4+2+O0hIREdVWlT4obNiwYWjcuDFOnjyJVq1aoVOnTvrn6tSpYxBwiaqD4ZkOVAgJ4UmpiYiIaqNHOg9thw4d0KFDh2LLX3nllUd5WSJF6taV4eUlIT1d5DxaIiKiWqzSKeDUqVNITEzUP75z5w7ee+89jBw5EosXL9ZfjpaoOgUF8cAwIiKi2q7SKSAmJgZHjhzRP547dy62bdsGLy8vrFy5El988UWVdJCoLLoDw5KSVJB5sTAiIqJaieehJYumm0ebnS3gyhXBxL0hIiIiU+B5aMmiPXxgGBEREdU+PA8tWbQWLSTY2mrnGnAeLRERUe3E89CSRbOyAvz9eWAYERFRbcbz0JLFCwzU4PhxFU6d4pQDIiKi2ojnoSWLp5tHe+mSiJwcwNnZxB0iIiIio3qkQJufn49NmzbhyJEjuHPnDlxdXdGuXTs888wzcHBwqKo+EpXpwQPDTp9WoWNHjQl7Q0RERMZW6UmHqampGDx4MGbPno0LFy5AEARcuHABc+bMwZAhQ5CamlqV/SQqle5ctADn0RIREdVGlR6hjYmJAQBs3boVzZo10y9PSUnBv/71L8ybNw8LFy589B4SlcPVFfDxkXDliohTpxhoiYiIaptK//Xfv38/pk2bZhBmAaBZs2Z47bXXsG/fvkfuHJFSbdtqR2l/+82KVwwjIiKqZSodaDUaDWxtbUt8ztbWFhoN5zGS8fTqVQgAuHxZxN9/c5SWiIioNqn0X/62bdviiy++QE5OjsHynJwc/Pe//0Xbtm0fuXNESvXsqYEgaIdmd+x4pGMdiYiIyMJU+i//jBkzMHr0aHTr1g2dOnWCp6cnMjIykJiYCCsrK3zzzTdV2U+iMnl6ymjbVsKRIyrs2KECzxxHRERUe1R6hNbX1xdbtmzB8OHDcfPmTRw4cAA3b97EiBEjsHnzZvz9999V2U+icvXurZ12cOiQCrdvm7YvREREZDyP9Nmst7c33n777WLLf/nlF0RFRWHQoEGP8vJEFdK7dyHmzbOFRiNgzx4rPPNMoam7REREREbAo2eoxggKkuDtrb3IwvbtnEdLRERUWzDQUo0hCEXTDnbvtgJPtEFERFQ7MNBSjaILtFlZAg4fVpm4N0RERGQMDLRUozzxhAa2ttrTd+3cyUBLRERUG1RoomFoaCgEQSi3HS+qQKbi6Ah06aLB7t1W2L7dCu++qzZ1l4iIiKiaVSjQvvDCC4oCLZEp9e5diN27rXDmjApXrwpo2JDXwiUiIqrJKhRoX+HZ6skC9OpVCN3Z5HbutMK4cfdN2yEiIiKqVpxDSzVO48Yy/Py00154GVwiIqKaj4GWaqRevbSB9vffVcjPN3FniIiIqFox0FKN1KeP9vRdd+8K2LePZzsgIiKqycwm0K5ZswY9evRAcHAwhg8fjhMnTpTadvv27YiIiED79u0REhKCIUOGYPPmzcbrLJm9Dh00cHXVHgzGaQdEREQ1m1kE2vj4eMTExGDy5MnYtGkT/P39ERkZiYyMjBLbu7q6YtKkSfjuu++wZcsWRERE4J133sHvv/9u5J6TubKyAnr00I7S7thhBZknOiAiIqqxzCLQrlq1CiNGjMDQoUPRokULREdHw87ODhs2bCixfceOHdG7d280b94cjRo1wtixY+Hn54cjR44Yuedkznr10gbaa9dEnDljFrs6ERERVQOTfxarVquRlJSEiRMn6peJooiwsDAcO3as3PVlWcaBAwdw4cIFvPHGG4q3K4oCRNE459RVqUSDWypdVdaqTx8JgiBDlgXs3m2N1q1rzum7uE8pwzopwzopwzopwzopx1pVHZMH2qysLGg0Gnh4eBgs9/DwQEpKSqnr5eTkoGvXrlCr1RBFER9++CG6dOmieLvu7o5Gv0iEi4u9UbdnyaqiVm5uQOfOwP79wK5dNoiOtqmCnpkX7lPKsE7KsE7KsE7KsE7KsVaPzuSBtrIcHR2xefNm5OfnIzExEfPmzYOPjw86duyoaP3MzDyjjtC6uNgjO7sAGo1klG1aqqquVY8e1ti/3waJiTKSk/Ph7l4FnTQD3KeUYZ2UYZ2UYZ2UYZ2UY63K5+bmqKidyQOtm5sbVCpVsQPAMjIy4OnpWep6oiiicePGAICAgAAkJydj+fLligOtJMmQJOMeKaTRSCgs5A6rRFXVqmfP+5g92waSJGD7dhHDhhVWQe/MB/cpZVgnZVgnZVgnZVgn5VirR2fySRs2NjYIDAxEYmKifpkkSUhMTERoaKji15EkCWq1ujq6SBasVSsJDRpof0ns3Gny/9+IiIioGpg80ALA+PHjsX79emzatAnJycmYOXMmCgoKEBERAQCIiorCJ598om+/bNky7Nu3D1euXEFycjJWrlyJLVu2YPDgwaZ6C2SmBAHo3Vs7KrtrlxUKa9YALREREcEMphwAwIABA5CZmYlFixYhPT0dAQEBiI2N1U85SE1NhSgWZe/8/HxER0fjxo0bsLOzQ7NmzTB//nwMGDDAVG+BzFjv3oWIi7PBnTsCDh9WoVMnjam7RERERFVIkOXaecr59PQco23LykqEm5sjsrLyOEemHNVRq/x8wN/fCXfvCpgy5R4++MDyp6Zwn1KGdVKGdVKGdVKGdVKOtSqfl5ezonZmMeWAqDo5OADh4dpRWc6jJSIiqnkYaKlW0F017H//U+HyZeOef5iIiIiqFwMt1Qq6A8MAYMcOjtISERHVJAy0VCv4+MgICOC0AyIiopqIgZZqDd0o7R9/qJCXZ+LOEBERUZVhoKVao1cv7QjtvXsC/vhDZeLeEBERUVVhoKVao317DdzctGep276d0w6IiIhqCgZaqjWsrIDu3YuuGlY7z8BMRERU8zDQUq2im0d7/bqIpCTu/kRERDUB/6JTrdKjRyFEUTs0y9N3ERER1QwMtFSruLkBHTpoDw5joCUiIqoZGGip1undWxtojxwRcesWrxpGRERk6RhoqdbRzaOVZQG7d/P0XURERJaOgZZqHX9/CT4+EgBOOyAiIqoJGGip1hEEoFcv7Sjtnj1WuH/fxB0iIiKiR8JAS7VSnz7aQJudLeDgQU47ICIismQMtFQrhYVpYG/P03cRERHVBAy0VCvZ2wNPPKE928HOnRyhJSIismQMtFRr6c52cPasChcv8vRdREREloqBlmot3YFhALBzJ6cdEBERWSoGWqq1HntMRmCgdtrB9u0MtERERJaKgZZqNd20g/37VcjNNXFniIiIqFIYaKlW0wVatVrAb79xlJaIiMgSMdBSrda2rQQPD+1Vw3i2AyIiIsvEQEu1mkoFdO+unUe7Y4cVZNnEHSIiIqIKY6ClWk931bC0NBEnT/JHgoiIyNLwrzfVet27F0Kl4lXDiIiILBUDLdV6rq5Ax45F0w6IiIjIsjDQEqHoIgvHjom4eZNXDSMiIrIkDLREAPr00Y7QyrKA3bt5tgMiIiJLwkBLBKBlSwmNGmlP38VpB0RERJaFgZYIgCAUXWRhzx4rqNUm7hAREREpxkBL9A9doM3NFfDnn5x2QEREZCnMJtCuWbMGPXr0QHBwMIYPH44TJ06U2nb9+vV47rnn0KFDB3To0AHjxo0rsz2REmFhGjg48PRdRERElsYsAm18fDxiYmIwefJkbNq0Cf7+/oiMjERGRkaJ7f/8808MHDgQX3/9NdatW4f69evjhRdeQFpampF7TjWJnR3Qtat2lJaBloiIyHKYRaBdtWoVRowYgaFDh6JFixaIjo6GnZ0dNmzYUGL7Tz75BKNGjUJAQACaN2+O2bNnQ5IkJCYmGrnnVNP07q0920FysoiUFJ6+i4iIyBKYfBhKrVYjKSkJEydO1C8TRRFhYWE4duyYotcoKChAYWEhXF1dFW9XFAWIonECi0olGtxS6Uxdq759JUyfrr2/a5c1fH0LTdKP8pi6TpaCdVKGdVKGdVKGdVKOtao6Jg+0WVlZ0Gg08PDwMFju4eGBlJQURa+xYMEC1K1bF2FhYYq36+7uCEEw7gici4u9UbdnyUxVKzc3IDQUOHYM2LPHFu+8Y2uSfijFfUoZ1kkZ1kkZ1kkZ1kk51urRmTzQPqrly5cjPj4eX3/9NWxtlYePzMw8o47QurjYIzu7ABqNZJRtWipzqFXPntY4dswGe/fKuHw5H87OJulGmcyhTpaAdVKGdVKGdVKGdVKOtSqfm5ujonYmD7Rubm5QqVTFDgDLyMiAp6dnmeuuWLECy5cvx6pVq+Dv71+h7UqSDEmSK9zfR6HRSCgs5A6rhClr1bPnfSxYYIP79wXs2iXiqafMc9oBwH1KKdZJGdZJGdZJGdZJOdbq0Zl80oaNjQ0CAwMNDujSHeAVGhpa6npffvklPv/8c8TGxiI4ONgYXaVaIjRUgqen9hfLzp08Hy0REZG5M3mgBYDx48dj/fr12LRpE5KTkzFz5kwUFBQgIiICABAVFYVPPvlE33758uVYuHAh5s6di8ceewzp6elIT09HXl6eqd4C1SCiCPTsqT3bwY4dVpD4TzMREZFZM/mUAwAYMGAAMjMzsWjRIqSnpyMgIACxsbH6KQepqakQxaLsvW7dOty/fx+vvvqqwetMmTIFr7zyilH7TjVT796F+O47a6SnizhxQkRICFMtERGRuTKLQAsAo0ePxujRo0t8bvXq1QaPd+/ebYwuUS325JOFsLKSUVgoYPt2K4SEqE3dJSIiIiqFWUw5IDI3Li5Ap07aaQc7d5rN/31ERERUAgZaolL07q09u8Fff6mQlsarhhEREZkrBlqiUugCLQDs2sWzHRAREZkrBlqiUjRvLqNJE+3BYNu3c9oBERGRuWKgJSqFIAB9+mhHaffutcK9eybuEBEREZWIgZaoDL16aQNtXp6AAwc47YCIiMgcMdASlaFzZw0cHbWXSN6xg9MOiIiIzBEDLVEZbG2Bbt20o7Tbt1tBlk3cISIiIiqGgZaoHLp5tBcvikhO5um7iIiIzA0DLVE5evbU6O9z2gEREZH5YaAlKke9ejJCQrShloGWiIjI/DDQEimgO9vBgQMqZGebuDNERERkgIGWSAHdVcMKCwXs3ctRWiIiInPCQEukQJs2Ery8eNUwIiIic8RAS6SAKAK9emnn0e7apYIkmbhDREREpMdAS6SQbtrBrVsijh3jjw4REZG54F9lIoWefLIQ1ta8ahgREZG5YaAlUsjJSXspXICBloiIyJww0BJVgG7awcmTKqSm8qphRERE5oCBlqgCdIEWAHbu5CgtERGROWCgJaqAZs1kNG+uPcXBjh0qE/eGiIiIAAZaogrTXTXst9+scPeuiTtDREREDLREFdWnjzbQ5ucL2L+fo7RERESmxkBLVEEdO2rg5KQ9fRfn0RIREZkeAy1RBdnYAN27a0dpt2+3giybuENERES1HAMtUSXoznZw+bKIc+f4Y0RERGRK/EtMVAk9emj097dv5zxaIiIiU2KgJaqEunVltG2rDbWcR0tERGRa/EtMVEm9ehXi6FEV/vxThUWLbODuLsPNTYaHh/ZW92VtbeqeEhER1WwMtESV1KdPIT7+2BYajYDZs21Lbefiog227u6yPvQ+eFvSfXt7I74RIiIiC8dAS1RJwcESxo5VY9s2K2RlCbh/XyixXXa2gOxsAZcuKX9te/uicFtS8PXyApo1A5ycBNStCzg7V9GbIiIiskAMtESVJAjA/Pn3MH/+PcgykJsLZGYKyMoSkJkpGNx/eJnucX5+ySG4oEDAtWsCrl0rrxcOAABHRxn160vw9pbh7a29X79+0X1vbxn16smw4k88ERHVQPzzRlQFBEE7SursLKNxY+Unpr17F4oC8IP379wpHoLz8gScP6/C+fNl9VGGl5eM+vWLh1/trfa+i4v2/RAREVkKswi0a9aswYoVK5Ceng5/f3+8//77aN26dYltz507h0WLFiEpKQnXrl3D22+/jXHjxhm3w0RVxM4O/wRJ5SG4sBDIyRFRUOCIv/++i6tXgRs3BNy4ISA1VURqqvZ+RobhSUxkWcDNmwJu3gSOHy/9VGMODtrR3IeDrre3jLp1ZTg6yrCzA+zsZNjaaqdH2NoC1tYMwkREZBomD7Tx8fGIiYlBdHQ02rRpg7i4OERGRiIhIQEeHh7F2hcUFKBhw4bo168fYmJiTNBjItOysgK8vAA3N6BRIw0KC6US2927B6SlaUOuNuxq72uXFS2/e9cwhebnC7hwQcCFCxU7q58oGgZd3X3DZbrHgK2tbNDG1lZ7MJxhO9mgra2t9r7hLaDiqYCJiGo1kwfaVatWYcSIERg6dCgAIDo6Gr/++is2bNiAl156qVj71q1b60dvP/nkE6P2lciS2NoCjRrJaNRIU2obWQZu3wZu3Cga2S0a5S0KwrduCZDlsodfJUlAfj5KnRdcnaytZdjYFAXnB0OxgwNgZWUHGxu5xDBctE7RMl2AdnKS4eoqw9VVe7aKOnW0bWqS+/eB7GztrSTxnwMiskwmDbRqtRpJSUmYOHGifpkoiggLC8OxY8eqdduiKEAUjfOHV6USDW6pdKyVMlVZJy8v7VdwsAxABlB8xPf+fe1o782bAu7e1R60dvcu/vkScO8eUFAA3Lsn/HOrXa5b9mBb3f2ittrbu3eBwsLK/Uzevy/g/n3tXOKSVV1Ks7MrCrnaWxl16hTdf/C5OnUM77u4VF1g1GiAvDzdWTSAnBzt2TRycvDQrfa+9vbBttrbgoIHa+YIGxttP11cZLi4yHB2Ln7f2fnBNvjncdEyR0fjTD+5f1+73+Xna/chw/tF/2Bpl2uX6fY5e3vtJwIODjIcHLQHVjo4aB/b2wOOjsWf4+8nZVgn5VirqmPSQJuVlQWNRlNsaoGHhwdSUlKqddvu7o4QjDzhz8WFJxdVirVSxph1qlu3+rdRWAh94NWFXF1Q0YbkotuHv0paXpG2d+9qA1J5tKFcQFpa5d6js7N2ukidOtqvh+87OWnPmJGdDdy5Y3j74P2cnMptvzxqtYBbt4Bbtyr/+1EUARcX/BPmDe8/+NjFRTsqrA2exb/y8kp/Lj9f2ferKtnY4J+Aaw9HRxh8aZcX/3pwuZ2d9h8alUpbI939hx+X9VxF1xUE081trym/x2VZu5+WdWtjo/2qbK1rSq1MyeRTDkwlMzPPqCO0Li72yM4ugEZT8nxH0mKtlKnpdVKptMHOyelRX6didZIkbdjVjjgLyM0Fbt/Wnlnizh38c6u9X7Tc8LnbtwGNpvTfLdrRUuDy5Ud7b+VRqYpGTHUjqs7OxUdZnZ1luLoKcHKyQVqa+oHwXDSiqxsFfnBZWe9RkrRTWW7frt73WBEqVdEIrLW1dpRWF4zLm06jo1Zrv8zpfSmhUmlP2fdg0LWyAqysZIii7v6Dz8kG7XS32rbyQ22Lr2NtLcDe3goFBYXQaGRoNNpPFGRZu99IEvTLJAn6x0W3QrFlRevrlgklrq/7kuWiL0kSioXQ4m1KvlW6bwDa4wjs7QF7e+0nObpPAOzs8M9yuditg4MANzdrCIIatrZyie3t7LT7rr39g9OoirYry9r98t493a3wwGNBv1z7JZTbTve45OcE+PpKmDNHbbTTQLq5OSpqZ9JA6+bmBpVKhYyMDIPlGRkZ8PT0rNZtS5IMSVJ+ZHlV0GikUg/gIUOslTKskzIVqZO1tfbLyUk7FaOiZLloKsDt29ppALoArL1fchDWtc/P147macOnrD8dnC6E6h7rljk5PRhQtY+dnbV/CJWOFllZiXBzs0FW1n1FdZJlbRB8cBpD0fSGh8Ov4fQH3eOcnKIDEnUHBOo+7jf8g1/SMhhMGSgtLDg6Fj0u7RLUslw0VUE3LUE3VeHh23v3REiSDTIy7iM3V35gOkPxtrrXuXfP9Kf+0IW/4qq7b7VrzEySBOTlaX/+K15bmwq1trLSHjdQWKgNnMa0d68KQ4eq0batef3tMeneZmNjg8DAQCQmJqJXr14AAEmSkJiYiNGjR5uya0RElSIIutFlGQ0aGPefZmMRBN3H6NpzGVeWWl000mcqggD9yK1W6e+nKPirFf+DVFhYFJjv3TMcqSxplPLhEcqSRzFLHsHUthOKjWhqNNr56UX3S18uSdplhm109w2Xl/a62hFREYAEUdSOAuumQuhuBUE7cqxb9vDz2mVyCct094uvq9uPdMsEQf7nFvrbB++X9FxJ6xg+X9JyGWq17liAojncDz5+eLnuOATtrfZ+Rei+R1XFxkYbkG1ttZ9g6O5rbx98HggM1KBNG/MKs4AZ/Ps0fvx4zJgxA0FBQWjdujXi4uJQUFCAiIgIAEBUVBTq1auH6dOnA9AeSJacnKy/n5aWhjNnzsDBwQGNGzc22fsgIqKKsanYoJRFsrIquuiKoZr5zw6gC/6OyMoq4CdI5dDVKiMjDzk50gMB2DD8lhSK1WoBVlYPBk9ZP5e3pDCq/ZL/WWbYviacQ9zkgXbAgAHIzMzEokWLkJ6ejoCAAMTGxuqnHKSmpkIUi47+u3nzJp5++mn945UrV2LlypV4/PHHsXr1amN3n4iIiOiRiGLRpx5Fau4/PdVBkGW5VlYsPb2aDhEuQdF/q3n8b7UcrJUyrJMyrJMyrJMyrJMyrJNyrFX5vLycFbXjic+IiIiIyKIx0BIRERGRRWOgJSIiIiKLxkBLRERERBaNgZaIiIiILBoDLRERERFZNAZaIiIiIrJoDLREREREZNEYaImIiIjIojHQEhEREZFFY6AlIiIiIovGQEtEREREFo2BloiIiIgsGgMtEREREVk0BloiIiIismgMtERERERk0RhoiYiIiMiiMdASERERkUVjoCUiIiIii8ZAS0REREQWjYGWiIiIiCwaAy0RERERWTQGWiIiIiKyaAy0RERERGTRGGiJiIiIyKIx0BIRERGRRWOgJSIiIiKLxkBLRERERBaNgZaIiIiILBoDLRERERFZNAZaIiIiIrJoDLREREREZNEYaImIiIjIoplNoF2zZg169OiB4OBgDB8+HCdOnCiz/bZt29CvXz8EBwdj0KBB2Lt3r5F6SkRERETmxCwCbXx8PGJiYjB58mRs2rQJ/v7+iIyMREZGRontjx49iunTp2PYsGHYvHkzevbsicmTJ+Ps2bNG7jkRERERmZogy7Js6k4MHz4cwcHB+OCDDwAAkiShW7duGDNmDF566aVi7adOnYqCggIsW7ZMv2zEiBHw9/fHrFmzFG0zPT2najqvgFV+DtxuXEF2dgE0Gslo27VEKpUIFxd71qocrJMyrJMyrJMyrJMyrJNyllgrTUtfyC6uRtuel5ezonZW1dyPcqnVaiQlJWHixIn6ZaIoIiwsDMeOHStxnb/++gvjxo0zWBYeHo6dO3cq3q4oChBFoVJ9rpDsO6jTJhC4cxsu1b+1GoO1UoZ1UoZ1UoZ1UoZ1UoZ1Us6SaiW51sGd40mAEUOtEiYPtFlZWdBoNPDw8DBY7uHhgZSUlBLXuXXrFjw9PYu1v3XrluLturs7QhCMEGjFQsAImyEiIiKqbqIAuNVxBFwdTd0VAyYPtKaSmZlnnBFaWEF14gxcrl9CXt5daDQmn+Fh1lQqAY6OdqxVOVgnZVgnZVgnZVgnZVgn5SyxVhpfX0CyArLyjLI9NzdlwdnkgdbNzQ0qlarYAWAZGRnFRmF1PD09i43GltW+JJIkQ5KMtPM4OQMdO0KdlYfCQsuYI2MqVlYiHN0cWatysE7KsE7KsE7KsE7KsE7KWWytzLCvJj/LgY2NDQIDA5GYmKhfJkkSEhMTERoaWuI6ISEhOHDggMGy/fv3IyQkpDq7SkRERERmyOSBFgDGjx+P9evXY9OmTUhOTsbMmTNRUFCAiIgIAEBUVBQ++eQTffvnn38ev//+O1auXInk5GQsXrwYp06dwujRo031FoiIiIjIREw+5QAABgwYgMzMTCxatAjp6ekICAhAbGysfgpBamoqRLEoe7dt2xYLFizAZ599hk8//RRNmjTB0qVL4evra6q3QEREREQmYhbnoTUFo56H1kqEm5sjsixtjowJsFbKsE7KsE7KsE7KsE7KsE7KsVblU3oeWrOYckBEREREVFkMtERERERk0RhoiYiIiMiiMdASERERkUVjoCUiIiIii8ZAS0REREQWjYGWiIiIiCwaAy0RERERWTQGWiIiIiKyaLX2SmFEREREVDNwhJaIiIiILBoDLRERERFZNAZaIiIiIrJoDLREREREZNEYaImIiIjIojHQEhEREZFFY6AlIiIiIovGQEtEREREFo2BloiIiIgsGgMtEREREVk0BtoqsmbNGvTo0QPBwcEYPnw4Tpw4UWb7bdu2oV+/fggODsagQYOwd+9eI/XUdJYtW4ahQ4ciNDQUnTt3xssvv4yUlJQy19m4cSP8/PwMvoKDg43UY9NYvHhxsffcr1+/MtepjftTjx49itXJz88P0dHRJbavLfvSoUOH8K9//Qvh4eHw8/PDzp07DZ6XZRkLFy5EeHg4WrdujXHjxuHixYvlvm5Ff8eZu7LqdP/+fcyfPx+DBg1CSEgIwsPDERUVhbS0tDJfszI/u5agvH3qrbfeKva+IyMjy33d2rRPASjx95Wfnx9iY2NLfc2auk9VBytTd6AmiI+PR0xMDKKjo9GmTRvExcUhMjISCQkJ8PDwKNb+6NGjmD59OqZNm4bu3bvjp59+wuTJk7Fx40b4+vqa4B0Yx8GDBzFq1CgEBwdDo9Hg008/RWRkJLZu3QoHB4dS13NyckJCQoL+sSAIxuiuSbVs2RKrVq3SP1apVKW2ra370w8//ACNRqN/fO7cOYwfP77MX/a1YV/Kz8+Hn58fhg4diilTphR7/ssvv8Tq1asxb948NGzYEAsXLkRkZCTi4+Nha2tb4mtW9HecJSirTnfv3sXp06cxadIk+Pv7Izs7G3PmzMGkSZOwcePGMl+3Ij+7lqK8fQoAnnjiCcTExOgf29jYlPmatW2fAoA//vjD4PFvv/2Gd999F3379i3zdWviPlUtZHpkw4YNk6Ojo/WPNRqNHB4eLi9btqzE9q+99pr80ksvGSwbPny4/P7771drP81NRkaG7OvrKx88eLDUNhs2bJDbtWtnxF6Z3qJFi+TBgwcrbs/9SWv27Nlyr169ZEmSSny+Nu5Lvr6+8o4dO/SPJUmSu3TpIsfGxuqXZWdny0FBQfLPP/9c6utU9HecpXm4TiU5fvy47OvrK1+7dq3UNhX92bVEJdVqxowZ8qRJkyr0OtynZHnSpEny888/X2ab2rBPVRVOOXhEarUaSUlJCAsL0y8TRRFhYWE4duxYiev89ddf6Ny5s8Gy8PBw/PXXX9XZVbOTk5MDAHB1dS2zXX5+Prp3745u3bph0qRJOHfunDG6Z1KXLl1CeHg4evbsienTp+P69eultuX+pP053LJlC4YOHVrmqGtt3JcedPXqVaSnpxv8vnJ2dkabNm1K/X1Vmd9xNVFubi4EQYCLi0uZ7Srys1uTHDx4EJ07d0bfvn3x4YcfIisrq9S23KeAW7duYe/evRg2bFi5bWvrPlVRnHLwiLKysqDRaIp9ROLh4VHq/NBbt27B09OzWPtbt25VWz/NjSRJmDt3Ltq2bVvmx+JNmzbF3Llz4efnh5ycHKxcuRL/93//h61bt8Lb29uIPTae1q1bIyYmBk2bNkV6ejqWLl2KUaNG4aeffoKTk1Ox9tyfgJ07dyInJwfPPPNMqW1q4770sPT0dAAo8fdVaftLZX7H1TT37t3DggULMHDgwBJ/BnUq+rNbUzzxxBPo3bs3GjZsiCtXruDTTz/FhAkT8N1335X48Tj3KWDTpk1wdHREnz59ymxXW/epymCgJZOIjo7GuXPn8O2335bZLjQ0FKGhoQaPBwwYgHXr1mHq1KnV3EvT6Natm/6+v78/2rRpg+7du2Pbtm0YPny4CXtmvjZs2ICuXbuiXr16pbapjfsSPbr79+/jtddegyzLpR5wqFNbf3YHDhyov687cKlXr176UVsqbsOGDRg0aFCp89Z1aus+VRmccvCI3NzcoFKpkJGRYbA8IyOj2KiZjqenZ7HRkLLa1zSzZs3Cr7/+iri4uAqPjFlbWyMgIACXL1+upt6ZHxcXFzRp0qTU91zb96dr165h//79ij66e1Bt3Je8vLwAoEK/ryrzO66muH//PqZOnYrr169j5cqVFR4RK+9nt6by8fGBm5sbLl26VOLztXmfAoDDhw/jwoULlQqktXWfUoKB9hHZ2NggMDAQiYmJ+mWSJCExMdFgNOhBISEhOHDggMGy/fv3IyQkpDq7anKyLGPWrFnYsWMH4uLi4OPjU+HX0Gg0OHv2rP4Pc22Ql5eHK1eulPqea+v+pLNx40Z4eHjgySefrNB6tXFfatiwIby8vAx+X+Xm5uL48eOl/r6qzO+4mkAXZi9duoSvvvoKbm5uFX6N8n52a6obN27g9u3bpb7v2rpP6fzwww8IDAyEv79/hdetrfuUEpxyUAXGjx+PGTNmICgoCK1bt0ZcXBwKCgoQEREBAIiKikK9evUwffp0AMDzzz+PMWPGYOXKlejWrRvi4+Nx6tQpzJo1y5Rvo9pFR0fj559/xueffw5HR0f9fD5nZ2fY2dkBKF6rJUuWICQkBI0bN0Z2djZWrFiB69ev1+iPWj766CN0794dDRo0wM2bN7F48WKIooinnnoKAPenB0mShI0bN+Lpp5+GlZXhr7Paui/l5eUZjN5cvXoVZ86cgaurKxo0aIDnn38eX3zxBRo3bqw/bVfdunXRq1cv/Tpjx45F7969MXr0aADl/46zRGXVycvLC6+++ipOnz6NZcuWQaPR6H9fubq66k9J9XCdyvvZtVRl1crV1RVLlixB37594enpiStXrmD+/Plo3LgxnnjiCf06tX2fatCgAQDtP5AJCQmYMWNGia9RW/ap6sBAWwUGDBiAzMxMLFq0COnp6QgICEBsbKz+o5PU1FSIYtFgeNu2bbFgwQJ89tln+PTTT9GkSRMsXbq0Rp8zFADWrl0LABgzZozB8piYGP0vsYdrlZ2djffffx/p6elwdXVFYGAg1q1bhxYtWhiv40Z248YNTJs2Dbdv34a7uzvatWuH9evXw93dHQD3pwft378f169fx9ChQ4s9V1v3pVOnTuH555/XP9adG/SZZ57BvHnzMGHCBBQUFOCDDz5AdnY22rVrh9jYWIO5fFeuXDE4Sr2833GWqKw6TZkyBbt37wYADBkyxGC9r7/+Gh07dgRQvE7l/exaqrJqNXPmTJw9exabN29GTk4O6tatiy5duuC1114zOBdtbd+n5s2bBwDYunUrZFkuNZDWln2qOgiyLMum7gQRERERUWVxDi0RERERWTQGWiIiIiKyaAy0RERERGTRGGiJiIiIyKIx0BIRERGRRWOgJSIiIiKLxkBLRERERBaNgZaIyMgWL14MPz+/Er+WL19u9P5s3LgRfn5+yMzMNPq2iYiqAq8URkRkAnZ2doiLiyu2vH79+iboDRGRZWOgJSIyAVEUERISYupuEBHVCJxyQERkhnTTDz7++GN06tQJoaGheOutt5Cbm2vQ7tq1a3j11VfRrl07hISEIDIyEn///Xex19u8eTOefvppBAcHo2PHjpgwYQKuXbtm0ObGjRt48cUXERISgj59+mDz5s3V+RaJiKoMAy0RkYkUFhYW+3rQ6tWrkZKSgo8++ghvvPEGfvnlF7z//vv653NzczFmzBicPn0a0dHRmD9/PrKysjB69Gikpqbq28XGxmLGjBkIDAzEkiVLMGfOHDRu3LjYnNk33ngD4eHhWLp0KQICAvDWW28hOTm5eotARFQFOOWAiMgE8vPzERgYWGz5mjVr0L59ewCAjY0Nli5dCpVKBQCwtbXFe++9hylTpqB58+bYuHEjrl+/jq1bt6J58+YAgA4dOqB79+6Ii4vDW2+9hZycHCxZsgTPPvssZs2apd9Or169im171KhRGDVqFAAgNDQUe/fuxS+//IKXX365yt8/EVFVYqAlIjIBOzs7fPPNN8WWN2vWTH+/e/fu+jALAP369cO7776LkydPonnz5jh8+DBatmypD7MAUKdOHYSFheHIkSMAgGPHjqGgoADDhg0rt0/h4eH6+w4ODmjQoAFu3LhRqfdHRGRMDLRERCYgiiKCg4PLbOPh4WHw2MnJCba2trh58yYAIDs7G56eniWud+7cOQDA7du3AQB169Ytt0/Ozs4Gj62traFWq8tdj4jI1DiHlojITGVkZBg8zs3Nxb179/Th1NXVtVgb3Xqurq4AtCO2APQhmIioJmKgJSIyU3v27IFGo9E/TkhIgCAI+pHddu3a4ezZs0hJSdG3uXPnDvbv34927doB0M6Ftbe3x4YNG4zbeSIiI+KUAyIiE5AkCX/99Vex5R4eHvDx8QEAqNVqTJ48GSNHjsTVq1exYMEC9O3bVz9nNiIiAl999RUmTpyIqVOnwtbWFl988QWsrKwwduxYANppBJMnT8aCBQsgyzJ69uwJSZLw559/YuDAgeVOeyAisgQMtEREJnD37l08++yzxZYPGzYMc+bMAQCMGTMGmZmZiIqKglqtRu/evfHBBx/o2zo5OWH16tWYN28e3n//fUiShLZt2+Kbb74xuOLYhAkT4O7ujq+++gobN26Eo6MjQkNDi83RJSKyVIIsy7KpO0FERIb8/PwQFRWFyMhIU3eFiMjscQ4tEREREVk0BloiIiIismicckBEREREFo0jtERERERk0RhoiYiIiMiiMdASERERkUVjoCUiIiIii8ZAS0REREQWjYGWiIiIiCwaAy0RERERWTQGWiIiIiKyaAy0RERERGTR/h8B+9ZajntqnQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 800x450 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class NullStream:\n",
    "        @staticmethod\n",
    "        def write(*_): pass\n",
    "        @staticmethod\n",
    "        def flush(*_): pass\n",
    "\n",
    "def print_to_stdout_and_stream(text, stream:TextIO = NullStream):\n",
    "        sys.stdout.write(text)\n",
    "        sys.stdout.flush()\n",
    "        stream.write(text)\n",
    "        stream.flush()\n",
    "\n",
    "# DEVICE = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "NUM_EXPERIMENT_TYPES = 2 # 1 - only 9, 2 - 4+9\n",
    "NUM_EXPERIMENTS_PER_TYPE = 1\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "\n",
    "with open('experiments-results.csv', mode='at', encoding=\"utf-8\") as results_stream:\n",
    "    print_to_stdout_and_stream(\"experiment_id,\\texperiment_type,\\tseed,\\tbatch_size,\\talpha,\\ttraining set size,\\ttest set size,\\tm,\\tl,\"\n",
    "                               \"\\tnum epochs,\\tfinal CELoss,\\ttotal elements,\\ttotal discoveries (ktest),\\tv,\\tfalse discoveries,\\tfdp,\"\n",
    "                               \"\\tBenchmark num epochs,\\tBenchmark final CELoss,\\tBenchmark total elements,\\tBenchmark total discoveries (ktest),\\tBenchmark v,\\tBenchmark false discoveries,\\tBenchmark fdp\\n\",\n",
    "                              results_stream) \n",
    "    \n",
    "    for exp_type in range(2,NUM_EXPERIMENT_TYPES+1):\n",
    "        \n",
    "        for i in range(NUM_EXPERIMENTS_PER_TYPE):\n",
    "            \n",
    "            # Print to know we started another discovery process\n",
    "            exp_id = F\"{exp_type}-{i}-{datetime.utcnow().strftime('%Y-%m-%d-%H-%M-%S')}\"\n",
    "            print_to_stdout_and_stream(F\"{exp_id},\"\n",
    "                                       F\"\\t{exp_type},\"\n",
    "                                       F\"\\t{i},\"\n",
    "                                       F\"\\t{BATCH_SIZE},\", results_stream)\n",
    "            \n",
    "            discovery_results = run_discovery(i, BATCH_SIZE, exp_type)\n",
    "            \n",
    "            print_to_stdout_and_stream(F\"\\t{discovery_results['alpha']},\"\n",
    "                                       F\"\\t{discovery_results['training_set_size']},\"\n",
    "                                       F\"\\t{discovery_results['test_set_size']},\"\n",
    "                                       F\"\\t{discovery_results['m']},\"\n",
    "                                       F\"\\t{discovery_results['l']},\"\n",
    "                                       F\"\\t{discovery_results['num_epochs']['real']},\"\n",
    "                                       F\"\\t{discovery_results['final_CELoss']['real']},\"\n",
    "                                       F\"\\t{discovery_results['total_elements']['real']},\"\n",
    "                                       F\"\\t{discovery_results['total_discoveries']['real']},\"\n",
    "                                       F\"\\t{discovery_results['v']['real']},\"\n",
    "                                       F\"\\t{discovery_results['false_discoveries']['real']},\"\n",
    "                                       F\"\\t{discovery_results['fdp']['real']},\"\n",
    "                                       F\"\\t{discovery_results['total_elements']['lr']},\"\n",
    "                                       F\"\\t{discovery_results['total_discoveries']['lr']},\"\n",
    "                                       F\"\\t{discovery_results['v']['lr']},\"\n",
    "                                       F\"\\t{discovery_results['false_discoveries']['lr']},\"\n",
    "                                       F\"\\t{discovery_results['fdp']['lr']},\"\n",
    "                                       F\"\\t{discovery_results['num_epochs']['benchmark']},\"\n",
    "                                       F\"\\t{discovery_results['final_CELoss']['benchmark']},\"\n",
    "                                       F\"\\t{discovery_results['total_elements']['benchmark']},\"\n",
    "                                       F\"\\t{discovery_results['total_discoveries']['benchmark']},\"\n",
    "                                       F\"\\t{discovery_results['v']['benchmark']},\"\n",
    "                                       F\"\\t{discovery_results['false_discoveries']['benchmark']},\"\n",
    "                                       F\"\\t{discovery_results['fdp']['benchmark']}\\n\", results_stream)\n",
    "            \n",
    "            # Reproduceability - save the model used for this discovery process\n",
    "            torch.save({ \n",
    "                'model_state_dict': discovery_results[\"model\"][\"real\"].state_dict(),\n",
    "                'optimizer_state_dict': discovery_results[\"optimizer\"][\"real\"].state_dict(),\n",
    "                'loss': discovery_results[\"final_CELoss\"][\"real\"],\n",
    "                'benchmark_model_state_dict': discovery_results[\"model\"][\"benchmark\"].state_dict(),\n",
    "                'benchmark_optimizer_state_dict': discovery_results[\"optimizer\"][\"benchmark\"].state_dict(),\n",
    "                'benchmark_loss': discovery_results[\"final_CELoss\"][\"benchmark\"],\n",
    "                'lr_null_mv': discovery_results[\"model\"][\"lr\"].null_mv,\n",
    "                'lr_positive_mv': discovery_results[\"model\"][\"lr\"].positive_mv,\n",
    "            }, F\"{exp_id}.pt\")\n",
    "\n",
    "print(\"*** All done! ***\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee3ea70-1e74-45de-b8d6-8bc298f526ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
