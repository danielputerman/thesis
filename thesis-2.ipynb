{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ce214c74-c41b-4cbc-9d0c-1e107bfa5aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "from torch.utils.data import Dataset as Dataset\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal\n",
    "from matplotlib import pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from datetime import datetime\n",
    "from typing import Optional, TextIO\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7977481a-dcd8-4ce9-932c-2558cca2b59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cpu\") # No point in using MPS for now :( See https://github.com/pytorch/pytorch/issues/77799"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95be1ac1-bb89-49c3-ae3f-32ec426172dd",
   "metadata": {},
   "source": [
    "## NN Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "06298ae5-d3f4-4865-8d24-7546ba410958",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses_over_epochs(train_losses: list[float], valid_losses: list[float]):\n",
    "    '''\n",
    "    Graphically show the training and validation loss for each epoch.\n",
    "    '''\n",
    "    \n",
    "    # temporarily change the style of the plots to seaborn \n",
    "    plt.style.use('seaborn')\n",
    "\n",
    "    train_losses = np.array(train_losses) \n",
    "    valid_losses = np.array(valid_losses)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize = (8, 4.5))\n",
    "\n",
    "    ax.plot(train_losses, color='blue', label='Training loss') \n",
    "    ax.plot(valid_losses, color='red', label='Validation loss')\n",
    "    ax.set(title=\"Loss over epochs\", \n",
    "            xlabel='Epoch',\n",
    "            ylabel='Loss') \n",
    "    ax.legend()\n",
    "    fig.show()\n",
    "    \n",
    "    # change the plot style to default\n",
    "    plt.style.use('default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b68323c6-3567-4d0f-a193-aa326d43f069",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_single_epoch(loader, criterion, model, optimizer, normalize_input_fn, normalize_labels_fn, positive_class = 1, train=True):\n",
    "    '''\n",
    "    Implementation a single epoch for the training/validation loop.\n",
    "    '''        \n",
    "    \n",
    "    model.train() if train else model.eval() \n",
    "    \n",
    "    running_loss = 0\n",
    "    \n",
    "    # Each iteration gets a batch from the train loader\n",
    "    for X, Y_true in loader:\n",
    "        X = normalize_input_fn(X) # Normalizing the input if necessary\n",
    "        X = X.to(DEVICE)\n",
    "        Y_true = Y_true.to(DEVICE)\n",
    "        # Y_true = normalize_labels_fn(Y_true)\n",
    "        # Y_true[Y_true == positive_class]  = 1 # We \"normalize\" the label of the positive class to be \"1\". Makes our lives easier (see comment below)\n",
    "        \n",
    "        optimizer.zero_grad() if train else None\n",
    "        \n",
    "        # Forward pass\n",
    "        Y_logits, Y_prob = model(X)\n",
    "        _, predicted_labels = torch.max(Y_prob, 1)  # The \"1\" is acutally misleading - it's the dimension to search the max in.\n",
    "                                                        # This actually returns the indices of the highest prediction for each row, \n",
    "                                                        # but since the index is one-to-one with the predicted digit (i.e., 0 or 1), \n",
    "                                                        # we use the index of the max probability as the label that's being predicted\n",
    "        batch_loss = criterion(Y_logits, Y_true) # we use the logits as the parameter since \"CELoss already pefroms softmax internally.\n",
    "        running_loss += batch_loss.item() * X.size(0) # X.size(0) is the size of the BATCH, not the image. \n",
    "                                                # The multiplication is required later for calculating the avg loss of the epoch step.\n",
    "        \n",
    "        # Backward pass, only required in training the model\n",
    "        if train:\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    avg_batch_loss_for_epoch = running_loss / len(loader.dataset)\n",
    "    return model, optimizer, avg_batch_loss_for_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7e981840-3d2d-4cf4-99bb-82347b160df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_loop(train_loader, validation_loader, criterion, model, optimizer, positive_class=1, num_epochs=10, normalize_input_fn=lambda x: x, \n",
    "             normalize_labels_fn=lambda y: y, print_every=1):\n",
    "    \n",
    "    # Objects for storing metrics\n",
    "    best_loss = 1e10\n",
    "    train_losses = []\n",
    "    validation_losses = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # print(f'Epoch: {epoch}\\t')\n",
    "        \n",
    "        # Training the model\n",
    "        _, _, train_loss = run_single_epoch(train_loader, criterion, model, optimizer, normalize_input_fn, normalize_labels_fn, positive_class)\n",
    "        train_losses.append(train_loss)\n",
    "        \n",
    "        # No need for validation when working with a score model\n",
    "        validation_losses.append(0)\n",
    "        # # Validation\n",
    "        # with torch.no_grad():\n",
    "        #     _, _, validation_loss = run_single_epoch(validation_loader, criterion, model, None, normalize_input_fn, normalize_labels_fn, positive_class, False)\n",
    "        #     validation_losses.append(validation_loss)\n",
    "        \n",
    "        # if epoch % print_every == (print_every - 1):\n",
    "        #     print(f'{datetime.now().time().replace(microsecond=0)} --- '\n",
    "        #           f'Epoch: {epoch}\\t'\n",
    "        #           f'Train loss: {train_loss:.4f}\\t'\n",
    "        #           # f'Vaildation loss: {validation_loss:.4f}\\t')\n",
    "        #           f'Vaildation loss: 0\\t')\n",
    "    \n",
    "    plot_losses_over_epochs(train_losses, validation_losses)\n",
    "        \n",
    "    return model, optimizer, num_epochs, (train_losses, validation_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d4ae6f-9b94-4f17-8a2d-0625afb7dfe4",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "558223a6-75d2-48f9-8fd1-6165d46c57f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet5(nn.Module):\n",
    "\n",
    "    def __init__(self, n_classes):\n",
    "        \n",
    "        super(LeNet5, self).__init__()\n",
    "        \n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1),\n",
    "            nn.Tanh(),\n",
    "            nn.AvgPool2d(kernel_size=2),\n",
    "            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1),\n",
    "            nn.Tanh(),\n",
    "            nn.AvgPool2d(kernel_size=2),\n",
    "            nn.Conv2d(in_channels=16, out_channels=120, kernel_size=5, stride=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(in_features=120, out_features=84),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(in_features=84, out_features=n_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        logits = self.classifier(x)\n",
    "        probabilities = F.softmax(logits, dim=1)\n",
    "        return logits, probabilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "fc3d7d05-586c-4e42-af9c-d3e93d6f5c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleDataSet(Dataset):\n",
    "    def __init__(self, data, targets):\n",
    "        super(SimpleDataSet, self).__init__()\n",
    "        assert data.shape[0] == targets.shape[0] # assuming shape[0] = dataset size\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.targets.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index], self.targets[index].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "823dd6c8-4934-46a6-ae3b-9ac6e9aa6eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncodeBasedLikelihoodRatioModel():\n",
    "    def __init__(self, vae, null_mv, positive_mv):\n",
    "        self.vae = vae\n",
    "        self.null_mv = null_mv\n",
    "        self.positive_mv = positive_mv\n",
    "    \n",
    "    def __call__(self, value):\n",
    "        mu_logvar = self.vae.encoder(value.view(-1, 1024)).view(-1, 2, LATENT_DIM)\n",
    "        mu = mu_logvar[:, 0, :]\n",
    "        llr = self.positive_mv.log_prob(mu) - self.null_mv.log_prob(mu)\n",
    "        # We need a 0s \"column as the first col to represent the probability of the \"null\" class (same as LeNet result)\n",
    "        llr_0_padded_right = torch.stack((torch.zeros(llr.view(-1,1).shape[0]).view(-1,1),llr.view(-1,1)), dim=1).squeeze()\n",
    "        return None, llr_0_padded_right\n",
    "    \n",
    "    def eval(self):\n",
    "        pass\n",
    "\n",
    "class LikelihoodRatioModel():\n",
    "    def __init__(self, null_mv, positive_mv):\n",
    "        self.null_mv = null_mv\n",
    "        self.positive_mv = positive_mv\n",
    "    \n",
    "    def __call__(self, value):\n",
    "        llr = self.positive_mv.log_prob(value) - self.null_mv.log_prob(value)\n",
    "        # We need a 0s \"column as the first col to represent the probability of the \"null\" class (same as LeNet result)\n",
    "        llr_0_padded_right = torch.stack((torch.zeros(llr.view(-1,1).shape[0]).view(-1,1),llr.view(-1,1)), dim=1).squeeze()\n",
    "        return None, llr_0_padded_right\n",
    "    \n",
    "    def eval(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86b6c0a-f40b-48fb-a9cf-723d020a1a38",
   "metadata": {},
   "source": [
    "## Samples Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "04d0731f-1cff-4681-84c4-203d8ef7cf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "LATENT_DIM = 5\n",
    "\n",
    "class VAEFC(nn.Module):\n",
    "    '''\n",
    "    A fully-connectec variational autoencoder (as opposed to convolution-based) used as generative model for MNIST.\n",
    "    '''\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(1024, 400),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(400, 400),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(400, LATENT_DIM * 2)\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(LATENT_DIM, 400),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(400, 400),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(400, 1024),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def reparameterise(self, mu, logvar):\n",
    "        if self.training:\n",
    "            std = logvar.mul(0.5).exp_()\n",
    "            eps = std.new_empty(std.size()).normal_()\n",
    "            return eps.mul_(std).add_(mu)\n",
    "        else:\n",
    "            return mu\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu_logvar = self.encoder(x.view(-1, 1024)).view(-1, 2, LATENT_DIM)\n",
    "        mu = mu_logvar[:, 0, :]\n",
    "        logvar = mu_logvar[:, 1, :]\n",
    "        z = self.reparameterise(mu, logvar)\n",
    "        return self.decoder(z), mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "24be2c54-bcf3-47b0-aced-f08bf43e5df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_loss_for_single_element_batch(x_hat, x, mu, logvar, y=None, β=3):\n",
    "    '''\n",
    "    'Dynamic' loss: changes based on the type of MNIST digit. This forces the VAE to place each digit near the mean we want, effectively\n",
    "    creating a mixture model of normals.\n",
    "\n",
    "    IMPORTANT: THIS WILL ONLY WORK WITH BATCH_SIZE=1 because otherwise the loss will not be calculated correctly.\n",
    "    '''\n",
    "    base_loss = nn.functional.binary_cross_entropy(\n",
    "        x_hat, x.view(-1, 1024), reduction='sum'\n",
    "    )\n",
    "    # KLD = 0.5 * torch.sum(logvar.exp() - logvar - 1 + mu.pow(2)) # Orig KLD\n",
    "    \n",
    "    # KLD(p,q) = KL(N(m1,s1), N(m2,s2)) = log(std2/std1) + (s1 + ((m1-m2)^2))/(2*s2) - 1/2    , where s is VARIANCE (not STD), std1=sqrt(s1)\n",
    "    KLD = 0\n",
    "    if y[0]==4:\n",
    "        KLD = 0.5 * torch.sum(logvar.exp() - logvar + (mu-1).pow(2) -1)\n",
    "    else:\n",
    "        KLD = 0.5 * torch.sum(logvar.exp() - logvar + (mu+1).pow(2) -1)\n",
    "    return base_loss + β * KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "6fd0552d-1b97-416a-ba3f-5f52d234ea0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data loading step\n",
    "\n",
    "class_map = {\"null\": 4, \"positive\": 9}\n",
    "labels_map = {4:0, 9:1} \n",
    "\n",
    "def get_loader_for_vae(dataset, class_to_load=None, batch_size=1, num_samples=None):\n",
    "    if class_to_load is None:\n",
    "        samples_index = torch.logical_or(dataset.targets == class_map[\"null\"] ,dataset.targets == class_map[\"positive\"]).nonzero().reshape(-1)\n",
    "    else:\n",
    "        samples_index = (dataset.targets == class_map[class_to_load]).nonzero().reshape(-1)\n",
    "    if num_samples is not None:\n",
    "        samples_index = samples_index[:num_samples]\n",
    "    print(F\"sample index: {samples_index.shape}\")\n",
    "    return DataLoader(dataset,batch_size=batch_size, shuffle=False, sampler=SubsetRandomSampler(samples_index), drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a1b0f7c8-eb16-42f8-9ab6-38b1e99e27e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_VAE(vae, train_loader, vae_criterion, epochs=10):\n",
    "    \n",
    "    learning_rate = 1e-3\n",
    "    \n",
    "    vae_optimizer = torch.optim.Adam(\n",
    "        vae.parameters(),\n",
    "        lr=learning_rate,\n",
    "    )\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        vae.train()\n",
    "        train_loss = 0\n",
    "        print(f'====> VAE Epoch: {epoch}')\n",
    "        for x, label in train_loader:\n",
    "            x = x.to(DEVICE)\n",
    "            # ===================forward=====================\n",
    "            x_hat, mu, logvar = vae(x)\n",
    "            loss = vae_criterion(x_hat, x, mu, logvar, label)\n",
    "            train_loss += loss.item()\n",
    "            # ===================backward====================\n",
    "            vae_optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            vae_optimizer.step()\n",
    "        # ===================log========================\n",
    "        print(f'VAE Average loss: {train_loss / len(train_loader.dataset):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "1fda199d-5447-446c-885d-ae0403ba8a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict\n",
    "\n",
    "VAECodes = TypedDict('VAECodes', {'mu': torch.Tensor, 'logvar': torch.Tensor, 'label': torch.Tensor})\n",
    "\n",
    "def get_VAE_codes_for_samples(vae: torch.nn.Module, loader: torch.utils.data.DataLoader) -> VAECodes: \n",
    "    codes = dict(mu=list(), logvar=list(), label=list())\n",
    "    means, logvars, labels = list(), list(), list()\n",
    "    with torch.no_grad():\n",
    "        vae.eval()\n",
    "        for x, y in loader:\n",
    "            x = x.to(DEVICE)\n",
    "            # ===================forward=====================\n",
    "            x_hat, mu, logvar = vae(x)\n",
    "            # =====================log=======================\n",
    "            means.append(mu.detach())\n",
    "            logvars.append(logvar.detach())\n",
    "            labels.append(y.detach())\n",
    "    # ===================log========================\n",
    "    codes['mu'] = torch.cat(means)\n",
    "    codes['logvar']= torch.cat(logvars)\n",
    "    codes['label'] = torch.cat(labels)\n",
    "    return codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "7233c658-11cb-455b-8ef5-6a2f875f7a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_and_vcov_for_vae_codes(codes: VAECodes):\n",
    "        mean_tensor = codes['mu'].mean(0)\n",
    "        centered_mus = codes['mu'] - mean_tensor\n",
    "        vcov = centered_mus.T.cov()\n",
    "        return dict(mean=mean_tensor, vcov=vcov, centered_mus=centered_mus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "792edc8b-4753-49d1-99e8-9422cc9506e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "VAEResult = TypedDict('VAEResult', {'vae': torch.nn.Module, 'null_mean': torch.Tensor, 'positive_mean':torch.Tensor, 'common_vcov': torch.Tensor})\n",
    "\n",
    "image_padding_to_32 = transforms.Compose([transforms.Resize((32,32)), transforms.ToTensor()])\n",
    "\n",
    "def get_trained_vae() -> torch.nn.Module:\n",
    "    '''\n",
    "    Returns: an MNIST-trained VAE.\n",
    "    '''\n",
    "    # Loading relevant data\n",
    "    train_all_loader = get_loader_for_vae(MNIST('./data', train=True, download=True, transform=image_padding_to_32))\n",
    "\n",
    "    # Create and train the VAE\n",
    "    vae = VAEFC().to(DEVICE)\n",
    "    train_VAE(vae, train_all_loader, vae_loss_for_single_element_batch)\n",
    "    \n",
    "    return vae\n",
    "\n",
    "\n",
    "def get_vae_stats(vae: torch.nn.Module):\n",
    "    '''\n",
    "    Parameters:\n",
    "        vae: The MNIST-trained VAE to get the stats from.\n",
    "    \n",
    "    Returns:\n",
    "        a Dictionary of the form: {null_mean: torch.Tensor, positive_mean: torch.Tensor, common_vcov: torch.Tensor} \n",
    "    '''\n",
    "    # Loading relevant data\n",
    "    train_null_only = get_loader_for_vae(MNIST('./data', train=True, download=True, transform=image_padding_to_32), class_to_load=\"null\")\n",
    "    train_positive_only = get_loader_for_vae(MNIST('./data', train=True, download=True, transform=image_padding_to_32), class_to_load=\"positive\")\n",
    "    \n",
    "    # get codes for null and positive classes\n",
    "    null_codes = get_VAE_codes_for_samples(vae, train_null_only)\n",
    "    positive_codes = get_VAE_codes_for_samples(vae, train_positive_only)\n",
    "    \n",
    "    # get the interesting stats to be used for the generation later\n",
    "    null_stats = get_mean_and_vcov_for_vae_codes(null_codes)\n",
    "    positive_stats = get_mean_and_vcov_for_vae_codes(positive_codes)\n",
    "    \n",
    "    # calculate common vcov matrix (we want this so that the likelihood ratio will translate to LDA).\n",
    "    all_centered_means = torch.cat((null_stats['centered_mus'], positive_stats['centered_mus']))\n",
    "    common_vcov= all_centered_means.T.cov()\n",
    "    \n",
    "    return dict(null_mean=null_stats['mean'], positive_mean=positive_stats['mean'], common_vcov=common_vcov)\n",
    "    \n",
    "    \n",
    "def get_trained_vae_and_stats() -> VAEResult:\n",
    "    vae = get_trained_vae()\n",
    "    stats = get_vae_stats(vae)\n",
    "    return dict(vae=vae, null_mean=stats['null_mean'], positive_mean=stats['positive_mean'], common_vcov=stats['common_vcov'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "dae9f1b8-4dc2-459b-98e3-ec017203476d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_generated_datasets_from_vae(vae: torch.nn.Module, null_mv: torch.distributions.MultivariateNormal, positive_mv: torch.distributions.MultivariateNormal):\n",
    "    \n",
    "    TRAINING_SIZE = 4000\n",
    "    TEST_NULL_SIZE = 1000\n",
    "    TEST_POSITIVE_SIZE = 1000\n",
    "    BENCHMARK_NULL_SIZE = 2000\n",
    "    BENCHMARK_POSITIVE_SIZE = 2000\n",
    "    with torch.no_grad():\n",
    "        vae.eval()\n",
    "        \n",
    "        # Training set (only 4s)\n",
    "        training_codes = null_mv.sample(torch.Size([TRAINING_SIZE]))\n",
    "        training_data = vae.decoder(training_codes).unsqueeze(dim=1).view(-1,1,32,32)\n",
    "        training_targets = torch.repeat_interleave(torch.tensor([0]), TRAINING_SIZE)\n",
    "        training_set = SimpleDataSet(training_data, training_targets)\n",
    "\n",
    "        # Benchmark set (4 and 9s)\n",
    "        benchmark_null_codes = null_mv.sample(torch.Size([BENCHMARK_NULL_SIZE]))\n",
    "        benchmark_positive_codes = positive_mv.sample(torch.Size([BENCHMARK_POSITIVE_SIZE]))\n",
    "        benchmark_codes = torch.cat((benchmark_null_codes, benchmark_positive_codes)) \n",
    "        benchmark_null_targets = torch.repeat_interleave(torch.tensor([0]), BENCHMARK_NULL_SIZE)\n",
    "        benchmark_positive_targets = torch.repeat_interleave(torch.tensor([1]), BENCHMARK_POSITIVE_SIZE)\n",
    "        benchmark_targets = torch.cat((benchmark_null_targets, benchmark_positive_targets)) \n",
    "        shuffle = torch.randperm(BENCHMARK_NULL_SIZE + BENCHMARK_POSITIVE_SIZE) # we want mixed, random-ordered samples\n",
    "        benchmark_codes = benchmark_codes[shuffle]\n",
    "        benchmark_targets = benchmark_targets[shuffle]\n",
    "        benchmark_data = vae.decoder(benchmark_codes).unsqueeze(dim=1).view(-1,1,32,32)\n",
    "        benchmark_set = SimpleDataSet(benchmark_data, benchmark_targets)\n",
    "\n",
    "\n",
    "        # Test set (4 and 9s)\n",
    "        test_null_codes = null_mv.sample(torch.Size([TEST_NULL_SIZE]))\n",
    "        test_positive_codes = positive_mv.sample(torch.Size([TEST_POSITIVE_SIZE]))\n",
    "        test_codes = torch.cat((test_null_codes, test_positive_codes)) \n",
    "        test_null_targets = torch.repeat_interleave(torch.tensor([0]), TEST_NULL_SIZE)\n",
    "        test_positive_targets = torch.repeat_interleave(torch.tensor([1]), TEST_POSITIVE_SIZE)\n",
    "        test_targets = torch.cat((test_null_targets, test_positive_targets)) \n",
    "        shuffle = torch.randperm(TEST_NULL_SIZE + TEST_POSITIVE_SIZE) # we want mixed, random-ordered samples\n",
    "        test_codes = test_codes[shuffle]\n",
    "        test_targets = test_targets[shuffle]\n",
    "        test_data = vae.decoder(test_codes).unsqueeze(dim=1).view(-1,1,32,32)\n",
    "        test_set = SimpleDataSet(test_data, test_targets)\n",
    "\n",
    "        return training_set, test_set, benchmark_set, training_codes, test_codes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc3169d-bb28-4a84-b604-40abc522e731",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "9c8f9c0d-79aa-49ad-94d0-8cd3088668b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trained_model(train_loader, test_loader, num_epochs=20):\n",
    "    LEARNING_RATE = 1e-3\n",
    "    N_CLASSES = 2\n",
    "    \n",
    "    model = nn.DataParallel(LeNet5(N_CLASSES)) # We create the model from scratch for each experiment\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    return run_loop(train_loader, test_loader, criterion, model, optimizer, normalize_input_fn=lambda x: x / 255.0, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "47ae51f0-5daa-445a-bfdb-62fc6324098e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConcatDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, datasetA, datasetB):\n",
    "        super(ConcatDataset, self).__init__()\n",
    "        self.datasetA = datasetA\n",
    "        self.datasetB = datasetB\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        if i<len(self.datasetA):\n",
    "            return self.datasetA[i]\n",
    "        else:\n",
    "            return self.datasetB[i-len(self.datasetA)]\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.datasetA) + len(self.datasetB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "9c86dc35-165a-4a32-a553-f7d20d4e48a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def clone_and_new_computation_graph(t: torch.Tensor, requires_grad=True) -> torch.Tensor:\n",
    "    '''\n",
    "        Returns: \n",
    "            A Tensor with the same data (copied) as `t`, on a new computation graph\n",
    "    '''\n",
    "    t2 = torch.detach(t).clone()\n",
    "    if requires_grad:\n",
    "        t2.requires_grad_()\n",
    "    return t2\n",
    "\n",
    "\n",
    "def get_synthetic_h0_h1(training_set: SimpleDataSet, test_set: SimpleDataSet, training_codes: torch.Tensor, test_codes: torch.Tensor) -> tuple[SimpleDataSet, SimpleDataSet, SimpleDataSet, int, Optional[torch.Tensor], Optional[torch.Tensor]]:\n",
    "    '''\n",
    "    Parameters:\n",
    "        Training and Test datasets. Each of the following form:\n",
    "            Dataset.data: 4-D tensor (batch size, channels, width, height). This is because nn.Conv2d expects input of this shape.\n",
    "            Dataset.targets: 1-D tensor (target class)\n",
    "    Returns:\n",
    "        H0, H1, H1 with true target values (used for validation), K\n",
    "    '''\n",
    "    \n",
    "    # k = math.floor(len(training_set) / 2) # TODO sample random k instead?\n",
    "    k = len(training_set)- len(test_set) # TODO sample random k instead?\n",
    "    # k = len(training_set) - 50\n",
    "    original_training_data = training_set.data\n",
    "    original_training_targets = training_set.targets\n",
    "\n",
    "    # Create H0 set by *copying* the training set, and have it use a separate computation graph.\n",
    "    h0_data = clone_and_new_computation_graph(original_training_data[:k])\n",
    "    h0_codes = training_codes[:k] if training_codes is not None else None\n",
    "    h0_targets = clone_and_new_computation_graph(original_training_targets[:k], requires_grad=False)\n",
    "    h0_targets[:] = 0\n",
    "\n",
    "    h0_set = SimpleDataSet(h0_data, h0_targets)\n",
    "    \n",
    "    # Create H1 and H1_true_targets sets by *copying* the data and have it use a separate computation graph\n",
    "    h1_0_data = clone_and_new_computation_graph(original_training_data[k:])\n",
    "    h1_0_codes = training_codes[k:] if training_codes is not None else None\n",
    "    h1_0_targets = clone_and_new_computation_graph(original_training_targets[k:], requires_grad=False)\n",
    "    h1_0_targets[:] = 1\n",
    "        \n",
    "    h1_0_data_for_true_targets = clone_and_new_computation_graph(original_training_data[k:])\n",
    "    h1_0_true_targets = clone_and_new_computation_graph(original_training_targets[k:], requires_grad=False)\n",
    "    \n",
    "    original_test_data = test_set.data\n",
    "    original_test_targets = test_set.targets\n",
    "    h1_1_data = clone_and_new_computation_graph(original_test_data)\n",
    "    h1_1_codes = test_codes if test_codes is not None else None\n",
    "    h1_1_targets = clone_and_new_computation_graph(original_test_targets, requires_grad=False)\n",
    "    h1_1_targets[:] = 1\n",
    "    \n",
    "    h1_1_data_for_true_targets = clone_and_new_computation_graph(original_test_data)\n",
    "    h1_1_true_targets = clone_and_new_computation_graph(original_test_targets, requires_grad=False)\n",
    "    \n",
    "    h1_data = torch.cat((h1_0_data, h1_1_data), 0)\n",
    "    h1_codes = torch.cat((h1_0_codes, h1_1_codes)) if test_codes is not None else None\n",
    "    h1_targets = torch.cat((h1_0_targets, h1_1_targets), 0)\n",
    "    \n",
    "    h1_set = SimpleDataSet(h1_data, h1_targets)\n",
    "    \n",
    "    h1_data_true = torch.cat((h1_0_data_for_true_targets, h1_1_data_for_true_targets), 0)\n",
    "    h1_targets_true = torch.cat((h1_0_true_targets, h1_1_true_targets), 0)\n",
    "    \n",
    "    h1_set_with_true_targets = SimpleDataSet(h1_data_true, h1_targets_true)\n",
    "    \n",
    "\n",
    "    return h0_set, h1_set, h1_set_with_true_targets, k, h0_codes, h1_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d6e556c7-9a5d-4d26-bba3-64222e4a204d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datasets_for_discovery(experiment_type: int, add_noise=False) -> tuple[SimpleDataSet, SimpleDataSet]:\n",
    "    '''\n",
    "    Parameters:\n",
    "        experiment_type:\n",
    "            1 - test data is only H1, no noise\n",
    "            2 - test data is a mix of H0 and H1, no noise\n",
    "            \n",
    "    Returns:\n",
    "        A Tuple of (training_set, test_set, benchmark_set)\n",
    "            Dataset.data: 4-D tensor (batch size, channels, width, height). This is because nn.Conv2d expects input of this shape.\n",
    "            Dataset.targets: 1-D tensor (target class)\n",
    "    '''\n",
    "    \n",
    "    BENCHMARK_TRAINING_SIZE = 1000 # data used for training a *standard* classifier for benchmark purposes\n",
    "    \n",
    "    image_padding_to_32 = transforms.Compose([transforms.Resize((32,32)), transforms.ToTensor()])\n",
    "    \n",
    "    if add_noise:\n",
    "        raise NotImplementedError(\"Adding noise was not yet implemented\")\n",
    "        \n",
    "    ## Training data\n",
    "    training_set_full = datasets.MNIST(root='./data', download=True, transform=image_padding_to_32, train=True)\n",
    "    training_subset_index = (training_set_full.targets == 4).nonzero().reshape(-1)\n",
    "    training_subset_loader = torch.utils.data.DataLoader(dataset=training_set_full, batch_size=len(training_subset_index), shuffle=False, sampler=Data.SubsetRandomSampler(training_subset_index))\n",
    "    training_subset_data, training_subset_targets = next(iter(training_subset_loader)) # We only need one iteration, as the loader has the size of the entire relevant sample\n",
    "\n",
    "    assert len(training_subset_targets[(training_subset_targets!=4).nonzero().reshape(-1)])==0 # Avoid bugs in data loading. You're welcome hahaha\n",
    "    \n",
    "    training_subset_targets[(training_subset_targets==4).nonzero().reshape(-1)] = 0  # Set the targets' value to 0 (as this is our \"null\" class).\n",
    "\n",
    "    # Separating training for Adadetect and benchmark\n",
    "    benchmark_four_subset_data = training_subset_data[-BENCHMARK_TRAINING_SIZE:]\n",
    "    benchmark_four_subset_targets = training_subset_targets[-BENCHMARK_TRAINING_SIZE:]\n",
    "    \n",
    "    # Notice that since we update training_subset_data itself, this MUST happen AFTER we already got the benchmark data.\n",
    "    training_subset_data = training_subset_data[:-BENCHMARK_TRAINING_SIZE]\n",
    "    training_subset_targets = training_subset_targets[:-BENCHMARK_TRAINING_SIZE]\n",
    "    \n",
    "    benchmark_nine_subset_index = (training_set_full.targets == 9).nonzero().reshape(-1)\n",
    "    benchmark_nine_subset_loader = torch.utils.data.DataLoader(dataset=training_set_full, batch_size=len(benchmark_nine_subset_index), shuffle=False, sampler=Data.SubsetRandomSampler(benchmark_nine_subset_index))\n",
    "    benchmark_nine_subset_data, benchmark_nine_subset_targets = next(iter(benchmark_nine_subset_loader)) \n",
    "    \n",
    "    assert len(benchmark_nine_subset_targets[(benchmark_nine_subset_targets!=9).nonzero().reshape(-1)])==0 # Avoid bugs in data loading. You're welcome hahaha\n",
    "    \n",
    "    benchmark_nine_subset_targets[(benchmark_nine_subset_targets==9).nonzero().reshape(-1)] = 1  # Set the targets' value to 1 (as this is our \"positive\" class).\n",
    "    \n",
    "    benchmark_data = torch.cat([benchmark_four_subset_data, benchmark_nine_subset_data], dim=0)\n",
    "    benchmark_targets = torch.cat([benchmark_four_subset_targets,benchmark_nine_subset_targets], dim=0)\n",
    "    benchmark_set = SimpleDataSet(benchmark_data, benchmark_targets)\n",
    "    \n",
    "    training_set = SimpleDataSet(training_subset_data, training_subset_targets)\n",
    "    \n",
    "    ## Test data\n",
    "    test_set_full = datasets.MNIST(root='./data', download=True, transform=image_padding_to_32, train=False)\n",
    "    test_subset_index = []\n",
    "    if experiment_type==1:\n",
    "        test_subset_index = (test_set_full.targets == 9).nonzero().reshape(-1)\n",
    "    elif experiment_type==2:\n",
    "        test_subset_index = torch.logical_or(test_set_full.targets == 4, test_set_full.targets == 9).nonzero().reshape(-1)\n",
    "    else:\n",
    "        raise NotImplementedError(\"Only 1,2 experiment types are supported\")\n",
    "    \n",
    "    test_subset_loader = torch.utils.data.DataLoader(dataset=test_set_full, batch_size=len(test_subset_index), shuffle=False, sampler=Data.SubsetRandomSampler(test_subset_index))\n",
    "    test_subset_data, test_subset_targets = next(iter(test_subset_loader))\n",
    "    test_subset_targets[(test_subset_targets==4).nonzero().reshape(-1)] = 0\n",
    "    test_subset_targets[(test_subset_targets==9).nonzero().reshape(-1)] = 1\n",
    "    test_set = SimpleDataSet(test_subset_data, test_subset_targets)\n",
    "    \n",
    "    return training_set, test_set, benchmark_set, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d3ddb536-ce1a-4bdb-a39a-94a725c9a66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_knockoffs(score_model, h1_set, h1_set_with_true_targets, l, m, alpha):\n",
    "    with torch.no_grad():\n",
    "        score_model.eval()\n",
    "        _, probability_scores = score_model(h1_set.data.to(DEVICE)) # probability scores is a tensor of pairs (p(0), p(1)).\n",
    "    probability_of_discovery = probability_scores[:,1].numpy() # We only care about the probability of a discovery (p(1))\n",
    "\n",
    "    print(F\"probability scores: {probability_scores}\")\n",
    "    print(F\"probability of discovery: {probability_of_discovery}\")\n",
    "    scores_df = pd.DataFrame({'score': probability_of_discovery, 'is_test': np.concatenate((np.repeat(0, l),np.repeat(1,m))),'truth':h1_set_with_true_targets.targets.numpy()})\n",
    "    scores_df.sort_values(by=['score'], inplace=True, ascending=True)\n",
    "    \n",
    "    fdp = 10 # a value which is definitely bigger than alpha\n",
    "    \n",
    "    for lower_bound in range(len(h1_set)):\n",
    "        scores_window_df = scores_df[lower_bound:] # get the subset of the samples we want to test with.\n",
    "        ktest = len(scores_window_df[scores_window_df['is_test']==1]) # This is the \"moving\" k, which changes as we move the lower score bound.\n",
    "        v = len(scores_window_df[scores_window_df['is_test']==0]) # The count of false discoveries that we know of (i.e., training samples)\n",
    "        try: \n",
    "            fdp = ((v+1) / (l+1)) * (m / ktest)\n",
    "        except ZeroDivisionError:\n",
    "            fdp = 99999\n",
    "            break\n",
    "        # print(F\"ktest: {ktest},\\t\"\n",
    "        #       F\"v: {v},\\t\"\n",
    "        #       F\"m: {m},\\t\"\n",
    "        #       F\"l: {l},\\t\"\n",
    "        #       F\"fdp: {fdp}\")\n",
    "\n",
    "        if fdp<=alpha:\n",
    "            # print(F\"Got FDP of {fdp} <= alpha({alpha}) , for lower bound: {lower_bound}\")\n",
    "            break\n",
    "    \n",
    "    total_elements = len(scores_window_df)\n",
    "    total_discoveries = ktest\n",
    "    false_discoveries = len(scores_window_df[(scores_window_df['is_test']==1) & (scores_window_df['truth']==0)])\n",
    "    \n",
    "    return dict(total_elements=total_elements, total_discoveries=total_discoveries,false_discoveries=false_discoveries,v=v,fdp=fdp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "bbf0a781-c9cd-4d00-a8b3-05641b8e7a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_discovery(seed, batch_size, experiment_type, alpha=0.1, use_generative=True):\n",
    "    \n",
    "    # Reproducability :-)\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    \n",
    "    null_mv = None\n",
    "    positive_mv = None\n",
    "    if use_generative:\n",
    "        vae_result = get_trained_vae_and_stats()\n",
    "        vae = vae_result['vae']\n",
    "        null_mean = vae_result['null_mean']\n",
    "        positive_mean = vae_result['positive_mean']\n",
    "        vcov = vae_result['common_vcov']\n",
    "        null_mv = MultivariateNormal(null_mean, vcov)\n",
    "        positive_mv = MultivariateNormal(positive_mean, vcov)\n",
    "    \n",
    "    \n",
    "    # Get the data (notice this loads in a different random order each time, given the seed)\n",
    "    training_set, test_set, benchmark_set, training_codes, test_codes = get_generated_datasets_from_vae(vae, null_mv, positive_mv) if use_generative else get_datasets_for_discovery(experiment_type)\n",
    "        \n",
    "    # Re-divide train and test data for AdaDetect\n",
    "    h0_set, h1_set, h1_set_with_true_targets, k, h0_codes, h1_codes = get_synthetic_h0_h1(training_set, test_set, training_codes, test_codes)\n",
    "    # print(F\"Training set size: {len(training_set)}, Test set size: {len(test_set)}\")\n",
    "    # print(F\"Selected K: {k}, h0 size: {len(h0_set)} , h1 size: {len(h1_set)}\")\n",
    "    h0h1_set = ConcatDataset(h0_set,h1_set)\n",
    "    h0h1_loader = DataLoader(h0h1_set, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    # Benchmark data loader\n",
    "    benchmark_loader = DataLoader(benchmark_set, shuffle=True)\n",
    "\n",
    "    ## Use BoNuS and Knockoff counting for stating discoveries while keeping FDR\n",
    "    l = len(training_set)-k # This is the length of the \"2nd part\" of the null samples, which will be concatenated to the test sample\n",
    "    m = len(test_set)\n",
    "    \n",
    "    # Training\n",
    "    real_model, optimizer, num_epochs, (train_losses, validation_losses) = get_trained_model(h0h1_loader, None, num_epochs=20)\n",
    "    benchmark_model, bm_optimizer, bm_num_epochs, (bm_train_losses, bm_validation_losses) = get_trained_model(benchmark_loader, None, num_epochs=50)\n",
    "\n",
    "    # Knockoff Process\n",
    "    real_knockoff_results = perform_knockoffs(real_model, h1_set, h1_set_with_true_targets, l, m, alpha)\n",
    "    benchmark_knockoff_results = perform_knockoffs(benchmark_model, h1_set, h1_set_with_true_targets, l, m, alpha)\n",
    "    \n",
    "    lr_model = LikelihoodRatioModel(null_mv, positive_mv) if use_generative else None\n",
    "    lr_knockoff_results = perform_knockoffs(lr_model, h1_codes, h1_set_with_true_targets, l, m, alpha) if use_generative else dict(total_elements=-1, total_discoveries=-1, false_discoveries=-1,v=-1,fdp=-1)\n",
    "    \n",
    "    return dict(model=dict(real=real_model, benchmark=benchmark_model, lr=lr_model),\n",
    "                optimizer=dict(real=optimizer,benchmark=bm_optimizer),\n",
    "                alpha=alpha,\n",
    "                training_set_size=len(training_set),\n",
    "                test_set_size=len(test_set),\n",
    "                m=m,\n",
    "                l=l,\n",
    "                num_epochs=dict(real=num_epochs, benchmark=bm_num_epochs),\n",
    "                final_CELoss=dict(real=train_losses[-1], benchmark=bm_train_losses[-1]),\n",
    "                total_elements=dict(real=real_knockoff_results[\"total_elements\"], benchmark=benchmark_knockoff_results[\"total_elements\"], lr=lr_knockoff_results[\"total_elements\"]),\n",
    "                total_discoveries=dict(real=real_knockoff_results[\"total_discoveries\"], benchmark=benchmark_knockoff_results[\"total_discoveries\"], lr=lr_knockoff_results[\"total_discoveries\"]), \n",
    "                false_discoveries=dict(real=real_knockoff_results[\"false_discoveries\"], benchmark=benchmark_knockoff_results[\"false_discoveries\"], lr=lr_knockoff_results[\"false_discoveries\"]),\n",
    "                v=dict(real=real_knockoff_results[\"v\"], benchmark=benchmark_knockoff_results[\"v\"], lr=lr_knockoff_results[\"v\"]),\n",
    "                fdp=dict(real=real_knockoff_results[\"fdp\"], benchmark=benchmark_knockoff_results[\"fdp\"], lr=lr_knockoff_results[\"fdp\"]))\n",
    "    \n",
    "    # return dict(model=dict(real=None, benchmark=None, likelihood_ratio=lr_model),\n",
    "    #             optimizer=dict(real=None,benchmark=None),\n",
    "    #             alpha=alpha,\n",
    "    #             training_set_size=len(training_set),\n",
    "    #             test_set_size=len(test_set),\n",
    "    #             m=m,\n",
    "    #             l=l,\n",
    "    #             num_epochs=dict(real=0, benchmark=0),\n",
    "    #             final_CELoss=dict(real=-1, benchmark=-1),\n",
    "    #             total_elements=dict(real=-1, benchmark=-1, lr=lr_knockoff_results[\"total_elements\"]),\n",
    "    #             total_discoveries=dict(real=-1, benchmark=-1, lr=lr_knockoff_results[\"total_discoveries\"]), \n",
    "    #             false_discoveries=dict(real=-1, benchmark=-1, lr=lr_knockoff_results[\"false_discoveries\"]),\n",
    "    #             v=dict(real=-1, benchmark=-1, lr=lr_knockoff_results[\"v\"]),\n",
    "    #             fdp=dict(real=-1, benchmark=-1, lr=lr_knockoff_results[\"fdp\"]))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "295b1d85-5d39-4fe1-8801-d2cbad527a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiment_id,\texperiment_type,\tseed,\tbatch_size,\talpha,\ttraining set size,\ttest set size,\tm,\tl,\tAdaDetect num epochs,\tAdaDetect final CELoss,\tAdaDetect total elements,\tAdaDetect total discoveries (ktest),\tAdaDetect v,\tAdaDetect false discoveries,\tAdaDetect fdp,\tLR total elements,\tLR total discoveries (ktest),\tLR v,\tLR false discoveries,\tLR fdp,\tBenchmark num epochs,\tBenchmark final CELoss,\tBenchmark total elements,\tBenchmark total discoveries (ktest),\tBenchmark v,\tBenchmark false discoveries,\tBenchmark fdp\n",
      "2-0-2023-07-24-11-52-14,\t2,\t0,\t32,sample index: torch.Size([11791])\n",
      "====> VAE Epoch: 0\n",
      "VAE Average loss: 38.7850\n",
      "====> VAE Epoch: 1\n",
      "VAE Average loss: 36.0431\n",
      "sample index: torch.Size([5842])\n",
      "sample index: torch.Size([5949])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/x6/ctsmhfm56hj3xdv0z721s6lc0000gn/T/ipykernel_90919/1730830866.py:7: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.\n",
      "  plt.style.use('seaborn')\n",
      "/var/folders/x6/ctsmhfm56hj3xdv0z721s6lc0000gn/T/ipykernel_90919/1730830866.py:20: UserWarning: Matplotlib is currently using module://matplotlib_inline.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  fig.show()\n",
      "/var/folders/x6/ctsmhfm56hj3xdv0z721s6lc0000gn/T/ipykernel_90919/1730830866.py:7: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.\n",
      "  plt.style.use('seaborn')\n",
      "/var/folders/x6/ctsmhfm56hj3xdv0z721s6lc0000gn/T/ipykernel_90919/1730830866.py:20: UserWarning: Matplotlib is currently using module://matplotlib_inline.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probability scores: tensor([[0.3935, 0.6065],\n",
      "        [0.3902, 0.6098],\n",
      "        [0.3959, 0.6041],\n",
      "        ...,\n",
      "        [0.3921, 0.6079],\n",
      "        [0.3935, 0.6065],\n",
      "        [0.3918, 0.6082]])\n",
      "probability of discovery: [0.6065154  0.6097698  0.6041129  ... 0.60794127 0.60649407 0.60818124]\n",
      "probability scores: tensor([[0.0120, 0.9880],\n",
      "        [0.0040, 0.9960],\n",
      "        [0.9943, 0.0057],\n",
      "        ...,\n",
      "        [0.0040, 0.9960],\n",
      "        [0.0040, 0.9960],\n",
      "        [0.0090, 0.9910]])\n",
      "probability of discovery: [0.98796535 0.99596584 0.00565465 ... 0.99595624 0.99595624 0.9909915 ]\n",
      "probability scores: tensor([[  0.0000,  -5.9533],\n",
      "        [  0.0000, -11.6984],\n",
      "        [  0.0000, -10.4817],\n",
      "        ...,\n",
      "        [  0.0000,  14.5177],\n",
      "        [  0.0000,  13.9293],\n",
      "        [  0.0000, -11.7666]])\n",
      "probability of discovery: [ -5.953265 -11.698424 -10.481724 ...  14.517678  13.92935  -11.766648]\n",
      "\t0.1,\t4000,\t2000,\t2000,\t2000,\t1,\t0.6426431719462077,\t165,\t151,\t14,\t6,\t0.09928810429222475,\t1143,\t1040,\t103,\t43,\t0.09995002498750624,\t1,\t0.429538318639532,\t1,\t1,\t0,\t1,\t0.9995002498750625\n",
      "*** All done! ***\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x450 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x450 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class NullStream:\n",
    "        @staticmethod\n",
    "        def write(*_): pass\n",
    "        @staticmethod\n",
    "        def flush(*_): pass\n",
    "\n",
    "def print_to_stdout_and_stream(text, stream:TextIO = NullStream):\n",
    "        sys.stdout.write(text)\n",
    "        sys.stdout.flush()\n",
    "        stream.write(text)\n",
    "        stream.flush()\n",
    "\n",
    "# DEVICE = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "NUM_EXPERIMENT_TYPES = 2 # 1 - only 9, 2 - 4+9\n",
    "NUM_EXPERIMENTS_PER_TYPE = 5\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "\n",
    "with open('experiments-results.csv', mode='at', encoding=\"utf-8\") as results_stream:\n",
    "    print_to_stdout_and_stream(\"experiment_id,\\texperiment_type,\\tseed,\\tbatch_size,\\talpha,\\ttraining set size,\\ttest set size,\\tm,\\tl,\"\n",
    "                               \"\\tAdaDetect num epochs,\\tAdaDetect final CELoss,\\tAdaDetect total elements,\\tAdaDetect total discoveries (ktest),\\tAdaDetect v,\\tAdaDetect false discoveries,\\tAdaDetect fdp,\"\n",
    "                               \"\\tLR total elements,\\tLR total discoveries (ktest),\\tLR v,\\tLR false discoveries,\\tLR fdp,\"\n",
    "                               \"\\tBenchmark num epochs,\\tBenchmark final CELoss,\\tBenchmark total elements,\\tBenchmark total discoveries (ktest),\\tBenchmark v,\\tBenchmark false discoveries,\\tBenchmark fdp\\n\",\n",
    "                              results_stream) \n",
    "    \n",
    "    for exp_type in range(2,NUM_EXPERIMENT_TYPES+1):\n",
    "        \n",
    "        for i in range(NUM_EXPERIMENTS_PER_TYPE):\n",
    "            \n",
    "            # Print to know we started another discovery process\n",
    "            exp_id = F\"{exp_type}-{i}-{datetime.utcnow().strftime('%Y-%m-%d-%H-%M-%S')}\"\n",
    "            print_to_stdout_and_stream(F\"{exp_id},\"\n",
    "                                       F\"\\t{exp_type},\"\n",
    "                                       F\"\\t{i},\"\n",
    "                                       F\"\\t{BATCH_SIZE},\", results_stream)\n",
    "            \n",
    "            discovery_results = run_discovery(i, BATCH_SIZE, exp_type)\n",
    "            \n",
    "            print_to_stdout_and_stream(F\"\\t{discovery_results['alpha']},\"\n",
    "                                       F\"\\t{discovery_results['training_set_size']},\"\n",
    "                                       F\"\\t{discovery_results['test_set_size']},\"\n",
    "                                       F\"\\t{discovery_results['m']},\"\n",
    "                                       F\"\\t{discovery_results['l']},\"\n",
    "                                       F\"\\t{discovery_results['num_epochs']['real']},\"\n",
    "                                       F\"\\t{discovery_results['final_CELoss']['real']},\"\n",
    "                                       F\"\\t{discovery_results['total_elements']['real']},\"\n",
    "                                       F\"\\t{discovery_results['total_discoveries']['real']},\"\n",
    "                                       F\"\\t{discovery_results['v']['real']},\"\n",
    "                                       F\"\\t{discovery_results['false_discoveries']['real']},\"\n",
    "                                       F\"\\t{discovery_results['fdp']['real']},\"\n",
    "                                       F\"\\t{discovery_results['total_elements']['lr']},\"\n",
    "                                       F\"\\t{discovery_results['total_discoveries']['lr']},\"\n",
    "                                       F\"\\t{discovery_results['v']['lr']},\"\n",
    "                                       F\"\\t{discovery_results['false_discoveries']['lr']},\"\n",
    "                                       F\"\\t{discovery_results['fdp']['lr']},\"\n",
    "                                       F\"\\t{discovery_results['num_epochs']['benchmark']},\"\n",
    "                                       F\"\\t{discovery_results['final_CELoss']['benchmark']},\"\n",
    "                                       F\"\\t{discovery_results['total_elements']['benchmark']},\"\n",
    "                                       F\"\\t{discovery_results['total_discoveries']['benchmark']},\"\n",
    "                                       F\"\\t{discovery_results['v']['benchmark']},\"\n",
    "                                       F\"\\t{discovery_results['false_discoveries']['benchmark']},\"\n",
    "                                       F\"\\t{discovery_results['fdp']['benchmark']}\\n\", results_stream)\n",
    "            \n",
    "            # Reproduceability - save the model used for this discovery process\n",
    "            torch.save({ \n",
    "                'model_state_dict': discovery_results[\"model\"][\"real\"].state_dict(),\n",
    "                'optimizer_state_dict': discovery_results[\"optimizer\"][\"real\"].state_dict(),\n",
    "                'loss': discovery_results[\"final_CELoss\"][\"real\"],\n",
    "                'benchmark_model_state_dict': discovery_results[\"model\"][\"benchmark\"].state_dict(),\n",
    "                'benchmark_optimizer_state_dict': discovery_results[\"optimizer\"][\"benchmark\"].state_dict(),\n",
    "                'benchmark_loss': discovery_results[\"final_CELoss\"][\"benchmark\"],\n",
    "                'lr_null_mv': discovery_results[\"model\"][\"lr\"].null_mv,\n",
    "                'lr_positive_mv': discovery_results[\"model\"][\"lr\"].positive_mv,\n",
    "            }, F\"{exp_id}.pt\")\n",
    "\n",
    "print(\"*** All done! ***\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee3ea70-1e74-45de-b8d6-8bc298f526ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
